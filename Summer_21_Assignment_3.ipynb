{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summer_21_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinW824/CSE-144-Applied-Machine-Learning/blob/main/Summer_21_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IlwhV0z2nMr"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU7xWQml74JY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chprzdhe2nMw"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "**DUE: Sunday July 11 at 11:59pm**\n",
        "\n",
        "Turn in the assignment via Canvas.\n",
        "\n",
        "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Runtime→→Restart runtime) and then run all cells (in the menubar, select Runtime→→Run All).\n",
        "\n",
        "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jeWubXE2nMx"
      },
      "source": [
        "NAME = \"Bowen Wang\"\n",
        "STUDENT_ID = \"bwang93\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_22iEs6s1oL"
      },
      "source": [
        "## Problem 1 - Logistic Regression Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrpQWvSs0x3v"
      },
      "source": [
        "Recall from lecture sigmoid function:\n",
        "$$\\begin{align}\n",
        "f(x)= \\sigma(\\theta^T \\cdot \\mathbf{x})) = \\frac{1}{1+e^{-\\theta^T \\cdot \\mathbf{x}}}\n",
        "\\end{align}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeJAjBYEs6iJ"
      },
      "source": [
        "### a) Probabilities (10 points)\n",
        "Write a script to, or by hand, calculate the probability $ \\sigma(\\theta^T \\cdot \\mathbf{x}))$ for each of the following $x^i$'s assuming Assuming $\\theta=[-0.1, 0.1, 0.5, 0.3]$, \n",
        "\n",
        "| | $x^i_{0}$ | $x^i_{1}$ | $x^i_{2}$ | y|\n",
        "| --- | --- | --- | --- | --- |\n",
        "|$x^{1}$ | 1 | -7 | -3 | 0 |\n",
        "|$x^{2}$ | 1 | 5 | 1 | 1 |\n",
        "|$x^{3}$ | 1 | 1 | 1 | 1 |\n",
        "|$x^{4}$ | -1 | -1 | 1 | 1 |\n",
        "|$x^{5}$ | 2 | -1 | 3 | 0 |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-14rVoP8iow",
        "outputId": "60af404c-b393-4b0e-d616-b43c484f7070"
      },
      "source": [
        "import math\n",
        "\n",
        "theta = [-0.1, 0.1, 0.5, 0.3]\n",
        "x = [\n",
        "     [1, -7, -3],\n",
        "     [1, 5, 1],\n",
        "     [1, 1, 1],\n",
        "     [-1, -1, 1],\n",
        "     [2, -1, 3],\n",
        "]\n",
        "\n",
        "for i, array in enumerate(x):\n",
        "    z = 0\n",
        "    for j in range(len(x[i])):\n",
        "        z += theta[j + 1] * x[i][j]\n",
        "    z += theta[0]\n",
        "    sigma = 1 / (1 + math.e ** (-z))\n",
        "    print(\"x{}: {}\".format(i+1, sigma))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1: 0.01212843498427425\n",
            "x2: 0.9426758241011313\n",
            "x3: 0.6899744811276125\n",
            "x4: 0.401312339887548\n",
            "x5: 0.6224593312018545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd413HoUtBRH"
      },
      "source": [
        "### b) Classification (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmoTCICMBMGs"
      },
      "source": [
        "Using the probabilities you calculated in part a) and the decision boundary $\\theta^T\\mathbf{x}=0$ classify the points as class 1 or class 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nKSXta9BIW7"
      },
      "source": [
        "$x_1: 0\\\\\n",
        "x_2: 1\\\\\n",
        "x_3: 1\\\\\n",
        "x_4: 0\\\\\n",
        "x_5: 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IeQoSWbtEPn"
      },
      "source": [
        "## Problem 2 - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh57Se9YtZBD"
      },
      "source": [
        "For this problem, we will predict whether or not breast tumors are cancerous or not using the Breast Cancer Wisconsin (Diagnostic) Data Set. Begin by importing and processing data. A description of the dataset is given below.\n",
        "\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
        "\n",
        "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
        "\n",
        "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
        "\n",
        "This database is also available through the UW CS ftp server:\n",
        "ftp ftp.cs.wisc.edu\n",
        "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
        "\n",
        "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1) ID number\n",
        "\n",
        "2) Diagnosis (M = malignant, B = benign)\n",
        "\n",
        "3 to 32)\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "* a) radius (mean of distances from center to points on the perimeter)\n",
        "* b) texture (standard deviation of gray-scale values)\n",
        "* c) perimeter\n",
        "* d) area\n",
        "* e) smoothness (local variation in radius lengths)\n",
        "* f) compactness (perimeter^2 / area - 1.0)\n",
        "* g) concavity (severity of concave portions of the contour)\n",
        "* h) concave points (number of concave portions of the contour)\n",
        "* i) symmetry\n",
        "* j) fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three\n",
        "largest values) of these features were computed for each image,\n",
        "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
        "13 is Radius SE, field 23 is Worst Radius.\n",
        "\n",
        "All feature values are recoded with four significant digits.\n",
        "\n",
        "Missing attribute values: none\n",
        "\n",
        "Class distribution: 357 benign, 212 malignant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm6WAqNPRRu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyKWchKWIvPi"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwexIqp8I_lF"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLF5xucumaai"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1igyRhO_Vugc0WD_bop9WUqX61Q4BJYBg\"})\n",
        "downloaded.GetContentFile('data.csv')  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpxch0eIm2D3"
      },
      "source": [
        "# Create pandas dataframe\n",
        "data = pd.read_csv('data.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEGGgoy6nD4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ddacd4e1-7d2a-46ba-88df-61a208915163"
      },
      "source": [
        "# Let's look at the data\n",
        "data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8birwmMhNxqx"
      },
      "source": [
        "# drop Unnamed: 32 column\n",
        "data = data.iloc[:,0:-1]\n",
        "\n",
        "#drop the id column\n",
        "data = data.iloc[:,1:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roig66zZ4z3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "236f9f39-b0ba-4fa8-bfa5-4e6578e2f45e"
      },
      "source": [
        "# Let's check the data again\n",
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0           M        17.99  ...          0.4601                  0.11890\n",
              "1           M        20.57  ...          0.2750                  0.08902\n",
              "2           M        19.69  ...          0.3613                  0.08758\n",
              "3           M        11.42  ...          0.6638                  0.17300\n",
              "4           M        20.29  ...          0.2364                  0.07678\n",
              "..        ...          ...  ...             ...                      ...\n",
              "564         M        21.56  ...          0.2060                  0.07115\n",
              "565         M        20.13  ...          0.2572                  0.06637\n",
              "566         M        16.60  ...          0.2218                  0.07820\n",
              "567         M        20.60  ...          0.4087                  0.12400\n",
              "568         B         7.76  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRmp0GI2nOi"
      },
      "source": [
        "### a) Converting Categorical Data to Numeric Values (5 points)\n",
        "\n",
        "The diagnosis column has categorical values 'B' if a tumor is benign, and 'M' if it is malignant. Convert these values to 0 for 'B' and 1 for 'M'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0vh80Yc2nOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "137d78b1-dc71-4056-e99d-59c0a19f2d16"
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
        "data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0            1        17.99  ...          0.4601                  0.11890\n",
              "1            1        20.57  ...          0.2750                  0.08902\n",
              "2            1        19.69  ...          0.3613                  0.08758\n",
              "3            1        11.42  ...          0.6638                  0.17300\n",
              "4            1        20.29  ...          0.2364                  0.07678\n",
              "..         ...          ...  ...             ...                      ...\n",
              "564          1        21.56  ...          0.2060                  0.07115\n",
              "565          1        20.13  ...          0.2572                  0.06637\n",
              "566          1        16.60  ...          0.2218                  0.07820\n",
              "567          1        20.60  ...          0.4087                  0.12400\n",
              "568          0         7.76  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zsToX3tPahn"
      },
      "source": [
        "### b) Run Logistic Regression (10 points)\n",
        "Divide your data into feature set X which contains the following variables:\n",
        "* radius_mean\t\n",
        "* texture_mean\t\n",
        "* perimeter_mean\tarea_mean\t\n",
        "* smoothness_mean\t\n",
        "* compactness_mean\n",
        "* concavity_mean\t\n",
        "* concave points_mean\t\n",
        "* symmetry_mean\t\n",
        "* fractal_dimension_mean\tradius_se\t\n",
        "* texture_se\tperimeter_se\t\n",
        "* area_se\t\n",
        "* smoothness_se\t\n",
        "* compactness_se\t\n",
        "* concavity_se\t\n",
        "* concave points_se\t\n",
        "* symmetry_se\t\n",
        "* fractal_dimension_se\t\n",
        "* radius_worst\t\n",
        "* texture_worst\t\n",
        "* perimeter_worst\t\n",
        "* area_worst\tsmoothness_worst\t\n",
        "* compactness_worst\t\n",
        "* concavity_worst\t\n",
        "* concave points_worst\t\n",
        "* symmetry_worst\t\n",
        "* fractal_dimension_worst\n",
        "\n",
        "and labels y which contains the diagnosis column. Then divide your data into 75% training set data and 25% test set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8e_w2-rRtED"
      },
      "source": [
        "# Split data into X and y\n",
        "X = data.drop(columns=['diagnosis'])### YOUR CODE HERE ###\n",
        "y = data.iloc[:, 0]### YOUR CODE HERE ###\n",
        "\n",
        "# Split X and y into X_train, y_train, X_test, y_test using train_test_split()\n",
        "### YOUR CODE HERE ###\n",
        "X = X.values\n",
        "y = y.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHlyB20UPqQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c93601a-b27a-4dcd-8aa9-85bad0172854"
      },
      "source": [
        "# instantiate LinearRegression\n",
        "clf = LogisticRegression(random_state=0)### YOUR CODE HERE ### \n",
        "\n",
        "\n",
        "# Fit the regressor using X_train and y_train\n",
        "### YOUR CODE HERE ###\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlmjRX-FV6Fa"
      },
      "source": [
        "### c) Classification accuracy for the training and test sets (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfwZS4CJWNrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0aea463-a5ce-48b7-dc7f-caea3cab22b3"
      },
      "source": [
        "# Generate predictions using X_train\n",
        "### YOUR CODE HERE ###\n",
        "from sklearn.metrics import accuracy_score\n",
        "train_pred = clf.predict(X_train)\n",
        "\n",
        "# Calculate the classification accuracy for the training set\n",
        "### YOUR CODE HERE ###\n",
        "train_score = accuracy_score(y_train, train_pred)\n",
        "print(\"train_score:\", train_score)\n",
        "\n",
        "# Generate predictions using X_test\n",
        "### YOUR CODE HERE ###\n",
        "test_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the classification accuracy for the test set\n",
        "### YOUR CODE HERE ###\n",
        "test_score = accuracy_score(y_test, test_pred)\n",
        "print(\"test_score:\", test_score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_score: 0.9483568075117371\n",
            "test_score: 0.9440559440559441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56vnLVWyU83B"
      },
      "source": [
        "### d) False Positives, False Negatives, True Positives, True Negatives (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luz4lriJdESy"
      },
      "source": [
        "In binary classification, A **false positive** (FP) is an outcome where the model incorrectly predicts the positive class. And a **false negative** (FN) is an outcome where the model incorrectly predicts the negative class. Likewise, a **true positive** (TP) is an outcome where the model correctly predicts a positive class. A **true negative** (TN) is an outcome where the model correctly predicts the negative class.\n",
        "\n",
        "Calculate the number of FPs, FNs, TPs,and TNs using the test set predictions and test set labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLFPG2AbhGj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9173ca8-503a-49e5-dd98-f8a492eb5a5b"
      },
      "source": [
        "# Calculate the number of false positives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "fp = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if test_pred[i] == 1 and y_test[i] == 0:\n",
        "        fp += 1\n",
        "print(\"false positive:\", fp)\n",
        "\n",
        "# Calculate the number of false negatives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "fn = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if y_test[i] == 1 and test_pred[i] == 0:\n",
        "        fn += 1\n",
        "print(\"false negative:\", fn)\n",
        "\n",
        "#Calculate the number of true positives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "tp = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if y_test[i] == test_pred[i] == 1:\n",
        "        tp += 1\n",
        "print(\"true positive:\", tp)\n",
        "\n",
        "#Calculate the number of true negatives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "tn = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if y_test[i] == test_pred[i] == 0:\n",
        "        tn += 1\n",
        "print(\"true negative:\", tn)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false positive: 6\n",
            "false negative: 2\n",
            "true positive: 51\n",
            "true negative: 84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p_GEkAbjYHv"
      },
      "source": [
        "### e) Precision and Recall (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0xed4wIjcmn"
      },
      "source": [
        "Two important statistics used to analyze the performance of classification models are precision and recall. **precision** (also called positive predictive value) is proportion of positive identifications that were actually correct, while **recall** (also known as sensitivity) is the proportion of actual positives that were identified correctly.\n",
        "\n",
        "Precision can be calculated as:\n",
        "$$Precision = \\frac{TP}{TP+FP}$$\n",
        "\n",
        "Recall can be calculated as:\n",
        "$$Recall = \\frac{TP}{TP+FN}$$\n",
        "\n",
        "For more info: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THYqeYZ5o_lE"
      },
      "source": [
        "Use your answer from part d) to calculate Precision:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMym2_FYpM3u"
      },
      "source": [
        "$$ Precision = \\dfrac{51}{51 + 6} = 0.8947 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTdTM4vmpMxc"
      },
      "source": [
        "User your answer from part d) to calculate Recall:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5gUHq9MpbVG"
      },
      "source": [
        "$$ Recall = \\dfrac{51}{51 + 2} = 0.9623 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZITT5VUttzO"
      },
      "source": [
        "## Problem 3 - Neural Network For Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMCxB72z-kC9"
      },
      "source": [
        "### a) Training a simply neural network for classification (5 points)\n",
        "Complete the following code segments to create a NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt7K04ckhK1v"
      },
      "source": [
        "# import Keras from TensorFlow\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Ekoez3ciwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "28340e6b-8ad8-4435-ef77-97b11116f2b5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets.samples_generator import make_moons\n",
        "from pylab import rcParams\n",
        "\n",
        "# Create the training data\n",
        "np.random.seed(42) \n",
        "data, labels = make_moons(n_samples=500, noise=0.1)\n",
        "colors = ['r' if y else 'b' for y in labels]\n",
        "print('data.shape =', data.shape)\n",
        "print('labels.shape =', labels.shape)\n",
        "plt.scatter(data[:,0], data[:,1], c=colors)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.shape = (500, 2)\n",
            "labels.shape = (500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW6XzU_IciwH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "a0db4036-aee1-4e84-fc6a-4af1b0b7e2ef"
      },
      "source": [
        "# Create and plot the test data\n",
        "np.random.seed(17)   \n",
        "test_data, test_labels = make_moons(n_samples=500, noise=0.1)\n",
        "colors = ['r' if y else 'b' for y in test_labels]\n",
        "print('test_data.shape =', test_data.shape)\n",
        "print('test_labels.shape =', test_labels.shape)\n",
        "plt.scatter(test_data[:,0], test_data[:,1], c=colors)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data.shape = (500, 2)\n",
            "test_labels.shape = (500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ1Coz15ciwJ"
      },
      "source": [
        "The above image is created by sampling from the same distribution as before. But these are entirely different points than your model was trained on.  So how our model performs on this test data will be a good indication of our model's ability to generalize.\n",
        "\n",
        " In the cell below, construct a simple neural network with 5 layers as follows:\n",
        "* **input layer** of shape 5\n",
        "* **dense layer** with 10 neurons, and relu activation\n",
        "* **dense layer** with 4 neurons, and relu activation\n",
        "* **dense layer** with 3 neurons, and relu activation\n",
        "* **dense layer** with 1 neuron, and sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRRrqpb1ciwK"
      },
      "source": [
        "def build_model1():\n",
        "    ### YOUR CODE HERE ###\n",
        "    input_layer = Input(shape=(2))\n",
        "    x = Dense(10, activation='relu')(input_layer)\n",
        "    x = Dense(4, activation='relu')(x)\n",
        "    x = Dense(3, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x) \n",
        "    return Model(input_layer, x)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6KzH-yXOAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd74a51-ea67-480f-f86c-1c1f6063ce9a"
      },
      "source": [
        "# Get model summary\n",
        "model = build_model1()\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 44        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 93\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PROyV-LvciwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db68d42-d477-4621-8f75-ea401331b835"
      },
      "source": [
        "# Compile the NN model, defining the optimizer to use (sgd), the loss function (binary_crossentropy), and the metrics (acc) to use.\n",
        "# These settings are appropriate for a binary classification task.\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Train the model (obviously on the training data), iterating on the data in batches of 32 samples for 300 epochs. Have a validation_split of 0.2.\n",
        "history = model.fit(data,\n",
        "                    labels, \n",
        "                    epochs=300, \n",
        "                    batch_size=32, \n",
        "                    validation_split=0.2)### YOUR CODE HERE ###\n",
        "\n",
        "# Evaluate the model's performance\n",
        "train_loss, train_acc = model.evaluate(data, labels)\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print('Training set accuracy:', train_acc)\n",
        "print('Test set accuracy:', test_acc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 1s 19ms/step - loss: 0.6746 - accuracy: 0.4675 - val_loss: 0.6699 - val_accuracy: 0.4700\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.5025 - val_loss: 0.6654 - val_accuracy: 0.5300\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6661 - accuracy: 0.5850 - val_loss: 0.6607 - val_accuracy: 0.6300\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6500 - val_loss: 0.6559 - val_accuracy: 0.6900\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6925 - val_loss: 0.6508 - val_accuracy: 0.7400\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7275 - val_loss: 0.6456 - val_accuracy: 0.7400\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7475 - val_loss: 0.6403 - val_accuracy: 0.7800\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7675 - val_loss: 0.6349 - val_accuracy: 0.7900\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.7750 - val_loss: 0.6288 - val_accuracy: 0.8000\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7850 - val_loss: 0.6225 - val_accuracy: 0.8000\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7925 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.8025 - val_loss: 0.6097 - val_accuracy: 0.8000\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.8025 - val_loss: 0.6030 - val_accuracy: 0.8000\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.8100 - val_loss: 0.5960 - val_accuracy: 0.8000\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.8100 - val_loss: 0.5888 - val_accuracy: 0.8000\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.8100 - val_loss: 0.5819 - val_accuracy: 0.8000\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.8100 - val_loss: 0.5749 - val_accuracy: 0.8000\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.8100 - val_loss: 0.5678 - val_accuracy: 0.7900\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8100 - val_loss: 0.5609 - val_accuracy: 0.7800\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.8100 - val_loss: 0.5541 - val_accuracy: 0.7800\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8100 - val_loss: 0.5474 - val_accuracy: 0.7700\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.8100 - val_loss: 0.5410 - val_accuracy: 0.7800\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.8100 - val_loss: 0.5345 - val_accuracy: 0.7700\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.8100 - val_loss: 0.5285 - val_accuracy: 0.7700\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.8075 - val_loss: 0.5225 - val_accuracy: 0.7700\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.8100 - val_loss: 0.5173 - val_accuracy: 0.7800\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.8100 - val_loss: 0.5120 - val_accuracy: 0.7900\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.8100 - val_loss: 0.5068 - val_accuracy: 0.8000\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.8100 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8125 - val_loss: 0.4972 - val_accuracy: 0.8000\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8100 - val_loss: 0.4928 - val_accuracy: 0.8000\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.8150 - val_loss: 0.4884 - val_accuracy: 0.8000\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8150 - val_loss: 0.4846 - val_accuracy: 0.8000\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.8175 - val_loss: 0.4807 - val_accuracy: 0.8000\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.8125 - val_loss: 0.4771 - val_accuracy: 0.8100\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.8150 - val_loss: 0.4734 - val_accuracy: 0.8100\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.8150 - val_loss: 0.4699 - val_accuracy: 0.8100\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.8175 - val_loss: 0.4663 - val_accuracy: 0.8100\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.8200 - val_loss: 0.4630 - val_accuracy: 0.8100\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.8200 - val_loss: 0.4600 - val_accuracy: 0.8100\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8225 - val_loss: 0.4571 - val_accuracy: 0.8300\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.8225 - val_loss: 0.4540 - val_accuracy: 0.8300\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.8225 - val_loss: 0.4512 - val_accuracy: 0.8400\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8225 - val_loss: 0.4483 - val_accuracy: 0.8400\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.8225 - val_loss: 0.4456 - val_accuracy: 0.8500\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.8225 - val_loss: 0.4430 - val_accuracy: 0.8500\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8225 - val_loss: 0.4405 - val_accuracy: 0.8500\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8200 - val_loss: 0.4376 - val_accuracy: 0.8500\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8200 - val_loss: 0.4349 - val_accuracy: 0.8500\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8200 - val_loss: 0.4326 - val_accuracy: 0.8500\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8225 - val_loss: 0.4302 - val_accuracy: 0.8500\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8225 - val_loss: 0.4279 - val_accuracy: 0.8500\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8225 - val_loss: 0.4259 - val_accuracy: 0.8500\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8275 - val_loss: 0.4235 - val_accuracy: 0.8500\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8275 - val_loss: 0.4212 - val_accuracy: 0.8500\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8275 - val_loss: 0.4190 - val_accuracy: 0.8500\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.8275 - val_loss: 0.4167 - val_accuracy: 0.8500\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8275 - val_loss: 0.4145 - val_accuracy: 0.8500\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8275 - val_loss: 0.4124 - val_accuracy: 0.8500\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8275 - val_loss: 0.4104 - val_accuracy: 0.8500\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8275 - val_loss: 0.4086 - val_accuracy: 0.8500\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8275 - val_loss: 0.4065 - val_accuracy: 0.8500\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8275 - val_loss: 0.4044 - val_accuracy: 0.8500\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8275 - val_loss: 0.4026 - val_accuracy: 0.8500\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8275 - val_loss: 0.4006 - val_accuracy: 0.8500\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8275 - val_loss: 0.3987 - val_accuracy: 0.8500\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8300 - val_loss: 0.3967 - val_accuracy: 0.8500\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8350 - val_loss: 0.3947 - val_accuracy: 0.8500\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.3993 - accuracy: 0.8350 - val_loss: 0.3928 - val_accuracy: 0.8500\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8350 - val_loss: 0.3908 - val_accuracy: 0.8500\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.8500\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8350 - val_loss: 0.3875 - val_accuracy: 0.8500\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8350 - val_loss: 0.3858 - val_accuracy: 0.8500\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8350 - val_loss: 0.3835 - val_accuracy: 0.8500\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8350 - val_loss: 0.3816 - val_accuracy: 0.8500\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8350 - val_loss: 0.3801 - val_accuracy: 0.8500\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8400 - val_loss: 0.3782 - val_accuracy: 0.8500\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8375 - val_loss: 0.3761 - val_accuracy: 0.8500\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8400 - val_loss: 0.3741 - val_accuracy: 0.8500\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8425 - val_loss: 0.3727 - val_accuracy: 0.8500\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8425 - val_loss: 0.3706 - val_accuracy: 0.8500\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8450 - val_loss: 0.3689 - val_accuracy: 0.8500\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8450 - val_loss: 0.3677 - val_accuracy: 0.8500\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8475 - val_loss: 0.3660 - val_accuracy: 0.8500\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8475 - val_loss: 0.3646 - val_accuracy: 0.8500\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8475 - val_loss: 0.3626 - val_accuracy: 0.8500\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8475 - val_loss: 0.3607 - val_accuracy: 0.8500\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8475 - val_loss: 0.3592 - val_accuracy: 0.8500\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8475 - val_loss: 0.3583 - val_accuracy: 0.8500\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8500 - val_loss: 0.3565 - val_accuracy: 0.8500\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8500 - val_loss: 0.3547 - val_accuracy: 0.8500\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8500 - val_loss: 0.3533 - val_accuracy: 0.8500\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8500 - val_loss: 0.3514 - val_accuracy: 0.8500\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8500 - val_loss: 0.3494 - val_accuracy: 0.8500\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8500 - val_loss: 0.3480 - val_accuracy: 0.8500\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8500 - val_loss: 0.3463 - val_accuracy: 0.8500\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8500 - val_loss: 0.3449 - val_accuracy: 0.8500\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8500 - val_loss: 0.3431 - val_accuracy: 0.8500\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8500 - val_loss: 0.3411 - val_accuracy: 0.8500\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8500 - val_loss: 0.3395 - val_accuracy: 0.8500\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8500 - val_loss: 0.3381 - val_accuracy: 0.8500\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8500 - val_loss: 0.3368 - val_accuracy: 0.8500\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8500 - val_loss: 0.3352 - val_accuracy: 0.8500\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8500 - val_loss: 0.3344 - val_accuracy: 0.8500\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8525 - val_loss: 0.3334 - val_accuracy: 0.8500\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8550 - val_loss: 0.3314 - val_accuracy: 0.8500\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3246 - accuracy: 0.8525 - val_loss: 0.3316 - val_accuracy: 0.8500\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8550 - val_loss: 0.3297 - val_accuracy: 0.8500\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8550 - val_loss: 0.3284 - val_accuracy: 0.8500\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8575 - val_loss: 0.3272 - val_accuracy: 0.8500\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8550 - val_loss: 0.3255 - val_accuracy: 0.8500\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8600 - val_loss: 0.3244 - val_accuracy: 0.8500\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8575 - val_loss: 0.3235 - val_accuracy: 0.8500\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8600 - val_loss: 0.3224 - val_accuracy: 0.8600\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8600 - val_loss: 0.3219 - val_accuracy: 0.8700\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8600 - val_loss: 0.3207 - val_accuracy: 0.8700\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8625 - val_loss: 0.3200 - val_accuracy: 0.8600\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8650 - val_loss: 0.3183 - val_accuracy: 0.8600\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8650 - val_loss: 0.3168 - val_accuracy: 0.8600\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8650 - val_loss: 0.3157 - val_accuracy: 0.8600\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8675 - val_loss: 0.3142 - val_accuracy: 0.8600\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8675 - val_loss: 0.3131 - val_accuracy: 0.8600\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8700 - val_loss: 0.3116 - val_accuracy: 0.8600\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.8700 - val_loss: 0.3111 - val_accuracy: 0.8600\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8725 - val_loss: 0.3099 - val_accuracy: 0.8600\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8725 - val_loss: 0.3098 - val_accuracy: 0.8600\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8725 - val_loss: 0.3096 - val_accuracy: 0.8600\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8750 - val_loss: 0.3085 - val_accuracy: 0.8600\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8725 - val_loss: 0.3067 - val_accuracy: 0.8600\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8725 - val_loss: 0.3058 - val_accuracy: 0.8600\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8725 - val_loss: 0.3055 - val_accuracy: 0.8600\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.8775 - val_loss: 0.3041 - val_accuracy: 0.8600\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8775 - val_loss: 0.3045 - val_accuracy: 0.8500\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8825 - val_loss: 0.3018 - val_accuracy: 0.8500\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8825 - val_loss: 0.3010 - val_accuracy: 0.8500\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8825 - val_loss: 0.3017 - val_accuracy: 0.8500\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8825 - val_loss: 0.3009 - val_accuracy: 0.8500\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8825 - val_loss: 0.2991 - val_accuracy: 0.8500\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.8825 - val_loss: 0.2976 - val_accuracy: 0.8500\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8825 - val_loss: 0.2961 - val_accuracy: 0.8500\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8825 - val_loss: 0.2954 - val_accuracy: 0.8500\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8825 - val_loss: 0.2943 - val_accuracy: 0.8500\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.8850 - val_loss: 0.2941 - val_accuracy: 0.8400\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2742 - accuracy: 0.8875 - val_loss: 0.2940 - val_accuracy: 0.8400\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.8900 - val_loss: 0.2934 - val_accuracy: 0.8500\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8925 - val_loss: 0.2933 - val_accuracy: 0.8500\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8925 - val_loss: 0.2930 - val_accuracy: 0.8500\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.8900 - val_loss: 0.2918 - val_accuracy: 0.8500\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8900 - val_loss: 0.2908 - val_accuracy: 0.8500\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8900 - val_loss: 0.2894 - val_accuracy: 0.8500\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.8900 - val_loss: 0.2889 - val_accuracy: 0.8500\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8925 - val_loss: 0.2867 - val_accuracy: 0.8500\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8925 - val_loss: 0.2869 - val_accuracy: 0.8500\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.8950 - val_loss: 0.2855 - val_accuracy: 0.8600\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8925 - val_loss: 0.2852 - val_accuracy: 0.8600\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.8950 - val_loss: 0.2843 - val_accuracy: 0.8600\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8975 - val_loss: 0.2841 - val_accuracy: 0.8600\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2599 - accuracy: 0.8975 - val_loss: 0.2845 - val_accuracy: 0.8600\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.8950 - val_loss: 0.2835 - val_accuracy: 0.8600\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.8975 - val_loss: 0.2818 - val_accuracy: 0.8700\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.9000 - val_loss: 0.2808 - val_accuracy: 0.8700\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.9000 - val_loss: 0.2805 - val_accuracy: 0.8700\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9025 - val_loss: 0.2790 - val_accuracy: 0.8700\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.9025 - val_loss: 0.2764 - val_accuracy: 0.8700\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2533 - accuracy: 0.9025 - val_loss: 0.2757 - val_accuracy: 0.8700\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9025 - val_loss: 0.2739 - val_accuracy: 0.8700\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9025 - val_loss: 0.2746 - val_accuracy: 0.8700\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9050 - val_loss: 0.2748 - val_accuracy: 0.8700\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9025 - val_loss: 0.2736 - val_accuracy: 0.8700\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9100 - val_loss: 0.2758 - val_accuracy: 0.8700\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.9075 - val_loss: 0.2746 - val_accuracy: 0.8700\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2475 - accuracy: 0.9075 - val_loss: 0.2735 - val_accuracy: 0.8700\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9075 - val_loss: 0.2746 - val_accuracy: 0.8600\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9075 - val_loss: 0.2718 - val_accuracy: 0.8700\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.9075 - val_loss: 0.2695 - val_accuracy: 0.8700\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.9125 - val_loss: 0.2714 - val_accuracy: 0.8600\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.9100 - val_loss: 0.2707 - val_accuracy: 0.8600\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.9100 - val_loss: 0.2706 - val_accuracy: 0.8600\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2414 - accuracy: 0.9100 - val_loss: 0.2696 - val_accuracy: 0.8600\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2405 - accuracy: 0.9100 - val_loss: 0.2691 - val_accuracy: 0.8600\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9100 - val_loss: 0.2689 - val_accuracy: 0.8600\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2391 - accuracy: 0.9125 - val_loss: 0.2672 - val_accuracy: 0.8600\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9125 - val_loss: 0.2673 - val_accuracy: 0.8600\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9175 - val_loss: 0.2668 - val_accuracy: 0.8600\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9175 - val_loss: 0.2652 - val_accuracy: 0.8600\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9150 - val_loss: 0.2638 - val_accuracy: 0.8700\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2346 - accuracy: 0.9150 - val_loss: 0.2622 - val_accuracy: 0.8700\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9125 - val_loss: 0.2611 - val_accuracy: 0.8800\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9200 - val_loss: 0.2600 - val_accuracy: 0.8800\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.9225 - val_loss: 0.2594 - val_accuracy: 0.8800\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9225 - val_loss: 0.2616 - val_accuracy: 0.8700\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9225 - val_loss: 0.2594 - val_accuracy: 0.8800\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9250 - val_loss: 0.2606 - val_accuracy: 0.8800\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2290 - accuracy: 0.9250 - val_loss: 0.2583 - val_accuracy: 0.8800\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9300 - val_loss: 0.2590 - val_accuracy: 0.8800\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9300 - val_loss: 0.2601 - val_accuracy: 0.8800\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9250 - val_loss: 0.2563 - val_accuracy: 0.8800\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9225 - val_loss: 0.2526 - val_accuracy: 0.8800\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9275 - val_loss: 0.2520 - val_accuracy: 0.8800\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9300 - val_loss: 0.2532 - val_accuracy: 0.8800\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2232 - accuracy: 0.9300 - val_loss: 0.2520 - val_accuracy: 0.8800\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9325 - val_loss: 0.2524 - val_accuracy: 0.8800\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2211 - accuracy: 0.9350 - val_loss: 0.2518 - val_accuracy: 0.8800\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2203 - accuracy: 0.9350 - val_loss: 0.2532 - val_accuracy: 0.8800\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2197 - accuracy: 0.9325 - val_loss: 0.2508 - val_accuracy: 0.8800\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9350 - val_loss: 0.2515 - val_accuracy: 0.8800\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9325 - val_loss: 0.2498 - val_accuracy: 0.8800\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2174 - accuracy: 0.9350 - val_loss: 0.2490 - val_accuracy: 0.8800\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9325 - val_loss: 0.2474 - val_accuracy: 0.8800\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9375 - val_loss: 0.2461 - val_accuracy: 0.8900\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9375 - val_loss: 0.2431 - val_accuracy: 0.8900\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2133 - accuracy: 0.9425 - val_loss: 0.2438 - val_accuracy: 0.8900\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9450 - val_loss: 0.2423 - val_accuracy: 0.8900\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9400 - val_loss: 0.2410 - val_accuracy: 0.8900\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2110 - accuracy: 0.9425 - val_loss: 0.2399 - val_accuracy: 0.9000\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2099 - accuracy: 0.9425 - val_loss: 0.2374 - val_accuracy: 0.9000\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9475 - val_loss: 0.2364 - val_accuracy: 0.9000\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2087 - accuracy: 0.9425 - val_loss: 0.2379 - val_accuracy: 0.9000\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9425 - val_loss: 0.2357 - val_accuracy: 0.9000\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2064 - accuracy: 0.9500 - val_loss: 0.2349 - val_accuracy: 0.9000\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9475 - val_loss: 0.2340 - val_accuracy: 0.9000\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.9475 - val_loss: 0.2331 - val_accuracy: 0.9000\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9475 - val_loss: 0.2330 - val_accuracy: 0.9100\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9450 - val_loss: 0.2316 - val_accuracy: 0.9100\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9475 - val_loss: 0.2308 - val_accuracy: 0.9100\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9475 - val_loss: 0.2300 - val_accuracy: 0.9100\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1999 - accuracy: 0.9525 - val_loss: 0.2298 - val_accuracy: 0.9100\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9475 - val_loss: 0.2291 - val_accuracy: 0.9100\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1983 - accuracy: 0.9500 - val_loss: 0.2290 - val_accuracy: 0.9100\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9475 - val_loss: 0.2275 - val_accuracy: 0.9100\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9475 - val_loss: 0.2269 - val_accuracy: 0.9100\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9475 - val_loss: 0.2267 - val_accuracy: 0.9100\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9475 - val_loss: 0.2228 - val_accuracy: 0.9200\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9500 - val_loss: 0.2220 - val_accuracy: 0.9200\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9525 - val_loss: 0.2238 - val_accuracy: 0.9200\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9500 - val_loss: 0.2233 - val_accuracy: 0.9200\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1909 - accuracy: 0.9475 - val_loss: 0.2198 - val_accuracy: 0.9200\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9475 - val_loss: 0.2165 - val_accuracy: 0.9200\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9550 - val_loss: 0.2145 - val_accuracy: 0.9200\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1879 - accuracy: 0.9550 - val_loss: 0.2169 - val_accuracy: 0.9200\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9500 - val_loss: 0.2159 - val_accuracy: 0.9200\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1857 - accuracy: 0.9500 - val_loss: 0.2142 - val_accuracy: 0.9200\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9500 - val_loss: 0.2123 - val_accuracy: 0.9200\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9525 - val_loss: 0.2123 - val_accuracy: 0.9200\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9525 - val_loss: 0.2085 - val_accuracy: 0.9200\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9550 - val_loss: 0.2086 - val_accuracy: 0.9200\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9525 - val_loss: 0.2098 - val_accuracy: 0.9200\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9500 - val_loss: 0.2072 - val_accuracy: 0.9200\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9550 - val_loss: 0.2073 - val_accuracy: 0.9200\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9500 - val_loss: 0.2047 - val_accuracy: 0.9200\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1774 - accuracy: 0.9525 - val_loss: 0.2028 - val_accuracy: 0.9200\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.9550 - val_loss: 0.2073 - val_accuracy: 0.9200\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.9525 - val_loss: 0.2034 - val_accuracy: 0.9200\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9525 - val_loss: 0.2031 - val_accuracy: 0.9200\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9550 - val_loss: 0.2025 - val_accuracy: 0.9200\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9525 - val_loss: 0.1986 - val_accuracy: 0.9200\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9550 - val_loss: 0.1981 - val_accuracy: 0.9200\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9525 - val_loss: 0.1976 - val_accuracy: 0.9200\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1693 - accuracy: 0.9550 - val_loss: 0.1956 - val_accuracy: 0.9200\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9525 - val_loss: 0.1936 - val_accuracy: 0.9300\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9575 - val_loss: 0.1942 - val_accuracy: 0.9200\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9525 - val_loss: 0.1926 - val_accuracy: 0.9300\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9550 - val_loss: 0.1904 - val_accuracy: 0.9300\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9575 - val_loss: 0.1901 - val_accuracy: 0.9300\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9575 - val_loss: 0.1890 - val_accuracy: 0.9300\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.9575 - val_loss: 0.1873 - val_accuracy: 0.9300\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9550 - val_loss: 0.1856 - val_accuracy: 0.9300\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.9575 - val_loss: 0.1839 - val_accuracy: 0.9400\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9575 - val_loss: 0.1840 - val_accuracy: 0.9300\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9550 - val_loss: 0.1840 - val_accuracy: 0.9300\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9575 - val_loss: 0.1833 - val_accuracy: 0.9300\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9600 - val_loss: 0.1808 - val_accuracy: 0.9300\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9600 - val_loss: 0.1796 - val_accuracy: 0.9400\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9550 - val_loss: 0.1788 - val_accuracy: 0.9300\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9600 - val_loss: 0.1785 - val_accuracy: 0.9300\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9625 - val_loss: 0.1752 - val_accuracy: 0.9400\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9575 - val_loss: 0.1761 - val_accuracy: 0.9400\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9625 - val_loss: 0.1742 - val_accuracy: 0.9400\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9600 - val_loss: 0.1718 - val_accuracy: 0.9400\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9625 - val_loss: 0.1699 - val_accuracy: 0.9400\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1484 - accuracy: 0.9600 - val_loss: 0.1702 - val_accuracy: 0.9400\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9625 - val_loss: 0.1711 - val_accuracy: 0.9400\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9625 - val_loss: 0.1685 - val_accuracy: 0.9400\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1457 - accuracy: 0.9625 - val_loss: 0.1668 - val_accuracy: 0.9400\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9650 - val_loss: 0.1673 - val_accuracy: 0.9400\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9600 - val_loss: 0.1651 - val_accuracy: 0.9400\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9650 - val_loss: 0.1665 - val_accuracy: 0.9400\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9650 - val_loss: 0.1663 - val_accuracy: 0.9400\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9650 - val_loss: 0.1627 - val_accuracy: 0.9400\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9650 - val_loss: 0.1606 - val_accuracy: 0.9400\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1375 - accuracy: 0.9650 - val_loss: 0.1580 - val_accuracy: 0.9500\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9675 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.9650 - val_loss: 0.1572 - val_accuracy: 0.9400\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9675 - val_loss: 0.1540 - val_accuracy: 0.9500\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9675 - val_loss: 0.1532 - val_accuracy: 0.9500\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9675 - val_loss: 0.1507 - val_accuracy: 0.9500\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.9725 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.9750 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9725 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.9725 - val_loss: 0.1454 - val_accuracy: 0.9600\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.9720\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9580\n",
            "Training set accuracy: 0.972000002861023\n",
            "Test set accuracy: 0.9580000042915344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nq6RMLzciwN"
      },
      "source": [
        "Let's next look at some training plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_BySHr13P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f35ee1b-bdec-4ad5-cabb-e19111bb0b4f"
      },
      "source": [
        "history"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce3f730450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpoIfuW8ciwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "314a9f9f-05bf-4732-ba5a-9da496170cc8"
      },
      "source": [
        "# The history of our accuracy during training.\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkivLoq-ciwU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0b856411-2267-438f-b959-1665cb32b6ce"
      },
      "source": [
        "# The history of our cross-entropy loss during training.\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd1zV9f7A8dcbRAhFVBAVUMHc4t6aWmrO0nZqNm5DW7fusmu/6jbu6Ha71W13G15NKzMrMzNXznKiuXCAoqioLBHZ8/P74/u1yAAZ53CA834+Hjw85zvfX4+eN58txhiUUkq5Lw9XB6CUUsq1NBEopZSb00SglFJuThOBUkq5OU0ESinl5jQRKKWUm9NEoFQZRCRMRIyI1CvHsXeJyPfVEZdSjqSJQNUZInJMRPJEJPCi7T/aX+ZhromsYglFqeqmiUDVNUeBKRfeiEg3wNd14ShV82kiUHXNPOCOYu/vBD4sfoCI+IvIhyKSJCJxIvKkiHjY+zxF5N8ikiwiscCEEs79QEROi0i8iPxNRDyrErCIBIvIEhE5KyKHReS+Yvv6i0ikiJwXkQQRedne7iMi80UkRUTOich2EWlelTiU+9JEoOqaLUAjEelsf0FPBuZfdMzrgD/QFhiOlTh+Y++7D7gG6AX0BW666Nw5QAHQzj5mNHBvFWNeAJwEgu37/UNERtj7XgVeNcY0Ai4HFtrb77SfoRUQANwPZFcxDuWmNBGouuhCqeBq4AAQf2FHseTwuDEm3RhzDHgJuN0+5BbgP8aYE8aYs8Dzxc5tDowHfmeMyTTGJAKv2NerFBFpBQwB/myMyTHG7ALe5+dSTT7QTkQCjTEZxpgtxbYHAO2MMYXGmB3GmPOVjUO5N00Eqi6aB0wF7uKiaiEgEPAC4optiwNC7NfBwImL9l3Qxj73tF0dcw74LxBUhViDgbPGmPRS4rkH6AActKt/rrG3zwNWAAtE5JSI/EtEvKoQh3JjmghUnWOMicNqNB4PfHHR7mSs36bbFNvWmp9LDaexqluK77vgBJALBBpjGts/jYwxXasQ7imgqYj4lRSPMSbGGDMFK9m8ACwSkQbGmHxjzLPGmC7AYKzqrDtQqhI0Eai66h5ghDEms/hGY0whVj3730XET0TaAH/g53aEhcAjIhIqIk2AWcXOPQ2sBF4SkUYi4iEil4vI8ArE5W039PqIiA/WF/4m4Hl7W3c79vkAIjJNRJoZY4qAc/Y1ikTkKhHpZld1ncdKbkUViEOpn2giUHWSMeaIMSaylN2/BTKBWOB74GNgtr3vPawql93ATn5dorgDqA/sB1KBRUDLCoSWgdWoe+FnBFZ31zCs0sGXwNPGmNX28WOBKBHJwGo4nmyMyQZa2Pc+j9UOsh6rukipChNdmEYppdyblgiUUsrNaSJQSik359REICJjReSQPVpyVgn7XxGRXfZPtN0dTymlVDVyWhuB3ZshGmtQz0lgOzDFGLO/lON/C/QyxtztlICUUkqVyJkzIfYHDhtjYgFEZAEwCau3RUmmAE9f6qKBgYEmLCzMUTEqpZRb2LFjR7IxpllJ+5yZCEL45QjNk8CAkg60+3KHA2tK2T8dmA7QunVrIiNL6xWolFKqJCISV9q+mtJYPBlYZA/2+RVjzLvGmL7GmL7NmpWY0JRSSlWSMxNBPL8cqh9Kscm/LjIZ+MSJsSillCqFMxPBdqC9iISLSH2sL/slFx8kIp2AJsBmJ8ailFKqFE5rIzDGFIjIw1jD9T2B2caYKBF5Dog0xlxICpOBBUaHOCulnCg/P5+TJ0+Sk5Pj6lCcysfHh9DQULy8yj8Zba2bYqJv375GG4uVUhV19OhR/Pz8CAgIQERcHY5TGGNISUkhPT2d8PDwX+wTkR3GmL4lnVdTGouVUsqpcnJy6nQSABARAgICKlzq0USglHIbdTkJXFCZZ3SbRBCTkM4Lyw9S26rClFLK2dwmEayPTuKddTF8teuUq0NRSrmhc+fO8dZbb1X4vPHjx3PunHOnYXObRHC331bWNHyK55fsJCk919XhKKXcTGmJoKCgoMzzli1bRuPGjZ0VFuBGicDDP4TwgqPcXvAlzyyJcnU4Sik3M2vWLI4cOULPnj3p168fQ4cOZeLEiXTp0gWA6667jj59+tC1a1fefffdn84LCwsjOTmZY8eO0blzZ+677z66du3K6NGjyc7OdkhszpxrqGYJHwYRN/FA1FeM3DeY5fuCGRvRwtVRKaVc4Nmvo9h/6rxDr9kluBFPX9u11P3//Oc/2bdvH7t27WLdunVMmDCBffv2/dTNc/bs2TRt2pTs7Gz69evHjTfeSEBAwC+uERMTwyeffMJ7773HLbfcwueff860adOqHLvblAgAGPN3PLx8+HeDj3hq8V7SsvNdHZFSyk3179//F339X3vtNXr06MHAgQM5ceIEMTExvzonPDycnj17AtCnTx+OHTvmkFjcp0QA4NcCGfEEfZfPol/+97y8siXPTopwdVRKqWpW1m/u1aVBgwY/vV63bh2rV69m8+bN+Pr6cuWVV5Y4FsDb2/un156eng6rGnKvEgFAv/ugeTee9/2YRVsOsS8+zdURKaXcgJ+fH+np6SXuS0tLo0mTJvj6+nLw4EG2bNlSrbG5XyLwrAfjX8Q/P5EHfVbx1Ff7KCrSsQVKKecKCAhgyJAhREREMHPmzF/sGzt2LAUFBXTu3JlZs2YxcODAao3Nfeca+mQq+UfWMSDjJZ6ePIxJPUOqfk2lVI114MABOnfu7OowqkVJz6pzDZVk1NPUK8zmaf9v+NfyQ+QWlLgmjlJK1XnumwiadUR63c61+cvxSDvGvM2lruKmlFJ1mvsmAoArH8fDox4vNvmK19ccJi1Lu5MqpdyPeyeCRi1h0EMMzFpHq9xo3lx32NURKaVUtXPvRAAw5BHwacyLTZcw54djnDrnmH65SilVW2gi8PGHK35H54ytRBDD+xuPujoipZSqVpoIAPrdC97+/CVgDZ9sO05qZp6rI1JK1TGVnYYa4D//+Q9ZWVkOjuhnmggAvP2gz530SF9PQMEZ5m4+5uqIlFJ1TE1OBO4111BZBsxAtrzF00EbmLkpmOnD2uJbX/96lFKOUXwa6quvvpqgoCAWLlxIbm4u119/Pc8++yyZmZnccsstnDx5ksLCQp566ikSEhI4deoUV111FYGBgaxdu9bhsek33QX+odD1ekYc/JbCrHEs2HaCu68Iv/R5Sqna59tZcGavY6/ZohuM+2epu4tPQ71y5UoWLVrEtm3bMMYwceJENmzYQFJSEsHBwXzzzTeANQeRv78/L7/8MmvXriUwMNCxMdu0aqi4QQ/jmZ/BY8228t7GWPIKilwdkVKqDlq5ciUrV66kV69e9O7dm4MHDxITE0O3bt1YtWoVf/7zn9m4cSP+/v7VEo+WCIoL7glhQ7k5cSnPpg1l6Z5T3NA71NVRKaUcrYzf3KuDMYbHH3+cGTNm/Grfzp07WbZsGU8++SQjR47kL3/5i9Pj0RLBxQY9hE/WaX7TZDcffH+U2jYpn1KqZio+DfWYMWOYPXs2GRkZAMTHx5OYmMipU6fw9fVl2rRpzJw5k507d/7qXGfQEsHF2o+BgPbcX7Cc9071ZtvRswxoG3Dp85RSqgzFp6EeN24cU6dOZdCgQQA0bNiQ+fPnc/jwYWbOnImHhwdeXl68/fbbAEyfPp2xY8cSHBzslMZi952GuiyRs2Hp7/mNPIdX+BDevaPEmVuVUrWITkPtommoRWSsiBwSkcMiMquUY24Rkf0iEiUiHzsznnLrfit4+/NY0+9ZdSCBuJRMV0eklFJO47REICKewJvAOKALMEVEulx0THvgcWCIMaYr8DtnxVMh9RtAzyl0Sl1LkMd55mw65uqIlFLKaZxZIugPHDbGxBpj8oAFwKSLjrkPeNMYkwpgjEl0YjwV0/cepCifp4J3snD7Cc7n6BTVStV2ta0qvDIq84zOTAQhwIli70/a24rrAHQQkR9EZIuIjC3pQiIyXUQiRSQyKSnJSeFepFkHCBvK6OxlZOfls3D7iUufo5SqsXx8fEhJSanTycAYQ0pKCj4+PhU6z9W9huoB7YErgVBgg4h0M8acK36QMeZd4F2wGourLbp+91D/s7u4t8UR5m1pyN1DwvHwkGq7vVLKcUJDQzl58iTV9suki/j4+BAaWrHxT85MBPFAq2LvQ+1txZ0Ethpj8oGjIhKNlRi2OzGu8ut0DTQI4m6fdbx7pj3rohMZ0am5q6NSSlWCl5cX4eE6bUxJnFk1tB1oLyLhIlIfmAwsueiYxVilAUQkEKuqKNaJMVWMpxf0mkbzhPV080tnziZd11gpVfc4LREYYwqAh4EVwAFgoTEmSkSeE5GJ9mErgBQR2Q+sBWYaY1KcFVOl9LkTMYYnW+5gQ3QSR5IyXB2RUko5lA4oK495N1CYeICIsy9yS/8wnp0UUb33V0qpKnLZgLI6o89deKaf4o/hcSzacZJ07UqqlKpDNBGUR8dx0LA5t8hqMvMKWbTjpKsjUkoph9FEUB6eXtDrdhqdXMfVIXl8uDmOoqLaVaWmlFKl0URQXn3uBGP4U+BWjiZnsj6mbvdFVkq5D00E5dW4NbQbRYdTi2nRsB5zdf4hpVQdoYmgIvr+Bkk/zRPt41h3KIlY7UqqlKoDNBFURPsx4BfM6Oxvqe/pwewfjro6IqWUqjJNBBXhWQ963473sbXcEyF8FnmS5IxcV0ellFJVoomgonrfASJMb7CBvMIibStQStV6mggqyj8UOk2gyYGPmdCpMR9ujiMzt8DVUSmlVKVpIqiMAfdDdiozQ/aSlp3PAl2rQClVi2kiqIw2Q6B5BG1i5tG/TRM+2BhLfmGRq6NSSqlK0URQGSLQfzok7GNW1xROpeWwZNcpV0ellFKVoomgsrrdDJc1odfphXRu2Yg31x6mQEsFSqlaSBNBZdX3hd53IAeX8udBDYhNzuTrPVoqUErVPpoIqqLfvQAMT1tC55aNeP07LRUopWofTQRV0bg1dJqA7JzD769sRWxyJl9pW4FSqpbRRFBV/WdAdiqj8tbSNbgRr6yOJreg0NVRKaVUuWkiqKqwKyC4Fx6b/sOsMe04mZrN/C3HXR2VUkqVmyaCqhKBYY9B6jGGZq9jaPtA3lgTw3ldzlIpVUtoInCEjuOgeTfY8CJ/Ht2e1Kx83lx72NVRKaVUuWgicAQRGP4YnD1CROp33NQnlNnfH+WIrleglKoFNBE4SqdrIKgLbHiRWWM74OPlyTNLojBG1zZWStVsmggcxcMDhv0Jkg8RGLeMP17dgY0xySzfd8bVkSmlVJk0EThSl+ugWWdY8zem9WtJpxZ+/HXpfrLydJpqpVTNpYnAkTw8YfRf4Wws9XbO4a/XRXAqLYdXv4txdWRKKVUqTQSO1m4UhA+H9S/Qr7kHk/u14r0Nsew8nurqyJRSqkROTQQiMlZEDonIYRGZVcL+u0QkSUR22T/3OjOeaiECo/8G2anw/cs8MaEzLRr58KfPdpOTryOOlVI1j9MSgYh4Am8C44AuwBQR6VLCoZ8aY3raP+87K55q1bI79JgMW97BL+c0/7qpB7FJmfx7xSFXR6aUUr/izBJBf+CwMSbWGJMHLAAmOfF+NcuIJ63SwconuaJ9INMGtuaDH46y/dhZV0emlFK/4MxEEAIUX8z3pL3tYjeKyB4RWSQirUq6kIhMF5FIEYlMSkpyRqyO5x9qdSfd/xXErOLxcZ1p1cSXRz/5kdTMPFdHp5RSP3F1Y/HXQJgxpjuwCphb0kHGmHeNMX2NMX2bNWtWrQFWyeBHILADfPNHGkgeb07tTXJGHr/7dBdFRTrQTClVMzgzEcQDxX/DD7W3/cQYk2KMybXfvg/0cWI81a+eN0x4Gc7Fwfp/0i3Un6cndmF9dJLORaSUqjGcmQi2A+1FJFxE6gOTgSXFDxCRlsXeTgQOODEe1wgfCr1uh02vw/GtTO3fmut7hfDy6mi+j0l2dXRKKeW8RGCMKQAeBlZgfcEvNMZEichzIjLRPuwREYkSkd3AI8BdzorHpcb8AxqFwuL7kfws/n59BO2DGvLogh85k5bj6uiUUm5OatukaH379jWRkZGuDqPijm6EuddAn7vg2lc5nJjBpDe+p1PLRiyYPhAvT1c31yil6jIR2WGM6VvSPv32qS7hQ2HIo7BjDuz5jHZBDfnnjd3ZEZfK88sOujo6pZQb00RQnUY8Ba0HwdePQlI01/YI5jdDwpj9w1E+izxx6fOVUsoJNBFUJ08vuGk2ePnAZ3dCXhZPjO/MFe0CeeLLfeyI08FmSqnqp4mgujUKhhveg8QDsPR31PMQ3pjai+DGPsyYt4P4c9mujlAp5WY0EbhCu5Fw1f/Bnk9h479p7Fuf9+/sS05+EffM2U5ati58r5SqPpoIXGXYTOh2C6z5G+z7gnZBfrw9rTdHkjK4Z852svN0plKlVPXQROAqIjDxdWg1ABY/ACcjGdq+Ga/c2pMdx1N58KMd5BcWuTpKpZQb0ETgSl4+MPljaNgcPpkC505wTfdg/nZdBGsPJTHzs906J5FSyuk0Ebhag0CYuhAKcmD+jZCZzG0D2jBzTEcW7zrFc0v3U9sG/SmlahdNBDVBUCerZHAuDuZdB9mpPHjl5dxzRThzNh3jte90gjqllPNoIqgpwofC5I8g6RDMvxHJTeeJ8Z25oXcIr6yOZu6mY66OUClVR2kiqEnajYKb58Lp3fDxrXgUZPHCjd0Z1bk5Ty+J4qOtca6OUClVB2kiqGk6jYcb3oUTW+CTyXgVZPHmbb0Y0SmIJ77cx/wtmgyUUo6liaAmirgRrnsHjn0P82/AOz+dt6f1ZmSnIJ5cvI95mgyUUg6kiaCm6nEr3DwH4nfC3Gvxzk3lrWm9GdU5iKcW7+O/64+4OkKlVB2hiaAm6zIJpiyA5Gj433i8sxJ567Y+XNO9Jc9/e5AXVxzUrqVKqSrTRFDTtR8F0z6H8/Hwv7HUTz/Oq5N7MaV/a95ce4SnvtpHoQ46U0pVgSaC2iDsCrhjCWSfgw/G4BkfyT+uj2DG8LbM33KcGfN2kJVX4OoolVK1lCaC2iK0D9y93JqWYs54ZOeHPD6uM89N6sqagwnc+t8tJJ7X9Y+VUhWniaA2CeoM9621SghfPwLf/JE7+gXz3h19OZyYwfVvbeLQmXRXR6mUqmU0EdQ2vk3htkXW+sfb34cPJzKylfDZ/YPILyziprc38X1MsqujVErVIpoIaiMPT7j6ObjxAzi1C/47nAgOs/ihIYQ0uYy7/reNhdt1DWSlVPmUKxGISAMR8bBfdxCRiSLi5dzQ1CV1uwnuWQke9WD2OIKPLeaz+wcx6PIAHvt8Dy+uOKjTWCulLqm8JYINgI+IhAArgduBOc4KSlVAy+4wfR206g+L78dv7VPMvr0nU/q34s21R7h77nZSM/NcHaVSqgYrbyIQY0wWcAPwljHmZqCr88JSFdIgAG5fDAMfhK1v4/XxjfxjVCB/uy6CTYdTuOb179l14pyro1RK1VDlTgQiMgi4DfjG3ubpnJBUpXjWg7HPw/X/hfgdyNtDmNY4ikUPDEIEbn5nE3M3HdORyEqpXylvIvgd8DjwpTEmSkTaAmudF5aqtB6TYfp68A+FBVPovus5lt7fm2Htm/H0kigeWbCLjFwdfKaU+lm5EoExZr0xZqIx5gW70TjZGPPIpc4TkbEickhEDovIrDKOu1FEjIj0rUDsqjTNOsC9q2HQwxD5AY3nj+G9MT48NrYj3+w5xaQ3vic6QccbKKUs5e019LGINBKRBsA+YL+IzLzEOZ7Am8A4oAswRUS6lHCcH/AosLWiwasy1POGMX+HaV9Adioe74/gwXpL+ejufqRlFzDpjR/48seTro5SKVUDlLdqqIsx5jxwHfAtEI7Vc6gs/YHDxphYY0wesACYVMJxfwVeAHR+BGdoNxIe2ATtR8Pqpxm0fiorpjWnW6g/v/90N//35V5y8gtdHaVSyoXKmwi87HED1wFLjDH5wKVaHUOA4qOaTtrbfiIivYFWxphvKIOITBeRSBGJTEpKKmfI6icNAuHW+XDD+5AcQ8C8kXzSZSsPDAvj463HufmdzZw4m+XqKJVSLlLeRPBf4BjQANggIm2A81W5sd3W8DLwx0sda4x51xjT1xjTt1mzZlW5rfsSge43w0PboP3VeH73NH+Of4SPJzXmWEomE17byOr9Ca6OUinlAuVtLH7NGBNijBlvLHHAVZc4LR5oVex9qL3tAj8gAlgnIseAgcASbTB2Mr/mVungxg/gbCyDV1/HxkG7CGvqzb0fRvLC8oMUFBa5OkqlVDUqb2Oxv4i8fKF6RkRewiodlGU70F5EwkWkPjAZWHJhpzEmzRgTaIwJM8aEAVuAicaYyMo9iio3EWt6ioe2QoexNN78DxZ7P8Pvuxfw9roj3Pb+VhLTtclGKXdR3qqh2UA6cIv9cx74X1knGGMKgIeBFcABYKE9BuE5EZlY+ZCVwzQMglvnwc1z8Eg7zqOH72FFxBoOnUxgwmvfsyU2xdURKqWqgZRnpKmI7DLG9LzUturQt29fExmphQaHy0yGlU/C7k/IbdqR6TmPsDG1CTPHdGLGsLZ4eIirI1RKVYGI7DDGlFj1Xt4SQbaIXFHsgkOAbEcEp2qIBoFw/Tsw7XO8c5KZk/8Y/w7ZwCvL9zJ9XiRpWfmujlAp5STlTQT3A2+KyDG7YfcNYIbTolKu024UzNiItBnMDcnvsC3gWVJjNjPh9Y3sOakT1ylVF5W319BuY0wPoDvQ3RjTCxjh1MiU6/iHwLRFcNsiGnvmssjraR7Im8vUt9fx/sZYXeNAqTqmQiuUGWPO2yOMAf7ghHhUTdL+anhwM9Lrdm4rXMxq3ydZtuwr7pm7nZSMXFdHp5RykKosVamth+7Axx8mvga3L6a5L3zu/SzDjr7MTa+uZGOMjvJWqi6oSiLQ+gF3cvlVyIObkX738huPb/k6fwbb5szimS8ida4ipWq5MruPikg6JX/hC3CZMaaeswIrjXYfrQHid1K4/t94Rn9DXFEQs/1mcPsd02nXvJGrI1NKlaLS3UeNMX7GmEYl/Pi5IgmoGiKkN55TP4Y7viKwsR/PZv6V2Ddv4OPvIrUhWalaqCpVQ8rdtb2SBo9uJWPok1zlsYvrNoxnzb+nkhCtJTalahNNBKpqPL1oOHIm9R7eTELoGAZnfkfgR6OInvsQJifN1dEppcpBE4FyCAlsT/h98zg7YxerG0ygXexHpL3Yi/ORC6Ac05gopVxHE4FyqNDgYK7+03yW9J/HiQJ/Gi2dQfLb4yA5xtWhKaVKoYlAOZyHh3DdhGvxvn8tbzV4gPoJuyl4YyBZy56C3HRXh6eUuogmAuU0HVo25r4//INFgxfzddFgfLe9Rs7LPTA75kKRjj1QqqbQRKCcysvTg7vHDKDbwx/zWJNXiMpuinz9CPlvDYWjG1wdnlIKTQSqmrQL8uP53/6GXVcv5A9Fj5KUlABzr8V8MhVSjrg6PKXcWrkWpqlJdGRx7Xc8JYunPt9O17j5PFJ/Cd5SiAyYAUP/CL5NXR2eUnWSIxamUcphWgf4Mue+YbSa9BTjil7l84IhmM1vYl7qBJ9Mgf1LtMupUtVISwTKpU6nZfPEl/uIPxTJw403M9ZzO14Zp6BlD2jaFkY9C03auDpMpWq9skoEmgiUyxljWLL7FM8siSI7N58P2m9iUGEkHgn7oDAPut0MAx+EFhGuDlWpWkurhlSNJiJM6hnCqj8MZ1TXltx2cDDj059g98Tl0PtOiPoS3rkClvwWTv2o1UZKOZiWCFSNsyLqDM8uieJUWg439Arh8REtaBb5H4j8wCohBHaEbjdBmyHQehB46O8zSl2KVg2pWicrr4A31hzmvY2xeHl68JshYTw0MBDfmK9hz0I4vsk6sHEb6DAWhjwC/qGuDVqpGkwTgaq1YpMyeHlVNEv3nCak8WU8O7ErIzsHIdmpcHg17P0MYteDCAy4HwbMgEbBrg5bqRpHE4Gq9bYfO8v/fbGXmMQMrmgXyP+N70yXYHtFtHMnYM3fYM8CEE/oNc1KCs27uDZopWoQTQSqTsgrKGL+ljheWxNDWnY+N/YO5Q9XdyC48WXWAWdjYfNbsHOu1ZbQcTy0GwldrocGAa4NXikX00Sg6pS0rHzeWBvD3E1xiMBdQ8J4YPjlNPatbx2QmQLb34dt/4WsFKuUcFljuKyJlRyGPAoNAl37EEpVM5clAhEZC7wKeALvG2P+edH++4GHgEIgA5hujNlf1jU1EagLTqZm8fKqaL78MZ6G9etx9xXh3DM0nEY+XtYBxkDiAdj3OWSfhbR4q13B2w96TIagztDpGvANsNoYlKrDXJIIRMQTiAauBk4C24Epxb/oRaSRMea8/Xoi8KAxZmxZ19VEoC526Ew6r6yKZnnUGfwv82L6sLbcOTiMht71fn1w4kFY81eIWWlVH3l6g3hYpYQrZ2lCUHWWqxLBIOAZY8wY+/3jAMaY50s5fgpwhzFmXFnX1USgSrMvPo2XV0Wz5mAiTXy9mD7scu4Y1IYGJSWEwnxIOgQ/zoPUYxC9HPxbQXYqNA2H/tOh523g4Vntz6GUM7gqEdwEjDXG3Gu/vx0YYIx5+KLjHgL+ANQHRhhjfrWmoYhMB6YDtG7duk9cXJxTYlZ1w64T53hlVTTro5No2qA+U/q34s7BYQT5+ZR8QlGRlRCOfGdVE8XvgNO7oUV3GPN3CB9WvQ+glBPU6ERQ7PipwBhjzJ1lXVdLBKq8dsSl8va6w6w5mEj9eh7cNqAN0wa2ITywQdknGmO1K6x6Gs6fhID20GUihPYH74bQJNwaq6DVSKoWqS1VQx5AqjHGv6zraiJQFXU0OZM31hxm8a54CosM1/YI5rcj2tGhuV/ZJ+bnWCWFQ8sgdh2Yop/3eXhZPZFC+0H/+6DtVZoYVI3mqkRQD6uxeCQQj9VYPNUYE1XsmPYXqoJE5Frg6dICvUATgaqshPM5zN8Sx3sbY8nJL2Lw5QHcMSiMUZ2DqOd5ifmKMhIh7STknofkGDgfD5nJcOhbyEqGwCfSI7wAABkpSURBVA4QcaPVC0lnSVU1kCu7j44H/oPVfXS2MebvIvIcEGmMWSIirwKjgHwgFXi4eKIoiSYCVVVnM/NYsP048zfHcSoth5DGlzFtYBtu7deKpg3qV+xiBbnW7Kjb3oX4neDpZY1VCOwAPadAo1CoV8FrKuUEOqBMqRIUFBax+kACczfFsTk2Be96HkzsEcydg8OICCmzhrJkmcmw9PdwaheknQAM1PeD1gOgqBDqeUOv26HTBK1GUtVOE4FSl3DoTDpzNx/jy53xZOcX0rdNE+4cHMbYiBZ4XaraqCSJB+HkNjixDc7sscYqZCZbCSK4N3S9HoJ7QdgVmhRUtdBEoFQ5pWXl89mOE8zbEkdcShZBft7cNqANUwa0Kr37aXkVFcKP82HLW5B00NrW5gq4dR74Nq168EqVQROBUhVUVGRYF53InE1xbIhOwstTuLJjEJN6BjO6Swvq16vCYjjGWAPXor6A5f8HDZpBxPXQ7z67SkmgKB8OfmNVI7UaAKlxENTJYc+n3I8mAqWqIDYpg/lbjrNs72nOnM+haYP63NwnlEk9Q+jUwg8PjypU7cRtgo0vwZE1v+yeCoAAxuqqWpQPY56HQQ9aJQsd8awqSBOBUg5QWGTYGJPEgm0nWHUggcIiQ5sAX+4eEs5NfUJLnsqivE7vhqMbrYnwslPhXBz0vsuaEyk+0uq6Gr0cWg202h6atoWGzSF8ODTrYL1v0V3bG1SpNBEo5WCJ53NYH53Ex9uO8+Pxc/h4eTCyc3Ou7d6SKzsG4ePl4N/YC/NhxRPWus3dJ0NumjWb6qmdPx8TPtzqtto0HLrfqlNtq1/QRKCUE+08nsoXO0/y7d4zpGTm0dC7HqO7NOfaHsEMaRdYtfaEixXkWt1QL8hJg3PHreU6N70O+dlWkqjvZ82oOuhBqH+JKTWUW9BEoFQ1KCgsYnNsCl/vPsXyfWc4n1NAY18vxkW04NruwQxoG4BnVdoTyivpEHz3HBxcCg1bQP97rZlUfQNgx1xoOxwaBoG3P3g4MEmpGk0TgVLVLLegkI3RySzdc4qV+xPIyisksKE3E7q14NoewfRu3aRqjczlcXwLrP07HN1gjWPwDYDMpJ8bn1sPguYRcGAJ9L4DRjzp3HiUS2kiUMqFsvMKWXsoka93n2LNwURyC4oI9vfhmh7BXNO9Jd1C/BFnNvKmHIG9n0HCPugwzmp89vCCnR9a+5uEQdIBmPIpdCxzXShVi2kiUKqGyMgtYPX+BL7efYoNMUnkF1o9j8Z0bUGfNk24qmOQY9sUypKXBR71rG6rH1xttTVM/dSaVK9BIPiHQv2GcHI7NAqBsCHVE5dyCk0EStVA57LyWBF1hq93n2br0RTyCw1NfL24qmMQIzoHMbR9M/wv86qeYFKOwLtXWrOrlkQ8IKgrNA2DYY9Bi27aVbWW0USgVA2XV1DED0eSWbLrFOsOJZKalY+nh9AvrAmjOjdnXLeWhDS+zLlBpJ+xBrg1aWPNi5SXCTnnrNLAwaXWkp7xOyEvAwI7wlX/B50naoNzLaGJQKlapLDIsOtEKt8dSGTNwUQOnkkHoEeoP12CGzGhWzCDLw9wfmNzSTKSrIV6Nr8JyYessQs3zwEvX/Cq4lxMyqk0EShVi8WlZLJ0z2nWRydx4PR50nMKCGl8Gdd0b8nwjs3o06YJ3vWqecqJokKInA3LZgIGvBtB/+kw8EFoEFC9sahy0USgVB2Rk1/Iqv0JfL7zJBtjkiksMvh4edAvrCkD2wYwoVtLwi61JrMjHVwGJ7ZC6lHYvwQ861tdUcf8QxfkqWE0EShVB6Xn5LM19izfH05m85EUDiVYVUjhgQ0Y1TmIcd1a0qtVY+d2TS0u8aA1xfbOudaaCz6NrJ5I171jLc6jXEoTgVJu4ExaDkv3nGJDTDKbjySTX2gIaXwZ47u1oGerJgztEEgjn2rohbR3Eaz5K+RmQD0fOH8SAtpBx3FWm0KTMAhs7/w41C9oIlDKzaRl57N6fwLf7D3NRnu8gm99TwZfHkC/sKaM6tKcy5s1dF4AF75XctKswWyHvrVGOBflW9vDh0GnayF8qDVewdvPebEoQBOBUm4tO6+Q/afTWLQjni2xKRxNzgQgtMllDOvQjAndWtK2WQOa+/k4tydSznlIiILjm61RzalH7R1ilRgatbQanMOHWY3POk7BoTQRKKV+ciYth2V7rUFsG6KTyc4vBKBjcz+mD2vLqC7Nq2cgW8oRiN8BZ49Cwl44s9caqwDWWgu3LYKW3Z0fh5vQRKCUKlF2XiE/HE7m+Nks5m2J42hyJl6eQu/WTegf3pQxXVsQEeJfPcEU5kPsOqvUsOVtq7qo+62w+xNrjYUJL1ntC6pSNBEopS7JGMOuE+dYvu8Mm46kEHUqjSIDXVo2YliHZgzrEEjfNk2rZy6koxvgkynWKOZWA6weSY2C4Z6VVm8kVWGaCJRSFZaWnc+iHSdZGXWGHXGpFBRZDc4D2wYwrH0gV3dt4dxpL/JzIO2E1X5wdAPMvwEuHwG3fAgxq6BZJ2uZTlUumgiUUlWSkVvA5iMpbIhOYmNMEsdSsvD0EGuCvE5BDO/YzPlzIUXOhqW/Bx9/qzcSQLdbYOzzuixnOWgiUEo51LHkTD7edpxv9pwm/lw2AO2DGjK8QzOu7BhEv3AnTXuxdxGs/xcMmAHnT8EPr4J3Q2s21JFPQ2iJ33MKTQRKKScxxnAkKYN1h5JYH53E1tiz5BUWcZmXNWZhTEQLbugVQj1PJ7UrJB6A9S9Ys6aKJwyYDoeWQ6/brKku1E9clghEZCzwKuAJvG+M+edF+/8A3AsUAEnA3caYuLKuqYlAqZorK6+ALbEprDuUxLpDSRw/m0Vok8sY0SmIqzoGMbR9oHOSwund8L8JkJcOvoGQlWzNiNp/Ogx/DObfaI1sHvKo4+9dS7gkEYiIJxANXA2cBLYDU4wx+4sdcxWw1RiTJSIPAFcaY24t67qaCJSqHYwxrNyfwIJtx9kSe5bs/EL8L/OiR6vG3HtFOIMvD3BsUsjLtBqYfRpZ3U9PbLXWUfBvDWnHAYFhM62xCZePgPrVODlfDeCqRDAIeMYYM8Z+/ziAMeb5Uo7vBbxhjClzPTxNBErVPrkFhXYpwVpjIeF8rrUaW6cgRndpztD2zWjgXc+xNzXGWjfhu+eg281w9og1qhmg9WC4ayl4VPP03S7kqkRwEzDWGHOv/f52YIAx5uFSjn8DOGOM+VsJ+6YD0wFat27dJy6uzNojpVQNlpNfyHcHEll9IIE1BxNJy86nfj0PrmgXyJT+rRneoZljxyrknLfWXvbwgNx02L0Alv0JWg2EkD7Q9Xpo1c9x96uhanwiEJFpwMPAcGNMblnX1RKBUnVHQWERkXGprNqfwNI9p0g4n4ufdz2rpNC1OcM7NMPP0TOmGgMb/w0HvoakaCjMtaqMut5gdUOto11Ra3TVkIiMAl7HSgKJl7quJgKl6qb8wiI2RCexMiqB1QcSSMnMo76nB4PbBTC6SwtGdQkiyM/By2HmplurrO3+xHrv1QBGPGGttFbHJr1zVSKoh9VYPBKIx2osnmqMiSp2TC9gEVbJIaY819VEoFTdV1hk2Hk8lZVRZ1gRlcDxs1l4CFzXM4Rb+7Wib1hTPB05U2rMKkg/DQe/gejl0PRya2qLfvdCaB/H3ceFXNl9dDzwH6zuo7ONMX8XkeeASGPMEhFZDXQDTtunHDfGTCzrmpoIlHIvxhiiEzL4LPIE87bEkVtQRECD+lzdpTljIlow+PIAxw1eMwZ2zLESw7GNkHveGo8w6lnwbeqYe7iIDihTStUJGbkFrDuUyPJ9Z1h7MJHMvEL8vOsxvltLRnYOon94Uxr7Omit5NwMa7Dalres9RF6TgXxsKa46DAWWkQ45j7VRBOBUqrOyckvZNORZL7Zc4Zv950mK68QEbimezBT+rWif3hTx4xTSNgP3z5mdT318IKCbPCoB+NfhF53gKeDu706iSYCpVSdlltQyO4TaXx3IIEPN8eRnV9Iq6aXMalHCAPbBtA/3IHTZ2cmw6K74eh6awGd1gOt9oQa3sCsiUAp5TYycgvYEJ3EnB+OseN4KoVFhpb+Pgzv0Iwh7QIZG9ECr6qWFIoKrXWY931urbJ2Lg46XWOtvzz0j9AwyDEP40CaCJRSbikjt4BNh5OZv/U4++LTOJuZR5CfNzf3DeW6niG0b+5X9ZsYA4sfhD2f/tyGMPljaD2g6td2IE0ESim3V1RkWB+dxIebj7E+OokiA71aN2ZK/9aM6BREYEPvyl/cGMjPgnMnYMFUOHfc6m2UfhoyEuDa11zeuKyJQCmliklKz2XJ7lN8uPkYcSlZiEC/sKaMj2jB0A7NaBvYAKlsfX/WWfjmj7B/Mfi3goIcazK8QQ9BfV/odTukHIGGzaBxa4c+V1k0ESilVAmMMUSdOs/qAwks3XOaw4kZAHRq4ce0gW0Y2TmIlv6VXHmtqMia3+jccfjyAYj73tru4QVF+YDATbMh4gbHPMwlaCJQSqlyOJ6SxfroRD7cHEdMYgYeAkPaBTK6S3Ou7tKC5o28K1dSMMaqIkrcD9s/gM4TYfv71vub50D7qx3+LBfTRKCUUhVwYeW1L3bGszzqDLFJmQCENL6M3wwJY1LPEJr5VaFNAaylNuffBIlRMPpvMOhhp3Y/1USglFJVsC8+jR1xqXyz5zTbjp3F00Po26YJPVs35vpeIXRq0ahyF87Phi9nwP6voHk3aybUa16BsCsc+wBoIlBKKYeJSUjnix/j2XQ4mf2nz5NfaLiqYzPGRrTgqk6VmCG1qBAiZ1szoKafsVZaG/wwDLgfvB3QvdWmiUAppZwgNTOPOZuOsTDyBKfTcvD0EMZ2bcH4bi25smMlVl1LjYMv7oMT26B5BNz2GTRq6ZBYNREopZQTGWM4eCadL3ae5POd8ZzNzKN+PQ+GtQ9kdNcWjOrcnKYNKjAZ3uHVsPBO8GlsNSY7YAU1TQRKKVVNLqy6tiLqDCujEog/l42HwODLA3noqnYMbNu0fD2PTu+GT6bC+XjoNAG8fKH37RA+rFJxaSJQSikXuDBOYUXUGRZGniDhfC5hAb70bt2Eu68IJyLEv+wL5KbDxpdh51xr9bSRf4HuN1cqFk0ESinlYtl5hSzeFc93BxLYdvQs53MKmNC9JX8a3ZHwwAZOv78mAqWUqkHO5+Tz3oZY3t94lJyCQroGN+K+oW25tnswHo5cgrMYTQRKKVUDJabnsGDbCZbtPc3BM+lEhDRi2oA2jItoib+vl0PvpYlAKaVqsKIiw+Jd8byx5jCxyZl4eQrDOzRjYs8Qxjli/QTKTgS1Y401pZSqwzw8hBt6h3J9rxD2xZ/nq13xLN1zmtUHEunQvCF3Dwnnmh7BNKzouIRy0hKBUkrVQEVFhlUHEnhh+UFikzJp5FOPv14XwaSeIZW6npYIlFKqlvHwEMZ0bcHoLs358cQ53t8YS+umvk65lyYCpZSqwUSE3q2b8NZtfZx2j6q3QCillKrVNBEopZSb00SglFJuThOBUkq5OacmAhEZKyKHROSwiMwqYf8wEdkpIgUicpMzY1FKKVUypyUCEfEE3gTGAV2AKSLS5aLDjgN3AR87Kw6llFJlc2b30f7AYWNMLICILAAmAfsvHGCMOWbvK3JiHEoppcrgzKqhEOBEsfcn7W0VJiLTRSRSRCKTkpIcEpxSSilLrRhQZox5F3gXQESSRCSukpcKBJIdFphr6bPUTPosNZM+C7QpbYczE0E80KrY+1B7W5UYY5pV9lwRiSxtro3aRp+lZtJnqZn0WcrmzKqh7UB7EQkXkfrAZGCJE++nlFKqEpyWCIwxBcDDwArgALDQGBMlIs+JyEQAEeknIieBm4H/ikiUs+JRSilVMqe2ERhjlgHLLtr2l2Kvt2NVGVWXd6vxXs6mz1Iz6bPUTPosZah16xEopZRyLJ1iQiml3JwmAqWUcnNukwguNe9RTScix0Rkr4jsEpFIe1tTEVklIjH2n01cHWdJRGS2iCSKyL5i20qMXSyv2Z/THhHp7brIf62UZ3lGROLtz2aXiIwvtu9x+1kOicgY10T9ayLSSkTWish+EYkSkUft7bXucynjWWrj5+IjIttEZLf9LM/a28NFZKsd86d2T0xExNt+f9jeH1apGxtj6vwP4AkcAdoC9YHdQBdXx1XBZzgGBF607V/ALPv1LOAFV8dZSuzDgN7AvkvFDowHvgUEGAhsdXX85XiWZ4A/lXBsF/vfmjcQbv8b9HT1M9ixtQR626/9gGg73lr3uZTxLLXxcxGgof3aC9hq/30vBCbb298BHrBfPwi8Y7+eDHxamfu6S4ngp3mPjDF5wIV5j2q7ScBc+/Vc4DoXxlIqY8wG4OxFm0uLfRLwobFsARqLSMvqifTSSnmW0kwCFhhjco0xR4HDWP8WXc4Yc9oYs9N+nY7VxTuEWvi5lPEspanJn4sxxmTYb73sHwOMABbZ2y/+XC58XouAkSIiFb2vuyQCh8175EIGWCkiO0Rkur2tuTHmtP36DNDcNaFVSmmx19bP6mG7ymR2sSq6WvEsdnVCL6zfPmv153LRs0At/FxExFNEdgGJwCqsEss5Y43Ngl/G+9Oz2PvTgICK3tNdEkFdcIUxpjfWtN4Piciw4juNVTaslX2Ba3PstreBy4GewGngJdeGU34i0hD4HPidMeZ88X217XMp4Vlq5edijCk0xvTEGmPVH+jk7Hu6SyJwyrxH1ckYE2//mQh8ifUPJOFC8dz+M9F1EVZYabHXus/KGJNg/+ctAt7j52qGGv0sIuKF9cX5kTHmC3tzrfxcSnqW2vq5XGCMOQesBQZhVcVdGABcPN6fnsXe7w+kVPRe7pIIavW8RyLSQET8LrwGRgP7sJ7hTvuwO4GvXBNhpZQW+xLgDruXykAgrVhVRY10UV359VifDVjPMtnu2REOtAe2VXd8JbHrkT8ADhhjXi62q9Z9LqU9Sy39XJqJSGP79WXA1VhtHmuBC6s4Xvy5XPi8bgLW2CW5inF1K3l1/WD1eojGqm97wtXxVDD2tli9HHYDURfix6oL/A6IAVYDTV0daynxf4JVNM/Hqt+8p7TYsXpNvGl/TnuBvq6OvxzPMs+OdY/9H7NlseOfsJ/lEDDO1fEXi+sKrGqfPcAu+2d8bfxcyniW2vi5dAd+tGPeB/zF3t4WK1kdBj4DvO3tPvb7w/b+tpW5r04xoZRSbs5dqoaUUkqVQhOBUkq5OU0ESinl5jQRKKWUm9NEoJRSbk4TgaqxRMSIyEvF3v9JRJ5x0LXniMhNlz6yyve5WUQOiMhaZ9/rovveJSJvVOc9Ve2liUDVZLnADSIS6OpAiis2wrM87gHuM8Zc5ax4lKoqTQSqJivAWp/19xfvuPg3ehHJsP+8UkTWi8hXIhIrIv8UkdvsOd73isjlxS4zSkQiRSRaRK6xz/cUkRdFZLs9WdmMYtfdKCJLgP0lxDPFvv4+EXnB3vYXrMFOH4jIiyWcM7PYfS7MOx8mIgdF5CO7JLFIRHztfSNF5Ef7PrNFxNve3k9ENok1h/22C6PQgWARWS7W2gL/KvZ8c+w494rIr/5ulftx6uL1SjnAm8CeC19k5dQD6Iw1XXQs8L4xpr9YC5b8FvidfVwY1vwzlwNrRaQdcAfW9An97C/aH0RkpX18byDCWFMX/0REgoEXgD5AKtYssdcZY54TkRFYc+JHXnTOaKypDfpjjdpdYk8keBzoCNxjjPlBRGYDD9rVPHOAkcaYaBH5EHhARN4CPgVuNcZsF5FGQLZ9m55YM3HmAodE5HUgCAgxxkTYcTSuwN+rqqO0RKBqNGPNIvkh8EgFTtturDnqc7GmEbjwRb4X68v/goXGmCJjTAxWwuiENY/THWJNA7wVa8qF9vbx2y5OArZ+wDpjTJKxpgL+CGsBm7KMtn9+BHba975wnxPGmB/s1/OxShUdgaPGmGh7+1z7Hh2B08aY7WD9fZmfpyv+zhiTZozJwSrFtLGfs62IvC4iY4FfzDiq3JOWCFRt8B+sL8v/FdtWgP2LjIh4YK08d0FusddFxd4X8ct/8xfPr2Kwfjv/rTFmRfEdInIlkFm58EskwPPGmP9edJ+wUuKqjOJ/D4VAPWNMqoj0AMYA9wO3AHdX8vqqjtASgarxjDFnsZbqu6fY5mNYVTEAE7FWcqqom0XEw243aIs1AdkKrCoXLwAR6WDP+FqWbcBwEQkUEU9gCrD+EuesAO4Waw59RCRERILsfa1FZJD9eirwvR1bmF19BXC7fY9DQEsR6Wdfx6+sxmy74d3DGPM58CRWdZdyc1oiULXFS8DDxd6/B3wlIruB5VTut/XjWF/ijYD7jTE5IvI+VvXRTnt64yQusQSoMea0iMzCmipYgG+MMWVOCW6MWSkinYHN1m3IAKZh/eZ+CGvxodlYVTpv27H9BvjM/qLfjrVWbZ6I3Aq8bk9bnA2MKuPWIcD/7FIUwONlxancg84+qlQNYlcNLb3QmKtUddCqIaWUcnNaIlBKKTenJQKllHJzmgiUUsrNaSJQSik3p4lAKaXcnCYCpZRyc/8P6LUZZREy4kMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXPkBbXs7Uqa"
      },
      "source": [
        "### b) Analyzing model performance (5 points)\n",
        "What was your model's final prediction accuracy on the test set? Explain the pattern/trend you have observed in the previous two plots in your own words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW4NHPHi78Fu"
      },
      "source": [
        "The final prediction accuracy is 0.9040.\\\n",
        "As the number of epochs increases, the training and test accuracy gradually increases and the loss decrease.\\\n",
        "The most significant change happens between epoch 100 - 200."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-UNwaIt_HgR"
      },
      "source": [
        "### c) Decision Boundary (5 points)\n",
        "Plot the decisin boundary of the network you built (using the code below) and explain what you observe and why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYDz8YyPciwW"
      },
      "source": [
        "The following code will allow us to visualize our deep neural network's decision boundary. Let's observe.\n",
        "\n",
        "This will take a moment to construct the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs6FGaHKciwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9de0df33-9afc-45fc-d557-c71ec3b0fc37"
      },
      "source": [
        "#\n",
        "# This code is substantively from https://rohitmidha23.github.io/Neural-Network-Decision-Boundary/\n",
        "#\n",
        "def plot_decision_boundary(X, y, model, steps=1000, cmap='bwr'):\n",
        "    # The following allows you to adjust the plot size\n",
        "    rcParams['figure.figsize'] = 8, 6  # 8 inches by 6 inches\n",
        "    cmap = plt.get_cmap(cmap)\n",
        "\n",
        "    # Define region of interest by data limits\n",
        "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "    x_span = np.linspace(xmin, xmax, steps)\n",
        "    y_span = np.linspace(ymin, ymax, steps)\n",
        "    xx, yy = np.meshgrid(x_span, y_span)\n",
        "\n",
        "    # Make predictions across region of interest\n",
        "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Plot decision boundary in region of interest\n",
        "    z = labels.reshape(xx.shape)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
        "\n",
        "    # Get predicted labels on training data and plot\n",
        "    train_labels = model.predict(X)\n",
        "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "plot_decision_boundary(test_data, test_labels, model) \n",
        "# Reset figure size back to default.\n",
        "rcParams['figure.figsize'] = 6, 4"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLtd20xC2Mj3"
      },
      "source": [
        "The decision boundary is not perfect, but mostly accuracy. There are some part of blue and red crosing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak3Y2clPLZpv"
      },
      "source": [
        "## Problem 4 - Fish Data revisited "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wiXAk_ILy2N"
      },
      "source": [
        "We will revist the \"Fish\" dataset and train a regression neural network on the features \"Length1\", \"Length2\", \"Length3\",\t\"Height\", and \"Width\" to predict Weight. Run or fill in the following cells and answer written response questions for each section. Begin by downloading \"Fish.csv\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMy-21iKABVc"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTvM0_JzABVc"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLDSqS7_JD0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "1912a727-fc74-46f4-ce6c-05a553553210"
      },
      "source": [
        "# Download the Fish data\n",
        "downloaded = drive.CreateFile({'id':\"1AtMi-xCejVlhYS5qjgjjW4gH-TLuWJjC\"})\n",
        "downloaded.GetContentFile('Fish.csv')  \n",
        "\n",
        "# Create pandas dataframe\n",
        "fish_data = pd.read_csv('Fish.csv')\n",
        "\n",
        "# Delete any rows for which there is a measurement of 0.0.\n",
        "fish_data = fish_data.drop( np.where(fish_data==0)[0] )\n",
        "fish_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>242.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>25.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.5200</td>\n",
              "      <td>4.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>290.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>31.2</td>\n",
              "      <td>12.4800</td>\n",
              "      <td>4.3056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>340.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>26.5</td>\n",
              "      <td>31.1</td>\n",
              "      <td>12.3778</td>\n",
              "      <td>4.6961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>363.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.5</td>\n",
              "      <td>12.7300</td>\n",
              "      <td>4.4555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>430.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>12.4440</td>\n",
              "      <td>5.1340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
              "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
              "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
              "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
              "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
              "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IZwN2j4yIaX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "b0a92c1c-4bc4-4f92-c47a-2fe2d2fc8188"
      },
      "source": [
        "fish_data.describe()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>400.847468</td>\n",
              "      <td>26.293038</td>\n",
              "      <td>28.465823</td>\n",
              "      <td>31.280380</td>\n",
              "      <td>8.986790</td>\n",
              "      <td>4.424232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>357.697796</td>\n",
              "      <td>10.011427</td>\n",
              "      <td>10.731707</td>\n",
              "      <td>11.627605</td>\n",
              "      <td>4.295191</td>\n",
              "      <td>1.689010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.900000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>1.728400</td>\n",
              "      <td>1.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>121.250000</td>\n",
              "      <td>19.150000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.200000</td>\n",
              "      <td>5.940600</td>\n",
              "      <td>3.398650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>281.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>29.700000</td>\n",
              "      <td>7.789000</td>\n",
              "      <td>4.277050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>650.000000</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>35.750000</td>\n",
              "      <td>39.675000</td>\n",
              "      <td>12.371850</td>\n",
              "      <td>5.586750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1650.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>63.400000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>18.957000</td>\n",
              "      <td>8.142000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Weight     Length1     Length2     Length3      Height       Width\n",
              "count   158.000000  158.000000  158.000000  158.000000  158.000000  158.000000\n",
              "mean    400.847468   26.293038   28.465823   31.280380    8.986790    4.424232\n",
              "std     357.697796   10.011427   10.731707   11.627605    4.295191    1.689010\n",
              "min       5.900000    7.500000    8.400000    8.800000    1.728400    1.047600\n",
              "25%     121.250000   19.150000   21.000000   23.200000    5.940600    3.398650\n",
              "50%     281.500000   25.300000   27.400000   29.700000    7.789000    4.277050\n",
              "75%     650.000000   32.700000   35.750000   39.675000   12.371850    5.586750\n",
              "max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH5esQZKdLNX"
      },
      "source": [
        "### a) Data Preprocessing (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yGF14XXidKS"
      },
      "source": [
        "Recall from the previous lectures and class excercises that it is especially important to normalize data for neural networks.\n",
        "\n",
        "In order to normalize our data to $[0,1]$ we use the equation:\n",
        "\n",
        "$$x_{norm}=\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
        "\n",
        "Normalize the \"Length1\", \"Length2\", \"Length3\",\t\"Height\", and \"Width\", and \"Weight\" columns. We often need to normalize the target variables in a neural network regression task to limit exploding gradients (why might exploding gradients be more prevalent in a regression task?).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA98AUX0kukU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "e989fcef-1ad4-4c4d-9938-41d4e31b06dd"
      },
      "source": [
        "# Get fish max and min weight, we'll need these later.\n",
        "fish_max = fish_data[\"Weight\"].max()\n",
        "fish_min = fish_data[\"Weight\"].min()\n",
        "\n",
        "# Normalize the \"Length1\", \"Length2\", \"Length3\", \"Height\", \"Width\", \"Weight\" columns of fish_data.\n",
        "### YOUR CODE HERE ###\n",
        "for col in fish_data:\n",
        "    if fish_data[col].dtype != object:\n",
        "        fish_data[col] = (fish_data[col] - fish_data[col].min()) / (fish_data[col].max() - fish_data[col].min())\n",
        "\n",
        "# Take a look at the new age column.\n",
        "fish_data.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.143604</td>\n",
              "      <td>0.304854</td>\n",
              "      <td>0.309091</td>\n",
              "      <td>0.358108</td>\n",
              "      <td>0.568334</td>\n",
              "      <td>0.418978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.320388</td>\n",
              "      <td>0.325455</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.624055</td>\n",
              "      <td>0.459235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.203211</td>\n",
              "      <td>0.318447</td>\n",
              "      <td>0.329091</td>\n",
              "      <td>0.376689</td>\n",
              "      <td>0.618123</td>\n",
              "      <td>0.514279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.217201</td>\n",
              "      <td>0.365049</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.417230</td>\n",
              "      <td>0.638566</td>\n",
              "      <td>0.480365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.368932</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.621966</td>\n",
              "      <td>0.576004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species    Weight   Length1   Length2   Length3    Height     Width\n",
              "0   Bream  0.143604  0.304854  0.309091  0.358108  0.568334  0.418978\n",
              "1   Bream  0.172800  0.320388  0.325455  0.378378  0.624055  0.459235\n",
              "2   Bream  0.203211  0.318447  0.329091  0.376689  0.618123  0.514279\n",
              "3   Bream  0.217201  0.365049  0.374545  0.417230  0.638566  0.480365\n",
              "4   Bream  0.257953  0.368932  0.374545  0.425676  0.621966  0.576004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCtWDzuDoI2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13c235d-60f5-4417-cf71-a9e30316eb4f"
      },
      "source": [
        "# split the data into features X_fish and target variable y_fish.\n",
        "y_fish = fish_data.iloc[:, 1] # Get Fish Weights\n",
        "X_fish = fish_data.drop(columns=['Weight']) # Get Fish measurements plus species\n",
        "X_fish = X_fish.drop(columns=['Species']) # Drop the Fish Species for now\n",
        "\n",
        "# print X.head(), you should have 5 features for each sample\n",
        "print(\"X_fish.head():\")\n",
        "print(X_fish.head())\n",
        "\n",
        "# print y.head(), you should have one label for each sample\n",
        "print(\"\\ny_fish.head()\")\n",
        "print(y_fish.head())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_fish.head():\n",
            "    Length1   Length2   Length3    Height     Width\n",
            "0  0.304854  0.309091  0.358108  0.568334  0.418978\n",
            "1  0.320388  0.325455  0.378378  0.624055  0.459235\n",
            "2  0.318447  0.329091  0.376689  0.618123  0.514279\n",
            "3  0.365049  0.374545  0.417230  0.638566  0.480365\n",
            "4  0.368932  0.374545  0.425676  0.621966  0.576004\n",
            "\n",
            "y_fish.head()\n",
            "0    0.143604\n",
            "1    0.172800\n",
            "2    0.203211\n",
            "3    0.217201\n",
            "4    0.257953\n",
            "Name: Weight, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr_6JsI5oyRl"
      },
      "source": [
        "# Split the X_fish and y_fish into 60/20 training/test split using train_test_split()\n",
        "### YOUR CODE HERE ###\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fish, y_fish, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSCV-qq2oUyk"
      },
      "source": [
        "### b) Neural Network Training (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpeCVuNvK4I"
      },
      "source": [
        "In the cell below, build a neural network 4 layers as follows:\n",
        "* **input layer** of shape 5\n",
        "* **dense layer** with 10 neurons, and sigmoid activation\n",
        "* **dense layer** with 10 neurons, and sigmoid activation\n",
        "* **dense layer** with 5 neurons, and sigmoid activation\n",
        "* **dense layer** with 1 neuron, and linear activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pno8UsUpSmR"
      },
      "source": [
        "def build_model1():\n",
        "### YOUR CODE HERE ###\n",
        "    input_layer = Input(shape=(5))\n",
        "    x = Dense(10, activation='sigmoid')(input_layer)\n",
        "    x = Dense(10, activation='sigmoid')(x)\n",
        "    x = Dense(5, activation='sigmoid')(x)\n",
        "    x = Dense(1, activation='linear')(x) \n",
        "    return Model(input_layer, x)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUJtdeuqkxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b84bc8-0b52-4487-9be7-d119cc08f9ca"
      },
      "source": [
        "# Get model summary\n",
        "model = build_model1()\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 5)]               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 231\n",
            "Trainable params: 231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtfFKunWp0jI"
      },
      "source": [
        "Declare an SGD optimizer with learning rate of 0.05, weight decay of 1e-6 and momentum of 0.9. Compile your model Use mean_squared_error as the loss and metrics with the sgd optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok2LdYJfpr05"
      },
      "source": [
        "# Declare the optimizer\n",
        "### YOUR CODE HERE ###\n",
        "sgd = SGD(learning_rate=0.05, decay=1e-6, momentum=0.9)\n",
        "\n",
        "# Compile model\n",
        "### YOUR CODE HERE ###\n",
        "model.compile(optimizer=sgd ,loss='mean_squared_error',metrics=['mean_squared_error'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVlE8NkXOAv"
      },
      "source": [
        "Perform model fitting using the training set. Train for 2500 epochs with a batch size of 128 and a validation split of 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6j3uRfqN-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44c0ec8-8fc0-42e5-9b80-00fdfe08550c"
      },
      "source": [
        "# Fit model\n",
        "history = model.fit(X_train,\n",
        "                    y_train, \n",
        "                    epochs=2500, \n",
        "                    batch_size=128, \n",
        "                    validation_split=0.25)### YOUR CODE HERE ###\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/2500\n",
            "1/1 [==============================] - 1s 537ms/step - loss: 0.0890 - mean_squared_error: 0.0890 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
            "Epoch 2/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
            "Epoch 3/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0430 - mean_squared_error: 0.0430 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
            "Epoch 4/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0698 - val_mean_squared_error: 0.0698\n",
            "Epoch 5/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - val_loss: 0.0846 - val_mean_squared_error: 0.0846\n",
            "Epoch 6/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0836 - val_mean_squared_error: 0.0836\n",
            "Epoch 7/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0649 - mean_squared_error: 0.0649 - val_loss: 0.0691 - val_mean_squared_error: 0.0691\n",
            "Epoch 8/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0522 - mean_squared_error: 0.0522 - val_loss: 0.0543 - val_mean_squared_error: 0.0543\n",
            "Epoch 9/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 10/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
            "Epoch 11/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0463 - mean_squared_error: 0.0463 - val_loss: 0.0598 - val_mean_squared_error: 0.0598\n",
            "Epoch 12/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0530 - mean_squared_error: 0.0530 - val_loss: 0.0592 - val_mean_squared_error: 0.0592\n",
            "Epoch 13/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0522 - mean_squared_error: 0.0522 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
            "Epoch 14/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
            "Epoch 15/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 16/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
            "Epoch 17/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
            "Epoch 18/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0610 - val_mean_squared_error: 0.0610\n",
            "Epoch 19/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0455 - mean_squared_error: 0.0455 - val_loss: 0.0563 - val_mean_squared_error: 0.0563\n",
            "Epoch 20/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 21/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 22/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
            "Epoch 23/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 24/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0423 - mean_squared_error: 0.0423 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
            "Epoch 25/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
            "Epoch 26/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 27/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 28/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
            "Epoch 29/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0542 - val_mean_squared_error: 0.0542\n",
            "Epoch 30/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
            "Epoch 31/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
            "Epoch 32/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
            "Epoch 33/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 34/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 35/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 36/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 37/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 38/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 39/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
            "Epoch 40/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
            "Epoch 41/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 42/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
            "Epoch 43/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
            "Epoch 44/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
            "Epoch 45/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 46/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 47/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 48/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 49/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 50/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 51/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 52/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
            "Epoch 53/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
            "Epoch 54/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
            "Epoch 55/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
            "Epoch 56/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 57/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 58/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 59/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 60/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 61/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 62/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 63/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 64/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 65/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
            "Epoch 66/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
            "Epoch 67/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
            "Epoch 68/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 69/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 70/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 71/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 72/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 73/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 74/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 75/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 76/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 77/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 78/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 79/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 80/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 81/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 82/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 83/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 84/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 85/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 86/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 87/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 88/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 89/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 90/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 91/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 92/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 93/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 94/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 95/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 96/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 97/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 98/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 99/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 100/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 101/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 102/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 103/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 104/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 105/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 106/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 107/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 108/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 109/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 110/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 111/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 112/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 113/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 114/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 115/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 116/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 117/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 118/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 119/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 120/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 121/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 122/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 123/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 124/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 125/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 126/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 127/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 128/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 129/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 130/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 131/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 132/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 133/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 134/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 135/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 136/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 137/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 138/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 139/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 140/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 141/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 142/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 143/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 144/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 145/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 146/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 147/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 148/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 149/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 150/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 151/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 152/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 153/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 154/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 155/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 156/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 157/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 158/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 159/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 160/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 161/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 162/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 163/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 164/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 165/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 166/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 167/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 168/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 169/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 170/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 171/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 172/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 173/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 174/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 175/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 176/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 177/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 178/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 179/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 180/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 181/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 182/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 183/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 184/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 185/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 186/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 187/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 188/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 189/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 190/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 191/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 192/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 193/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 194/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 195/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 196/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 197/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 198/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 199/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 200/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 201/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 202/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 203/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 204/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 205/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 206/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 207/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 208/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 209/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 210/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 211/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 212/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 213/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 214/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 215/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 216/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
            "Epoch 217/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
            "Epoch 218/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
            "Epoch 219/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
            "Epoch 220/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 221/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 222/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 223/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 224/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 225/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 226/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 227/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 228/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 229/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 230/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 231/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 232/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
            "Epoch 233/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
            "Epoch 234/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
            "Epoch 235/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
            "Epoch 236/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
            "Epoch 237/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
            "Epoch 238/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
            "Epoch 239/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
            "Epoch 240/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 241/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 242/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 243/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 244/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
            "Epoch 245/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
            "Epoch 246/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
            "Epoch 247/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 248/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 249/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 250/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 251/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 252/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 253/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 254/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 255/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 256/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 257/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 258/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 259/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 260/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 261/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 262/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 263/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 264/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
            "Epoch 265/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
            "Epoch 266/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
            "Epoch 267/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 268/2500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 269/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 270/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 271/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 272/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 273/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 274/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 275/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 276/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 277/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 278/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 279/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 280/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 281/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 282/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 283/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 284/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 285/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 286/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 287/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 288/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 289/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 290/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 291/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 292/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 293/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 294/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 295/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 296/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 297/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 298/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 299/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 300/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 301/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 302/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 303/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 304/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 305/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 306/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 307/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 308/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 309/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 310/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 311/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 312/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 313/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 314/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 315/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 316/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 317/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 318/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 319/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 320/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 321/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 322/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 323/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 324/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 325/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 326/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 327/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 328/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 329/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 330/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 331/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 332/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 333/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
            "Epoch 334/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 335/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 336/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 337/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 338/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 339/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 340/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
            "Epoch 341/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 342/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 343/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
            "Epoch 344/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
            "Epoch 345/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
            "Epoch 346/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 347/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 348/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
            "Epoch 349/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
            "Epoch 350/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
            "Epoch 351/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
            "Epoch 352/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
            "Epoch 353/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
            "Epoch 354/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
            "Epoch 355/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
            "Epoch 356/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
            "Epoch 357/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0416 - val_mean_squared_error: 0.0416\n",
            "Epoch 358/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0416 - val_mean_squared_error: 0.0416\n",
            "Epoch 359/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
            "Epoch 360/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
            "Epoch 361/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
            "Epoch 362/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
            "Epoch 363/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0412 - val_mean_squared_error: 0.0412\n",
            "Epoch 364/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0412 - val_mean_squared_error: 0.0412\n",
            "Epoch 365/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
            "Epoch 366/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0410 - val_mean_squared_error: 0.0410\n",
            "Epoch 367/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
            "Epoch 368/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
            "Epoch 369/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
            "Epoch 370/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0407 - val_mean_squared_error: 0.0407\n",
            "Epoch 371/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
            "Epoch 372/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
            "Epoch 373/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
            "Epoch 374/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0404 - val_mean_squared_error: 0.0404\n",
            "Epoch 375/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
            "Epoch 376/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
            "Epoch 377/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0402 - val_mean_squared_error: 0.0402\n",
            "Epoch 378/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
            "Epoch 379/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
            "Epoch 380/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0303 - mean_squared_error: 0.0303 - val_loss: 0.0399 - val_mean_squared_error: 0.0399\n",
            "Epoch 381/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0399 - val_mean_squared_error: 0.0399\n",
            "Epoch 382/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
            "Epoch 383/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
            "Epoch 384/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0396 - val_mean_squared_error: 0.0396\n",
            "Epoch 385/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
            "Epoch 386/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
            "Epoch 387/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
            "Epoch 388/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
            "Epoch 389/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
            "Epoch 390/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
            "Epoch 391/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
            "Epoch 392/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0389 - val_mean_squared_error: 0.0389\n",
            "Epoch 393/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0388 - val_mean_squared_error: 0.0388\n",
            "Epoch 394/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.0387 - val_mean_squared_error: 0.0387\n",
            "Epoch 395/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
            "Epoch 396/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
            "Epoch 397/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
            "Epoch 398/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
            "Epoch 399/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
            "Epoch 400/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
            "Epoch 401/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
            "Epoch 402/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
            "Epoch 403/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
            "Epoch 404/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 405/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
            "Epoch 406/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
            "Epoch 407/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 408/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
            "Epoch 409/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
            "Epoch 410/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
            "Epoch 411/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
            "Epoch 412/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
            "Epoch 413/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
            "Epoch 414/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
            "Epoch 415/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
            "Epoch 416/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
            "Epoch 417/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0364 - val_mean_squared_error: 0.0364\n",
            "Epoch 418/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0275 - mean_squared_error: 0.0275 - val_loss: 0.0363 - val_mean_squared_error: 0.0363\n",
            "Epoch 419/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
            "Epoch 420/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
            "Epoch 421/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
            "Epoch 422/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
            "Epoch 423/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
            "Epoch 424/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
            "Epoch 425/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
            "Epoch 426/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
            "Epoch 427/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
            "Epoch 428/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
            "Epoch 429/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
            "Epoch 430/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
            "Epoch 431/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
            "Epoch 432/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
            "Epoch 433/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
            "Epoch 434/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
            "Epoch 435/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0343 - val_mean_squared_error: 0.0343\n",
            "Epoch 436/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0342 - val_mean_squared_error: 0.0342\n",
            "Epoch 437/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
            "Epoch 438/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0339 - val_mean_squared_error: 0.0339\n",
            "Epoch 439/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0338 - val_mean_squared_error: 0.0338\n",
            "Epoch 440/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0337 - val_mean_squared_error: 0.0337\n",
            "Epoch 441/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
            "Epoch 442/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
            "Epoch 443/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
            "Epoch 444/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
            "Epoch 445/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0330 - val_mean_squared_error: 0.0330\n",
            "Epoch 446/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0329 - val_mean_squared_error: 0.0329\n",
            "Epoch 447/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
            "Epoch 448/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0326 - val_mean_squared_error: 0.0326\n",
            "Epoch 449/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
            "Epoch 450/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
            "Epoch 451/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
            "Epoch 452/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
            "Epoch 453/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
            "Epoch 454/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0317 - val_mean_squared_error: 0.0317\n",
            "Epoch 455/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
            "Epoch 456/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0314 - val_mean_squared_error: 0.0314\n",
            "Epoch 457/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
            "Epoch 458/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0312 - val_mean_squared_error: 0.0312\n",
            "Epoch 459/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0310 - val_mean_squared_error: 0.0310\n",
            "Epoch 460/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
            "Epoch 461/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0307 - val_mean_squared_error: 0.0307\n",
            "Epoch 462/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
            "Epoch 463/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
            "Epoch 464/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
            "Epoch 465/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0301 - val_mean_squared_error: 0.0301\n",
            "Epoch 466/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
            "Epoch 467/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
            "Epoch 468/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
            "Epoch 469/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
            "Epoch 470/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0293 - val_mean_squared_error: 0.0293\n",
            "Epoch 471/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
            "Epoch 472/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
            "Epoch 473/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
            "Epoch 474/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
            "Epoch 475/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
            "Epoch 476/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
            "Epoch 477/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
            "Epoch 478/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0280 - val_mean_squared_error: 0.0280\n",
            "Epoch 479/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
            "Epoch 480/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
            "Epoch 481/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
            "Epoch 482/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0274 - val_mean_squared_error: 0.0274\n",
            "Epoch 483/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
            "Epoch 484/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
            "Epoch 485/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0269 - val_mean_squared_error: 0.0269\n",
            "Epoch 486/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
            "Epoch 487/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0265 - val_mean_squared_error: 0.0265\n",
            "Epoch 488/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
            "Epoch 489/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n",
            "Epoch 490/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
            "Epoch 491/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
            "Epoch 492/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
            "Epoch 493/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
            "Epoch 494/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
            "Epoch 495/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0251 - val_mean_squared_error: 0.0251\n",
            "Epoch 496/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0250 - val_mean_squared_error: 0.0250\n",
            "Epoch 497/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0248 - val_mean_squared_error: 0.0248\n",
            "Epoch 498/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\n",
            "Epoch 499/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
            "Epoch 500/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
            "Epoch 501/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0241 - val_mean_squared_error: 0.0241\n",
            "Epoch 502/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0239 - val_mean_squared_error: 0.0239\n",
            "Epoch 503/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
            "Epoch 504/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
            "Epoch 505/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
            "Epoch 506/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 507/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
            "Epoch 508/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
            "Epoch 509/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
            "Epoch 510/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
            "Epoch 511/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
            "Epoch 512/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
            "Epoch 513/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
            "Epoch 514/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
            "Epoch 515/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
            "Epoch 516/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
            "Epoch 517/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
            "Epoch 518/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
            "Epoch 519/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
            "Epoch 520/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
            "Epoch 521/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
            "Epoch 522/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
            "Epoch 523/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
            "Epoch 524/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
            "Epoch 525/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
            "Epoch 526/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
            "Epoch 527/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
            "Epoch 528/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
            "Epoch 529/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
            "Epoch 530/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
            "Epoch 531/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
            "Epoch 532/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
            "Epoch 533/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
            "Epoch 534/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
            "Epoch 535/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
            "Epoch 536/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
            "Epoch 537/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
            "Epoch 538/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
            "Epoch 539/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
            "Epoch 540/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
            "Epoch 541/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
            "Epoch 542/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 543/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 544/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
            "Epoch 545/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 546/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "Epoch 547/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 548/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 549/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 550/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 551/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 552/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 553/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 554/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 555/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 556/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 557/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 558/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 559/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "Epoch 560/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
            "Epoch 561/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "Epoch 562/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "Epoch 563/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "Epoch 564/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "Epoch 565/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 566/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "Epoch 567/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "Epoch 568/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 569/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 570/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 571/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 572/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 573/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 574/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 575/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 576/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 577/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 578/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 579/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 580/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 581/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 582/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 583/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 584/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "Epoch 585/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "Epoch 586/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "Epoch 587/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
            "Epoch 588/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
            "Epoch 589/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
            "Epoch 590/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
            "Epoch 591/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
            "Epoch 592/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
            "Epoch 593/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
            "Epoch 594/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
            "Epoch 595/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
            "Epoch 596/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
            "Epoch 597/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
            "Epoch 598/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
            "Epoch 599/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
            "Epoch 600/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
            "Epoch 601/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
            "Epoch 602/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
            "Epoch 603/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
            "Epoch 604/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
            "Epoch 605/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
            "Epoch 606/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
            "Epoch 607/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
            "Epoch 608/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
            "Epoch 609/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
            "Epoch 610/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
            "Epoch 611/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
            "Epoch 612/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
            "Epoch 613/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 614/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 615/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
            "Epoch 616/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 617/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 618/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 619/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 620/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 621/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 622/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 623/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 624/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 625/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 626/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 627/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 628/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 629/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 630/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 631/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 632/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 633/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 634/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 635/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 636/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 637/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 638/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 639/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 640/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 641/2500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 642/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 643/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 644/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 645/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 646/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 647/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 648/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 649/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 650/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 651/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 652/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 653/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 654/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 655/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 656/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 657/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 658/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 659/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 660/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 661/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 662/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 663/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 664/2500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 665/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 666/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 667/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 668/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 669/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 670/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 671/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 672/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 673/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 674/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 675/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 676/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 677/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 678/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 679/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 680/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 681/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 682/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 683/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 684/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 685/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 686/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 687/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 688/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 689/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 690/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 691/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 692/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 693/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 694/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 695/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 696/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 697/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 698/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 699/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 700/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 701/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 702/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 703/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 704/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 705/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 706/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 707/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 708/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 709/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 710/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 711/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 712/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 713/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 714/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 715/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 716/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 717/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 718/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 719/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 720/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 721/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 722/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 723/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 724/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 725/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 726/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 727/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 728/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 729/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 730/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 731/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 732/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 733/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 734/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 735/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 736/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 737/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 738/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 739/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 740/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 741/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 742/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 743/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 744/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 745/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 746/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 747/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 748/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 749/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 750/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 751/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 752/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 753/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 754/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 755/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 756/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 757/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 758/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 759/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 760/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 761/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 762/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 763/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 764/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 765/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 766/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 767/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 768/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 769/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 770/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 771/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 772/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 773/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 774/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 775/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 776/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 777/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 778/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 779/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 780/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 781/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 782/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 783/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 784/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 785/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 786/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 787/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 788/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 789/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 790/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 791/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 792/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 793/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 794/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 795/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 796/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 797/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 798/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 799/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 800/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 801/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 802/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 803/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 804/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 805/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 806/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 807/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 808/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 809/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 810/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 811/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 812/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 813/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 814/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 815/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 816/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 817/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 818/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 819/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 820/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 821/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 822/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 823/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 824/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 825/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 826/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 827/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 828/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 829/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 830/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 831/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 832/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 833/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 834/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 835/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 836/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 837/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 838/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 839/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 840/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 841/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 842/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 843/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 844/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 845/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 846/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 847/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 848/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 849/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 850/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 851/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 852/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 853/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 854/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 855/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 856/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 857/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 858/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 859/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 860/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 861/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 862/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 863/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 864/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 865/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 866/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 867/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 868/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 869/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 870/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 871/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 872/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 873/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 874/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 875/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 876/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 877/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 878/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 879/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 880/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 881/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 882/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 883/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 884/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 885/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 886/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 887/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 888/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 889/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 890/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 891/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 892/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 893/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 894/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 895/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 896/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 897/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 898/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 899/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 900/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 901/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 902/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 903/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 904/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 905/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 906/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 907/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 908/2500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 909/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 910/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 911/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 912/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 913/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 914/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 915/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 916/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 917/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 918/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 919/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 920/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 921/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 922/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 923/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 924/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 925/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 926/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 927/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 928/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 929/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 930/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 931/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 932/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 933/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 934/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 935/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 936/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 937/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 938/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 939/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 940/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 941/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 942/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 943/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 944/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 945/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 946/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 947/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 948/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 949/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 950/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 951/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 952/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 953/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 954/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 955/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 956/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 957/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 958/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 959/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 960/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 961/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 962/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 963/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 964/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 965/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 966/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 967/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 968/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 969/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 970/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 971/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 972/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 973/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 974/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 975/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 976/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 977/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 978/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 979/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 980/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 981/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 982/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 983/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 984/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 985/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 986/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 987/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 988/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 989/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 990/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 991/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 992/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 993/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 994/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 995/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 996/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 997/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 998/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 999/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1000/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1001/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1002/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1003/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1004/2500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1005/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1006/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1007/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1008/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1009/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1010/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1011/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1012/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1013/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1014/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1015/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1016/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1017/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1018/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1019/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1020/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1021/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1022/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1023/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1024/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1025/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1026/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1027/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1028/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1029/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1030/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1031/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1032/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1033/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1034/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1035/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1036/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1037/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1038/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1039/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1040/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1041/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1042/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1043/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1044/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1045/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1046/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1047/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1048/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1049/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1050/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1051/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1052/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1053/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1054/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1055/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1056/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1057/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1058/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1059/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1060/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1061/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1062/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1063/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1064/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1065/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1066/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1067/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1068/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1069/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1070/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1071/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1072/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1073/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1074/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1075/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1076/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1077/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1078/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1079/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1080/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1081/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1082/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1083/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1084/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1085/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1086/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1087/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1088/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1089/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1090/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1091/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1092/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1093/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1094/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1095/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1096/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1097/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1098/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1099/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1100/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1101/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1102/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1103/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1104/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1105/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1106/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1107/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1108/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1109/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1110/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1111/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1112/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1113/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1114/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1115/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1116/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1117/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1118/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1119/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1120/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1121/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1122/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1123/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1124/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1125/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1126/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1127/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1128/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1129/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1130/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1131/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1132/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1133/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1134/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1135/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1136/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1137/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1138/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1139/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1140/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1141/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1142/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1143/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1144/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1145/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1146/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1147/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1148/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1149/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1150/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1151/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1152/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1153/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1154/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1155/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1156/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1157/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1158/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1159/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1160/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1161/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1162/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1163/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1164/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1165/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1166/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1167/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1168/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1169/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1170/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1171/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1172/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1173/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1174/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1175/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1176/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1177/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1178/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1179/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1180/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1181/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1182/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1183/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1184/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1185/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1186/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1187/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1188/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1189/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1190/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1191/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1192/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1193/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1194/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1195/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1196/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1197/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1198/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1199/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1200/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1201/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1202/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1203/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1204/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1205/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1206/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1207/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1208/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1209/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1210/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1211/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1212/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1213/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1214/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1215/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1216/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1217/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1218/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1219/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1220/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1221/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1222/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1223/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1224/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1225/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1226/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1227/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1228/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1229/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1230/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1231/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1232/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1233/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1234/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1235/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1236/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1237/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1238/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1239/2500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1240/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1241/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1242/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1243/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1244/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1245/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1246/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1247/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1248/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1249/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1250/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1251/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1252/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1253/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1254/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1255/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1256/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1257/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1258/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1259/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1260/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1261/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1262/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1263/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1264/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1265/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1266/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1267/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1268/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1269/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1270/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1271/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1272/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1273/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1274/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1275/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1276/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1277/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1278/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1279/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1280/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1281/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1282/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1283/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1284/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1285/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1286/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1287/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1288/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1289/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1290/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1291/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1292/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1293/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1294/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1295/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1296/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1297/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1298/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1299/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1300/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1301/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1302/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1303/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1304/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1305/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1306/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1307/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1308/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1309/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1310/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1311/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1312/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1313/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1314/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1315/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1316/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1317/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1318/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1319/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1320/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1321/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1322/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1323/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1324/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1325/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1326/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1327/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1328/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1329/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1330/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1331/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1332/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1333/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1334/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1335/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1336/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1337/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1338/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1339/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1340/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1341/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1342/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1343/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1344/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1345/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1346/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1347/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1348/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1349/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1350/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1351/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1352/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1353/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1354/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1355/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1356/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1357/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1358/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1359/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1360/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1361/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1362/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1363/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1364/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1365/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1366/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1367/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1368/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1369/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1370/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1371/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1372/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1373/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1374/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1375/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1376/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1377/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1378/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1379/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1380/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1381/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1382/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1383/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1384/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1385/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1386/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1387/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1388/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1389/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1390/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1391/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1392/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1393/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1394/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1395/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1396/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1397/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1398/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1399/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1400/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1401/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1402/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1403/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1404/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1405/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1406/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1407/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1408/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1409/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1410/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1411/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1412/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1413/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1414/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1415/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1416/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1417/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1418/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1419/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1420/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1421/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1422/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1423/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1424/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1425/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1426/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1427/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1428/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1429/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1430/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1431/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1432/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1433/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1434/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1435/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1436/2500\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1437/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1438/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1439/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1440/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1441/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1442/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1443/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1444/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1445/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1446/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1447/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1448/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1449/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1450/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1451/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1452/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1453/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1454/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1455/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1456/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1457/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1458/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1459/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1460/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1461/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1462/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1463/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1464/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1465/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1466/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1467/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1468/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1469/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1470/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1471/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1472/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1473/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1474/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1475/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1476/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1477/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1478/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1479/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1480/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1481/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1482/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1483/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1484/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1485/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1486/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1487/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1488/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1489/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1490/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1491/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1492/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1493/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1494/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1495/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1496/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1497/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1498/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1499/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1500/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1501/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1502/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1503/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1504/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1505/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1506/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1507/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1508/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1509/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1510/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1511/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1512/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1513/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1514/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1515/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1516/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1517/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1518/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1519/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1520/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1521/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1522/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1523/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1524/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1525/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1526/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1527/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1528/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1529/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1530/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1531/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1532/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1533/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1534/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1535/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1536/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1537/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1538/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1539/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1540/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1541/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1542/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1543/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1544/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1545/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1546/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1547/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1548/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1549/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1550/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1551/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1552/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1553/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1554/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1555/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1556/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1557/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1558/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1559/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1560/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1561/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1562/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1563/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1564/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1565/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1566/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1567/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1568/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1569/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1570/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1571/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1572/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1573/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1574/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1575/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1576/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1577/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1578/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1579/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1580/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1581/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1582/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1583/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1584/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1585/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1586/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1587/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1588/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1589/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1590/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1591/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1592/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1593/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1594/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1595/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1596/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1597/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1598/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1599/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1600/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1601/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1602/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1603/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1604/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1605/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1606/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1607/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1608/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1609/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1610/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1611/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1612/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1613/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1614/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1615/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1616/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1617/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1618/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1619/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1620/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1621/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1622/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1623/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1624/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1625/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1626/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1627/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1628/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1629/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1630/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1631/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1632/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1633/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1634/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1635/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1636/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1637/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1638/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1639/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1640/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1641/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1642/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1643/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1644/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1645/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1646/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1647/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1648/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1649/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1650/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1651/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1652/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1653/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1654/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1655/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1656/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1657/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1658/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1659/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1660/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1661/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1662/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1663/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1664/2500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1665/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1666/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1667/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1668/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1669/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1670/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1671/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1672/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1673/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1674/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1675/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1676/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1677/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1678/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1679/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1680/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1681/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1682/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1683/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1684/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1685/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1686/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1687/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1688/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1689/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1690/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1691/2500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1692/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1693/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1694/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1695/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1696/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1697/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1698/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1699/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1700/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1701/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1702/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1703/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1704/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1705/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1706/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1707/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1708/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1709/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1710/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1711/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1712/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1713/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1714/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1715/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1716/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1717/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1718/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1719/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1720/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1721/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1722/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1723/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1724/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1725/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1726/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1727/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1728/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1729/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1730/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1731/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1732/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1733/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1734/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1735/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1736/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1737/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1738/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1739/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1740/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1741/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1742/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1743/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1744/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1745/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1746/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1747/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1748/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1749/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1750/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1751/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1752/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1753/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1754/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1755/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1756/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1757/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1758/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1759/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1760/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1761/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1762/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1763/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1764/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1765/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1766/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1767/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1768/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1769/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1770/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1771/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1772/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1773/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1774/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1775/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1776/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1777/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1778/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1779/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1780/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1781/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1782/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1783/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1784/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1785/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1786/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1787/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1788/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1789/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1790/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1791/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1792/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1793/2500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1794/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1795/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1796/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1797/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1798/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1799/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1800/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1801/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1802/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1803/2500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1804/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1805/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1806/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1807/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1808/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1809/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1810/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1811/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1812/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1813/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1814/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1815/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1816/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1817/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1818/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1819/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1820/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1821/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1822/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1823/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1824/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1825/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1826/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1827/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1828/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1829/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1830/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1831/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1832/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1833/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1834/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1835/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1836/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1837/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1838/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1839/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1840/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1841/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1842/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1843/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1844/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1845/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1846/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1847/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1848/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1849/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1850/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1851/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1852/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1853/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1854/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1855/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1856/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1857/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1858/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1859/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1860/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1861/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1862/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1863/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1864/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1865/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1866/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1867/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1868/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1869/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1870/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1871/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1872/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1873/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1874/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1875/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1876/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1877/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1878/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1879/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1880/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1881/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1882/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1883/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1884/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1885/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1886/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1887/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1888/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1889/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1890/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1891/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1892/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1893/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1894/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1895/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1896/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1897/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1898/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1899/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1900/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1901/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1902/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1903/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1904/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1905/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1906/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1907/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1908/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1909/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1910/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1911/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1912/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1913/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1914/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1915/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1916/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1917/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1918/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1919/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1920/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1921/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1922/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1923/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1924/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1925/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1926/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1927/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1928/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1929/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1930/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1931/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1932/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1933/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1934/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1935/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1936/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1937/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1938/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1939/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1940/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1941/2500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1942/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1943/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1944/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1945/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1946/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1947/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1948/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1949/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1950/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1951/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1952/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1953/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1954/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1955/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1956/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1957/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1958/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1959/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1960/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1961/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1962/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1963/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1964/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1965/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1966/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1967/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1968/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1969/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1970/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1971/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1972/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1973/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1974/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1975/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1976/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1977/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1978/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1979/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1980/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1981/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1982/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1983/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1984/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1985/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1986/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1987/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1988/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1989/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1990/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1991/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1992/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1993/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1994/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1995/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1996/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1997/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1998/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1999/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2000/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2001/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2002/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2003/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2004/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2005/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2006/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2007/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2008/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2009/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2010/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2011/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2012/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2013/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2014/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2015/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2016/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2017/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2018/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2019/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2020/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2021/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2022/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2023/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2024/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2025/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2026/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2027/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2028/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2029/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2030/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2031/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2032/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2033/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2034/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2035/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2036/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2037/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2038/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2039/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2040/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2041/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2042/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2043/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2044/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2045/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2046/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2047/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2048/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2049/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2050/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2051/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2052/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2053/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2054/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2055/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2056/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2057/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2058/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2059/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2060/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2061/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2062/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2063/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2064/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2065/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2066/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2067/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2068/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2069/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2070/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2071/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2072/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2073/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2074/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2075/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2076/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2077/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2078/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2079/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2080/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2081/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2082/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2083/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2084/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2085/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2086/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2087/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2088/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2089/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2090/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2091/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2092/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2093/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2094/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2095/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2096/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2097/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2098/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2099/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2100/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2101/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2102/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2103/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2104/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2105/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2106/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2107/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2108/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2109/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2110/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2111/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2112/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2113/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2114/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2115/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2116/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2117/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2118/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2119/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2120/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2121/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2122/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2123/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2124/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2125/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2126/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2127/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2128/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2129/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2130/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2131/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2132/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2133/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2134/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2135/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2136/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2137/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2138/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2139/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2140/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2141/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2142/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2143/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2144/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2145/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2146/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2147/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2148/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2149/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2150/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2151/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2152/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2153/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2154/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2155/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2156/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2157/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2158/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2159/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2160/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2161/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2162/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2163/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2164/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2165/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2166/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2167/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2168/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2169/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2170/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2171/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2172/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2173/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2174/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2175/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2176/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2177/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2178/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2179/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2180/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2181/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2182/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2183/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2184/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2185/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2186/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2187/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2188/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2189/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2190/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2191/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2192/2500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2193/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2194/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2195/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2196/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2197/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2198/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2199/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2200/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2201/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2202/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2203/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2204/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2205/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2206/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2207/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2208/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2209/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2210/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2211/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2212/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2213/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2214/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2215/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2216/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2217/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2218/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2219/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2220/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2221/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2222/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2223/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2224/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2225/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2226/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2227/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2228/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2229/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2230/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2231/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2232/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 2233/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2234/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2235/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2236/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2237/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2238/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2239/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2240/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2241/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2242/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2243/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2244/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2245/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2246/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2247/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2248/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2249/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2250/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2251/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2252/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2253/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2254/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2255/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2256/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2257/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2258/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2259/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2260/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2261/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2262/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2263/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2264/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2265/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2266/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2267/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2268/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2269/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2270/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2271/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2272/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2273/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2274/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2275/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2276/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2277/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2278/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2279/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2280/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2281/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2282/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2283/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2284/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2285/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2286/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2287/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2288/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2289/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2290/2500\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2291/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2292/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2293/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2294/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2295/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2296/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2297/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2298/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2299/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2300/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2301/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 2302/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2303/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2304/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2305/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2306/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2307/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2308/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2309/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2310/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2311/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2312/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2313/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2314/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2315/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2316/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2317/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2318/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2319/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2320/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2321/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2322/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2323/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2324/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2325/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2326/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2327/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2328/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2329/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2330/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2331/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2332/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2333/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2334/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2335/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2336/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2337/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2338/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2339/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2340/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2341/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2342/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2343/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2344/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2345/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2346/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2347/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2348/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2349/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2350/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2351/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2352/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2353/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2354/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2355/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2356/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2357/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2358/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2359/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2360/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2361/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2362/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2363/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2364/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2365/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2366/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2367/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2368/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2369/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2370/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2371/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 2372/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2373/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2374/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2375/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2376/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2377/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2378/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2379/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2380/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2381/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2382/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2383/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2384/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2385/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2386/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2387/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2388/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2389/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2390/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2391/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2392/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2393/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2394/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2395/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2396/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2397/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2398/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2399/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2400/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2401/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2402/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2403/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2404/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2405/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2406/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2407/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2408/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2409/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2410/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2411/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2412/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2413/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2414/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2415/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2416/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2417/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2418/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2419/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2420/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2421/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2422/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2423/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2424/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2425/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2426/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2427/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2428/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2429/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2430/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2431/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2432/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2433/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2434/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2435/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2436/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2437/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2438/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2439/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2440/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2441/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2442/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2443/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2444/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2445/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2446/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2447/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2448/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2449/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2450/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2451/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2452/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2453/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2454/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2455/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2456/2500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2457/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2458/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2459/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2460/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2461/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2462/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2463/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2464/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2465/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2466/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2467/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2468/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2469/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2470/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2471/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2472/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2473/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2474/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2475/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2476/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2477/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2478/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2479/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2480/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2481/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2482/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2483/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2484/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2485/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2486/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2487/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2488/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2489/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2490/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2491/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2492/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2493/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2494/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2495/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2496/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2497/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2498/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2499/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2500/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0HqYFKtrVOM"
      },
      "source": [
        "# Get fish weight predictions\n",
        "y_fish_pred = model.predict(X_test)\n",
        "\n",
        "# map normalized fish weights back to grams\n",
        "y_fish_pred = (fish_max-fish_min) * y_fish_pred + fish_min \n",
        "y_test = (fish_max-fish_min) * y_test.values + fish_min "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0cyLYP-qx36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89e2e64-fd6c-433a-f73a-08118c65acf7"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Compute the mean squared error using y_fish_test and y_fish_pred\n",
        "### YOUR CODE HERE ###\n",
        "print(\"mean squared error:\", mean_squared_error(y_test, y_fish_pred))\n",
        "\n",
        "# Compute the coefficient of determination using y_fish_test and y_fish_pred\n",
        "### YOUR CODE HERE ###\n",
        "print(\"coefficient of determination:\", r2_score(y_test, y_fish_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean squared error: 17259.148028301846\n",
            "coefficient of determination: 0.889258373060352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXh5nXxgzAsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0c210e-0485-4334-bed4-18bda423d680"
      },
      "source": [
        "# Print the predictions along with actual weights\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format},precision=2)\n",
        "print(np.concatenate((y_fish_pred.reshape(len(y_fish_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[457.087952 390.000000]\n",
            " [202.547867 160.000000]\n",
            " [667.714050 700.000000]\n",
            " [840.435181 1015.000000]\n",
            " [117.150246 120.000000]\n",
            " [843.562805 1100.000000]\n",
            " [758.496155 820.000000]\n",
            " [935.822632 950.000000]\n",
            " [616.220337 556.000000]\n",
            " [178.161911 145.000000]\n",
            " [662.067139 700.000000]\n",
            " [1118.826904 1600.000000]\n",
            " [703.330444 720.000000]\n",
            " [16.447653 55.000000]\n",
            " [84.857925 85.000000]\n",
            " [247.110367 188.000000]\n",
            " [436.757996 300.000000]\n",
            " [221.602020 180.000000]\n",
            " [1118.826904 1550.000000]\n",
            " [361.805023 306.000000]\n",
            " [172.045731 140.000000]\n",
            " [903.509460 975.000000]\n",
            " [775.768250 1000.000000]\n",
            " [485.094543 450.000000]\n",
            " [144.758209 110.000000]\n",
            " [88.152649 78.000000]\n",
            " [369.343018 300.000000]\n",
            " [622.454651 650.000000]\n",
            " [-130.828827 6.700000]\n",
            " [550.387329 514.000000]\n",
            " [321.946442 290.000000]\n",
            " [295.295013 270.000000]\n",
            " [584.659241 700.000000]\n",
            " [450.311920 300.000000]\n",
            " [589.285889 510.000000]\n",
            " [618.544556 620.000000]\n",
            " [174.782074 150.000000]\n",
            " [177.971069 170.000000]\n",
            " [684.258484 700.000000]\n",
            " [199.008652 170.000000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FprpdF_YzJf6"
      },
      "source": [
        "What was the R-squared value and mean squared error for this model? Does this model appear to do a better job at predicting weights than linear regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDRR8wzy0SZu"
      },
      "source": [
        "[YOUR ANSWER HERE]"
      ]
    }
  ]
}