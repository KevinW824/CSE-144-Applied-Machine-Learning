{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summer_21_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinW824/CSE-144-Applied-Machine-Learning/blob/main/Summer_21_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IlwhV0z2nMr"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU7xWQml74JY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chprzdhe2nMw"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "**DUE: Sunday July 11 at 11:59pm**\n",
        "\n",
        "Turn in the assignment via Canvas.\n",
        "\n",
        "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Runtime→→Restart runtime) and then run all cells (in the menubar, select Runtime→→Run All).\n",
        "\n",
        "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jeWubXE2nMx"
      },
      "source": [
        "NAME = \"Bowen Wang\"\n",
        "STUDENT_ID = \"bwang93\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_22iEs6s1oL"
      },
      "source": [
        "## Problem 1 - Logistic Regression Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrpQWvSs0x3v"
      },
      "source": [
        "Recall from lecture sigmoid function:\n",
        "$$\\begin{align}\n",
        "f(x)= \\sigma(\\theta^T \\cdot \\mathbf{x})) = \\frac{1}{1+e^{-\\theta^T \\cdot \\mathbf{x}}}\n",
        "\\end{align}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeJAjBYEs6iJ"
      },
      "source": [
        "### a) Probabilities (10 points)\n",
        "Write a script to, or by hand, calculate the probability $ \\sigma(\\theta^T \\cdot \\mathbf{x}))$ for each of the following $x^i$'s assuming Assuming $\\theta=[-0.1, 0.1, 0.5, 0.3]$, \n",
        "\n",
        "| | $x^i_{0}$ | $x^i_{1}$ | $x^i_{2}$ | y|\n",
        "| --- | --- | --- | --- | --- |\n",
        "|$x^{1}$ | 1 | -7 | -3 | 0 |\n",
        "|$x^{2}$ | 1 | 5 | 1 | 1 |\n",
        "|$x^{3}$ | 1 | 1 | 1 | 1 |\n",
        "|$x^{4}$ | -1 | -1 | 1 | 1 |\n",
        "|$x^{5}$ | 2 | -1 | 3 | 0 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3AQpCM_BE-M"
      },
      "source": [
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd413HoUtBRH"
      },
      "source": [
        "### b) Classification (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmoTCICMBMGs"
      },
      "source": [
        "Using the probabilities you calculated in part a) and the decision boundary $\\theta^T\\mathbf{x}=0$ classify the points as class 1 or class 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nKSXta9BIW7"
      },
      "source": [
        "[YOUR ANSWER HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IeQoSWbtEPn"
      },
      "source": [
        "## Problem 2 - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh57Se9YtZBD"
      },
      "source": [
        "For this problem, we will predict whether or not breast tumors are cancerous or not using the Breast Cancer Wisconsin (Diagnostic) Data Set. Begin by importing and processing data. A description of the dataset is given below.\n",
        "\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
        "\n",
        "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
        "\n",
        "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
        "\n",
        "This database is also available through the UW CS ftp server:\n",
        "ftp ftp.cs.wisc.edu\n",
        "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
        "\n",
        "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1) ID number\n",
        "\n",
        "2) Diagnosis (M = malignant, B = benign)\n",
        "\n",
        "3 to 32)\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "* a) radius (mean of distances from center to points on the perimeter)\n",
        "* b) texture (standard deviation of gray-scale values)\n",
        "* c) perimeter\n",
        "* d) area\n",
        "* e) smoothness (local variation in radius lengths)\n",
        "* f) compactness (perimeter^2 / area - 1.0)\n",
        "* g) concavity (severity of concave portions of the contour)\n",
        "* h) concave points (number of concave portions of the contour)\n",
        "* i) symmetry\n",
        "* j) fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three\n",
        "largest values) of these features were computed for each image,\n",
        "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
        "13 is Radius SE, field 23 is Worst Radius.\n",
        "\n",
        "All feature values are recoded with four significant digits.\n",
        "\n",
        "Missing attribute values: none\n",
        "\n",
        "Class distribution: 357 benign, 212 malignant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm6WAqNPRRu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyKWchKWIvPi"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwexIqp8I_lF"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLF5xucumaai"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1igyRhO_Vugc0WD_bop9WUqX61Q4BJYBg\"})\n",
        "downloaded.GetContentFile('data.csv')  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpxch0eIm2D3"
      },
      "source": [
        "# Create pandas dataframe\n",
        "data = pd.read_csv('data.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEGGgoy6nD4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "7afd9800-b704-460f-cf76-60d6ad803829"
      },
      "source": [
        "# Let's look at the data\n",
        "data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8birwmMhNxqx"
      },
      "source": [
        "# drop Unnamed: 32 column\n",
        "data = data.iloc[:,0:-1]\n",
        "\n",
        "#drop the id column\n",
        "data = data.iloc[:,1:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roig66zZ4z3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "649f4a80-4679-4c8c-a665-1c096df37958"
      },
      "source": [
        "# Let's check the data again\n",
        "data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0           M        17.99  ...          0.4601                  0.11890\n",
              "1           M        20.57  ...          0.2750                  0.08902\n",
              "2           M        19.69  ...          0.3613                  0.08758\n",
              "3           M        11.42  ...          0.6638                  0.17300\n",
              "4           M        20.29  ...          0.2364                  0.07678\n",
              "..        ...          ...  ...             ...                      ...\n",
              "564         M        21.56  ...          0.2060                  0.07115\n",
              "565         M        20.13  ...          0.2572                  0.06637\n",
              "566         M        16.60  ...          0.2218                  0.07820\n",
              "567         M        20.60  ...          0.4087                  0.12400\n",
              "568         B         7.76  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRmp0GI2nOi"
      },
      "source": [
        "### a) Converting Categorical Data to Numeric Values (5 points)\n",
        "\n",
        "The diagnosis column has categorical values 'B' if a tumor is benign, and 'M' if it is malignant. Convert these values to 0 for 'B' and 1 for 'M'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0vh80Yc2nOj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "b89a4613-fac1-427b-ecda-72cb37a2c822"
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0            1        17.99  ...          0.4601                  0.11890\n",
              "1            1        20.57  ...          0.2750                  0.08902\n",
              "2            1        19.69  ...          0.3613                  0.08758\n",
              "3            1        11.42  ...          0.6638                  0.17300\n",
              "4            1        20.29  ...          0.2364                  0.07678\n",
              "..         ...          ...  ...             ...                      ...\n",
              "564          1        21.56  ...          0.2060                  0.07115\n",
              "565          1        20.13  ...          0.2572                  0.06637\n",
              "566          1        16.60  ...          0.2218                  0.07820\n",
              "567          1        20.60  ...          0.4087                  0.12400\n",
              "568          0         7.76  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zsToX3tPahn"
      },
      "source": [
        "### b) Run Logistic Regression (10 points)\n",
        "Divide your data into feature set X which contains the following variables:\n",
        "* radius_mean\t\n",
        "* texture_mean\t\n",
        "* perimeter_mean\tarea_mean\t\n",
        "* smoothness_mean\t\n",
        "* compactness_mean\n",
        "* concavity_mean\t\n",
        "* concave points_mean\t\n",
        "* symmetry_mean\t\n",
        "* fractal_dimension_mean\tradius_se\t\n",
        "* texture_se\tperimeter_se\t\n",
        "* area_se\t\n",
        "* smoothness_se\t\n",
        "* compactness_se\t\n",
        "* concavity_se\t\n",
        "* concave points_se\t\n",
        "* symmetry_se\t\n",
        "* fractal_dimension_se\t\n",
        "* radius_worst\t\n",
        "* texture_worst\t\n",
        "* perimeter_worst\t\n",
        "* area_worst\tsmoothness_worst\t\n",
        "* compactness_worst\t\n",
        "* concavity_worst\t\n",
        "* concave points_worst\t\n",
        "* symmetry_worst\t\n",
        "* fractal_dimension_worst\n",
        "\n",
        "and labels y which contains the diagnosis column. Then divide your data into 75% training set data and 25% test set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8e_w2-rRtED"
      },
      "source": [
        "# Split data into X and y\n",
        "X = data.drop(columns=['diagnosis'])### YOUR CODE HERE ###\n",
        "y = data.iloc[:, 0]### YOUR CODE HERE ###\n",
        "\n",
        "# Split X and y into X_train, y_train, X_test, y_test using train_test_split()\n",
        "### YOUR CODE HERE ###\n",
        "X = X.values\n",
        "y = y.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHlyB20UPqQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffb173b-4100-49fd-def8-254845d5d93a"
      },
      "source": [
        "# instantiate LinearRegression\n",
        "clf = LogisticRegression(random_state=0)### YOUR CODE HERE ### \n",
        "\n",
        "\n",
        "# Fit the regressor using X_train and y_train\n",
        "### YOUR CODE HERE ###\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlmjRX-FV6Fa"
      },
      "source": [
        "### c) Classification accuracy for the training and test sets (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfwZS4CJWNrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f60464c-9c67-4fa6-d72a-47f7b0d06a8b"
      },
      "source": [
        "# Generate predictions using X_train\n",
        "### YOUR CODE HERE ###\n",
        "from sklearn.metrics import accuracy_score\n",
        "train_pred = clf.predict(X_train)\n",
        "\n",
        "# Calculate the classification accuracy for the training set\n",
        "### YOUR CODE HERE ###\n",
        "train_score = accuracy_score(y_train, train_pred)\n",
        "print(\"train_score:\", train_score)\n",
        "\n",
        "# Generate predictions using X_test\n",
        "### YOUR CODE HERE ###\n",
        "test_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the classification accuracy for the test set\n",
        "### YOUR CODE HERE ###\n",
        "test_score = accuracy_score(y_test, test_pred)\n",
        "print(\"test_score:\", test_score)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_score: 0.9483568075117371\n",
            "test_score: 0.9440559440559441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56vnLVWyU83B"
      },
      "source": [
        "### d) False Positives, False Negatives, True Positives, True Negatives (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luz4lriJdESy"
      },
      "source": [
        "In binary classification, A **false positive** (FP) is an outcome where the model incorrectly predicts the positive class. And a **false negative** (FN) is an outcome where the model incorrectly predicts the negative class. Likewise, a **true positive** (TP) is an outcome where the model correctly predicts a positive class. A **true negative** (TN) is an outcome where the model correctly predicts the negative class.\n",
        "\n",
        "Calculate the number of FPs, FNs, TPs,and TNs using the test set predictions and test set labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLFPG2AbhGj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84420b65-a923-4e2a-dd97-70f15fb0ae2f"
      },
      "source": [
        "# Calculate the number of false positives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "fp = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if test_pred[i] == 1 and y_test[i] == 0:\n",
        "        fp += 1\n",
        "print(\"false positive:\", fp)\n",
        "\n",
        "# Calculate the number of false negatives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "fn = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if y_test[i] == 1 and test_pred[i] == 0:\n",
        "        fn += 1\n",
        "print(\"false negative:\", fn)\n",
        "\n",
        "#Calculate the number of true positives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "tp = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if y_test[i] == test_pred[i] == 1:\n",
        "        tp += 1\n",
        "print(\"true positive:\", tp)\n",
        "\n",
        "#Calculate the number of true negatives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "tn = 0\n",
        "for i in range(len(test_pred)):\n",
        "    if y_test[i] == test_pred[i] == 0:\n",
        "        tn += 1\n",
        "print(\"true negative:\", tn)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false positive: 6\n",
            "false negative: 2\n",
            "true positive: 51\n",
            "true negative: 84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p_GEkAbjYHv"
      },
      "source": [
        "### e) Precision and Recall (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0xed4wIjcmn"
      },
      "source": [
        "Two important statistics used to analyze the performance of classification models are precision and recall. **precision** (also called positive predictive value) is proportion of positive identifications that were actually correct, while **recall** (also known as sensitivity) is the proportion of actual positives that were identified correctly.\n",
        "\n",
        "Precision can be calculated as:\n",
        "$$Precision = \\frac{TP}{TP+FP}$$\n",
        "\n",
        "Recall can be calculated as:\n",
        "$$Recall = \\frac{TP}{TP+FN}$$\n",
        "\n",
        "For more info: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THYqeYZ5o_lE"
      },
      "source": [
        "Use your answer from part d) to calculate Precision:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMym2_FYpM3u"
      },
      "source": [
        "$$ Precision = \\dfrac{51}{51 + 6} = 0.8947 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTdTM4vmpMxc"
      },
      "source": [
        "User your answer from part d) to calculate Recall:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5gUHq9MpbVG"
      },
      "source": [
        "$$ Recall = \\dfrac{51}{51 + 2} = 0.9623 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZITT5VUttzO"
      },
      "source": [
        "## Problem 3 - Neural Network For Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMCxB72z-kC9"
      },
      "source": [
        "### a) Training a simply neural network for classification (5 points)\n",
        "Complete the following code segments to create a NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt7K04ckhK1v"
      },
      "source": [
        "# import Keras from TensorFlow\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Ekoez3ciwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "568ef1d4-afcf-447f-862b-091b956745b5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets.samples_generator import make_moons\n",
        "from pylab import rcParams\n",
        "\n",
        "# Create the training data\n",
        "np.random.seed(42) \n",
        "data, labels = make_moons(n_samples=500, noise=0.1)\n",
        "colors = ['r' if y else 'b' for y in labels]\n",
        "print('data.shape =', data.shape)\n",
        "print('labels.shape =', labels.shape)\n",
        "plt.scatter(data[:,0], data[:,1], c=colors)\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "data.shape = (500, 2)\n",
            "labels.shape = (500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW6XzU_IciwH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "e066430f-1727-466a-ea8f-b1325f939f3c"
      },
      "source": [
        "# Create and plot the test data\n",
        "np.random.seed(17)   \n",
        "test_data, test_labels = make_moons(n_samples=500, noise=0.1)\n",
        "colors = ['r' if y else 'b' for y in test_labels]\n",
        "print('test_data.shape =', test_data.shape)\n",
        "print('test_labels.shape =', test_labels.shape)\n",
        "plt.scatter(test_data[:,0], test_data[:,1], c=colors)\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data.shape = (500, 2)\n",
            "test_labels.shape = (500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ1Coz15ciwJ"
      },
      "source": [
        "The above image is created by sampling from the same distribution as before. But these are entirely different points than your model was trained on.  So how our model performs on this test data will be a good indication of our model's ability to generalize.\n",
        "\n",
        " In the cell below, construct a simple neural network with 5 layers as follows:\n",
        "* **input layer** of shape 5\n",
        "* **dense layer** with 10 neurons, and relu activation\n",
        "* **dense layer** with 4 neurons, and relu activation\n",
        "* **dense layer** with 3 neurons, and relu activation\n",
        "* **dense layer** with 1 neuron, and sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRRrqpb1ciwK"
      },
      "source": [
        "def build_model1():\n",
        "    ### YOUR CODE HERE ###\n",
        "    input_layer = Input(shape=(2))\n",
        "    x = Dense(10, activation='relu')(input_layer)\n",
        "    x = Dense(4, activation='relu')(x)\n",
        "    x = Dense(3, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x) \n",
        "    return Model(input_layer, x)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6KzH-yXOAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d9ec5f-d986-405c-b9de-00147225c588"
      },
      "source": [
        "# Get model summary\n",
        "model = build_model1()\n",
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 44        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 93\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PROyV-LvciwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e5ef37-0c0d-4b44-c520-caf4715dabcb"
      },
      "source": [
        "# Compile the NN model, defining the optimizer to use (sgd), the loss function (binary_crossentropy), and the metrics (acc) to use.\n",
        "# These settings are appropriate for a binary classification task.\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Train the model (obviously on the training data), iterating on the data in batches of 32 samples for 300 epochs. Have a validation_split of 0.2.\n",
        "history = model.fit(data,\n",
        "                    labels, \n",
        "                    epochs=300, \n",
        "                    batch_size=32, \n",
        "                    validation_split=0.2)### YOUR CODE HERE ###\n",
        "\n",
        "# Evaluate the model's performance\n",
        "train_loss, train_acc = model.evaluate(data, labels)\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print('Training set accuracy:', train_acc)\n",
        "print('Test set accuracy:', test_acc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 1s 21ms/step - loss: 0.7154 - accuracy: 0.3875 - val_loss: 0.7019 - val_accuracy: 0.4400\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7104 - accuracy: 0.3875 - val_loss: 0.7004 - val_accuracy: 0.4200\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.3800 - val_loss: 0.6998 - val_accuracy: 0.4200\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7065 - accuracy: 0.3800 - val_loss: 0.6994 - val_accuracy: 0.4000\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.7054 - accuracy: 0.3625 - val_loss: 0.6990 - val_accuracy: 0.3900\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.3500 - val_loss: 0.6987 - val_accuracy: 0.3700\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.3400 - val_loss: 0.6983 - val_accuracy: 0.3600\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.3375 - val_loss: 0.6980 - val_accuracy: 0.3500\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.3250 - val_loss: 0.6977 - val_accuracy: 0.3500\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.3150 - val_loss: 0.6974 - val_accuracy: 0.3300\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.3125 - val_loss: 0.6970 - val_accuracy: 0.3400\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.3200 - val_loss: 0.6966 - val_accuracy: 0.3400\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6989 - accuracy: 0.3175 - val_loss: 0.6962 - val_accuracy: 0.3400\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6982 - accuracy: 0.3400 - val_loss: 0.6959 - val_accuracy: 0.3500\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6975 - accuracy: 0.3600 - val_loss: 0.6956 - val_accuracy: 0.3800\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.3875 - val_loss: 0.6953 - val_accuracy: 0.3900\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.4075 - val_loss: 0.6949 - val_accuracy: 0.4200\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.4100 - val_loss: 0.6946 - val_accuracy: 0.4500\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.4550 - val_loss: 0.6942 - val_accuracy: 0.4600\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.4825 - val_loss: 0.6939 - val_accuracy: 0.4600\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5150 - val_loss: 0.6937 - val_accuracy: 0.4800\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5250 - val_loss: 0.6935 - val_accuracy: 0.5100\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5300 - val_loss: 0.6933 - val_accuracy: 0.5200\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5325 - val_loss: 0.6932 - val_accuracy: 0.5300\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5450 - val_loss: 0.6931 - val_accuracy: 0.5400\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5650 - val_loss: 0.6931 - val_accuracy: 0.5400\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5675 - val_loss: 0.6929 - val_accuracy: 0.5400\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5675 - val_loss: 0.6929 - val_accuracy: 0.5400\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5700 - val_loss: 0.6928 - val_accuracy: 0.5300\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5700 - val_loss: 0.6928 - val_accuracy: 0.5300\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5675 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.5675 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5700 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.5700 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5700 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.5675 - val_loss: 0.6927 - val_accuracy: 0.5300\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.5725 - val_loss: 0.6926 - val_accuracy: 0.5300\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.5700 - val_loss: 0.6926 - val_accuracy: 0.5300\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6911 - accuracy: 0.5675 - val_loss: 0.6925 - val_accuracy: 0.5300\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6911 - accuracy: 0.5725 - val_loss: 0.6926 - val_accuracy: 0.5300\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5700 - val_loss: 0.6924 - val_accuracy: 0.5400\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.5725 - val_loss: 0.6923 - val_accuracy: 0.5400\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5750 - val_loss: 0.6922 - val_accuracy: 0.5400\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.5750 - val_loss: 0.6921 - val_accuracy: 0.5400\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5750 - val_loss: 0.6921 - val_accuracy: 0.5400\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.5750 - val_loss: 0.6920 - val_accuracy: 0.5400\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5775 - val_loss: 0.6919 - val_accuracy: 0.5400\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5750 - val_loss: 0.6918 - val_accuracy: 0.5400\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5775 - val_loss: 0.6917 - val_accuracy: 0.5400\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5775 - val_loss: 0.6917 - val_accuracy: 0.5400\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5800 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5800 - val_loss: 0.6915 - val_accuracy: 0.5500\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5775 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.5850 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5825 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5900 - val_loss: 0.6911 - val_accuracy: 0.5500\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5875 - val_loss: 0.6910 - val_accuracy: 0.5500\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5875 - val_loss: 0.6909 - val_accuracy: 0.5500\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5875 - val_loss: 0.6908 - val_accuracy: 0.5500\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.5875 - val_loss: 0.6907 - val_accuracy: 0.5500\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5900 - val_loss: 0.6906 - val_accuracy: 0.5500\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6891 - accuracy: 0.5925 - val_loss: 0.6905 - val_accuracy: 0.5500\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5925 - val_loss: 0.6904 - val_accuracy: 0.5500\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5975 - val_loss: 0.6902 - val_accuracy: 0.5600\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5950 - val_loss: 0.6900 - val_accuracy: 0.5700\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.6000 - val_loss: 0.6899 - val_accuracy: 0.5700\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.6025 - val_loss: 0.6898 - val_accuracy: 0.5800\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.6050 - val_loss: 0.6896 - val_accuracy: 0.5800\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6050 - val_loss: 0.6894 - val_accuracy: 0.5800\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.6075 - val_loss: 0.6892 - val_accuracy: 0.5800\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.6100 - val_loss: 0.6890 - val_accuracy: 0.5800\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.6100 - val_loss: 0.6888 - val_accuracy: 0.5800\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.6175 - val_loss: 0.6886 - val_accuracy: 0.5800\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.6250 - val_loss: 0.6884 - val_accuracy: 0.5900\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.6300 - val_loss: 0.6881 - val_accuracy: 0.5900\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.6275 - val_loss: 0.6879 - val_accuracy: 0.5900\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.6375 - val_loss: 0.6878 - val_accuracy: 0.5900\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.6375 - val_loss: 0.6875 - val_accuracy: 0.5900\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.6375 - val_loss: 0.6873 - val_accuracy: 0.5900\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6864 - accuracy: 0.6375 - val_loss: 0.6871 - val_accuracy: 0.5900\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.6375 - val_loss: 0.6868 - val_accuracy: 0.6000\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.6375 - val_loss: 0.6866 - val_accuracy: 0.6000\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.6400 - val_loss: 0.6863 - val_accuracy: 0.6000\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.6425 - val_loss: 0.6860 - val_accuracy: 0.6000\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.6425 - val_loss: 0.6858 - val_accuracy: 0.6000\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.6475 - val_loss: 0.6855 - val_accuracy: 0.6100\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.6500 - val_loss: 0.6851 - val_accuracy: 0.6200\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6525 - val_loss: 0.6848 - val_accuracy: 0.6200\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.6500 - val_loss: 0.6846 - val_accuracy: 0.6200\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.6525 - val_loss: 0.6844 - val_accuracy: 0.6200\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.6575 - val_loss: 0.6841 - val_accuracy: 0.6300\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6841 - accuracy: 0.6575 - val_loss: 0.6837 - val_accuracy: 0.6300\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.6550 - val_loss: 0.6835 - val_accuracy: 0.6200\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.6550 - val_loss: 0.6831 - val_accuracy: 0.6200\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.6525 - val_loss: 0.6828 - val_accuracy: 0.6200\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.6575 - val_loss: 0.6825 - val_accuracy: 0.6200\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.6575 - val_loss: 0.6821 - val_accuracy: 0.6100\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.6600 - val_loss: 0.6818 - val_accuracy: 0.6100\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6625 - val_loss: 0.6815 - val_accuracy: 0.6200\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.6625 - val_loss: 0.6810 - val_accuracy: 0.6200\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.6525 - val_loss: 0.6806 - val_accuracy: 0.6200\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6450 - val_loss: 0.6803 - val_accuracy: 0.6200\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - accuracy: 0.6475 - val_loss: 0.6798 - val_accuracy: 0.6200\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - accuracy: 0.6425 - val_loss: 0.6794 - val_accuracy: 0.6200\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.6500 - val_loss: 0.6789 - val_accuracy: 0.6200\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.6375 - val_loss: 0.6783 - val_accuracy: 0.6200\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6275 - val_loss: 0.6777 - val_accuracy: 0.6200\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.6225 - val_loss: 0.6770 - val_accuracy: 0.6200\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.6125 - val_loss: 0.6763 - val_accuracy: 0.6100\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.6125 - val_loss: 0.6757 - val_accuracy: 0.6100\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.6050 - val_loss: 0.6751 - val_accuracy: 0.6100\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.6125 - val_loss: 0.6743 - val_accuracy: 0.6100\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.6125 - val_loss: 0.6735 - val_accuracy: 0.6100\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.6075 - val_loss: 0.6727 - val_accuracy: 0.6000\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.6050 - val_loss: 0.6718 - val_accuracy: 0.6000\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6000 - val_loss: 0.6708 - val_accuracy: 0.6000\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6713 - accuracy: 0.5950 - val_loss: 0.6699 - val_accuracy: 0.6000\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.5975 - val_loss: 0.6688 - val_accuracy: 0.5900\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.6000 - val_loss: 0.6677 - val_accuracy: 0.5800\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.6000 - val_loss: 0.6666 - val_accuracy: 0.5900\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6664 - accuracy: 0.6025 - val_loss: 0.6653 - val_accuracy: 0.5900\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6175 - val_loss: 0.6639 - val_accuracy: 0.5900\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.6125 - val_loss: 0.6625 - val_accuracy: 0.5800\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6175 - val_loss: 0.6610 - val_accuracy: 0.5800\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.6225 - val_loss: 0.6594 - val_accuracy: 0.5700\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6582 - accuracy: 0.6250 - val_loss: 0.6576 - val_accuracy: 0.5600\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6561 - accuracy: 0.6300 - val_loss: 0.6556 - val_accuracy: 0.5600\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6325 - val_loss: 0.6535 - val_accuracy: 0.5600\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6400 - val_loss: 0.6513 - val_accuracy: 0.5600\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.6450 - val_loss: 0.6490 - val_accuracy: 0.5800\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.6450 - val_loss: 0.6464 - val_accuracy: 0.5800\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6445 - accuracy: 0.6550 - val_loss: 0.6440 - val_accuracy: 0.5800\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6575 - val_loss: 0.6411 - val_accuracy: 0.5800\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6575 - val_loss: 0.6379 - val_accuracy: 0.5800\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6600 - val_loss: 0.6349 - val_accuracy: 0.6100\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6600 - val_loss: 0.6315 - val_accuracy: 0.6100\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6575 - val_loss: 0.6282 - val_accuracy: 0.6200\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.6625 - val_loss: 0.6245 - val_accuracy: 0.6400\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.6725 - val_loss: 0.6207 - val_accuracy: 0.6300\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.6775 - val_loss: 0.6166 - val_accuracy: 0.6300\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6825 - val_loss: 0.6124 - val_accuracy: 0.6300\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6875 - val_loss: 0.6085 - val_accuracy: 0.6500\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.6975 - val_loss: 0.6042 - val_accuracy: 0.6500\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.7075 - val_loss: 0.6000 - val_accuracy: 0.6800\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7175 - val_loss: 0.5958 - val_accuracy: 0.6800\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7200 - val_loss: 0.5919 - val_accuracy: 0.6800\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7200 - val_loss: 0.5879 - val_accuracy: 0.6800\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7250 - val_loss: 0.5838 - val_accuracy: 0.6800\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7275 - val_loss: 0.5795 - val_accuracy: 0.6800\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7300 - val_loss: 0.5756 - val_accuracy: 0.6800\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7325 - val_loss: 0.5716 - val_accuracy: 0.6800\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.7325 - val_loss: 0.5678 - val_accuracy: 0.6900\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7325 - val_loss: 0.5638 - val_accuracy: 0.7000\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7375 - val_loss: 0.5600 - val_accuracy: 0.7000\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.7375 - val_loss: 0.5559 - val_accuracy: 0.7100\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.7375 - val_loss: 0.5520 - val_accuracy: 0.7200\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7475 - val_loss: 0.5483 - val_accuracy: 0.7200\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7450 - val_loss: 0.5446 - val_accuracy: 0.7200\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7525 - val_loss: 0.5406 - val_accuracy: 0.7300\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7550 - val_loss: 0.5369 - val_accuracy: 0.7300\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7550 - val_loss: 0.5331 - val_accuracy: 0.7400\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7575 - val_loss: 0.5295 - val_accuracy: 0.7400\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7600 - val_loss: 0.5261 - val_accuracy: 0.7400\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7625 - val_loss: 0.5224 - val_accuracy: 0.7400\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7675 - val_loss: 0.5186 - val_accuracy: 0.7400\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7675 - val_loss: 0.5150 - val_accuracy: 0.7400\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7700 - val_loss: 0.5115 - val_accuracy: 0.7400\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7750 - val_loss: 0.5082 - val_accuracy: 0.7400\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7750 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7800 - val_loss: 0.5012 - val_accuracy: 0.7600\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7850 - val_loss: 0.4977 - val_accuracy: 0.7600\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7850 - val_loss: 0.4946 - val_accuracy: 0.7700\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7875 - val_loss: 0.4918 - val_accuracy: 0.7600\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7875 - val_loss: 0.4888 - val_accuracy: 0.7600\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7900 - val_loss: 0.4853 - val_accuracy: 0.7700\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7875 - val_loss: 0.4819 - val_accuracy: 0.7700\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7875 - val_loss: 0.4788 - val_accuracy: 0.7800\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7900 - val_loss: 0.4759 - val_accuracy: 0.7900\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.8000 - val_loss: 0.4724 - val_accuracy: 0.7900\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.8000 - val_loss: 0.4699 - val_accuracy: 0.8000\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.8025 - val_loss: 0.4667 - val_accuracy: 0.8100\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.8000 - val_loss: 0.4638 - val_accuracy: 0.8200\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.8050 - val_loss: 0.4605 - val_accuracy: 0.8200\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.8050 - val_loss: 0.4573 - val_accuracy: 0.8200\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8050 - val_loss: 0.4541 - val_accuracy: 0.8300\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.8050 - val_loss: 0.4512 - val_accuracy: 0.8400\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8100 - val_loss: 0.4481 - val_accuracy: 0.8400\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.8150 - val_loss: 0.4453 - val_accuracy: 0.8400\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8150 - val_loss: 0.4427 - val_accuracy: 0.8500\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8150 - val_loss: 0.4396 - val_accuracy: 0.8500\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8150 - val_loss: 0.4365 - val_accuracy: 0.8500\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8150 - val_loss: 0.4339 - val_accuracy: 0.8500\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8150 - val_loss: 0.4309 - val_accuracy: 0.8500\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8150 - val_loss: 0.4279 - val_accuracy: 0.8500\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8200 - val_loss: 0.4255 - val_accuracy: 0.8500\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8250 - val_loss: 0.4226 - val_accuracy: 0.8500\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8250 - val_loss: 0.4198 - val_accuracy: 0.8500\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8275 - val_loss: 0.4169 - val_accuracy: 0.8500\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8275 - val_loss: 0.4142 - val_accuracy: 0.8500\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8275 - val_loss: 0.4114 - val_accuracy: 0.8500\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8275 - val_loss: 0.4088 - val_accuracy: 0.8500\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8275 - val_loss: 0.4063 - val_accuracy: 0.8500\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8275 - val_loss: 0.4042 - val_accuracy: 0.8500\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8275 - val_loss: 0.4017 - val_accuracy: 0.8500\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8275 - val_loss: 0.3995 - val_accuracy: 0.8500\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8300 - val_loss: 0.3968 - val_accuracy: 0.8500\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8300 - val_loss: 0.3942 - val_accuracy: 0.8500\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8350 - val_loss: 0.3914 - val_accuracy: 0.8500\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8350 - val_loss: 0.3890 - val_accuracy: 0.8500\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8350 - val_loss: 0.3870 - val_accuracy: 0.8500\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8350 - val_loss: 0.3843 - val_accuracy: 0.8500\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8350 - val_loss: 0.3817 - val_accuracy: 0.8500\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8375 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3760 - accuracy: 0.8400 - val_loss: 0.3776 - val_accuracy: 0.8500\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8450 - val_loss: 0.3749 - val_accuracy: 0.8500\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8425 - val_loss: 0.3727 - val_accuracy: 0.8500\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8475 - val_loss: 0.3699 - val_accuracy: 0.8500\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8475 - val_loss: 0.3673 - val_accuracy: 0.8500\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8500 - val_loss: 0.3650 - val_accuracy: 0.8500\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8500 - val_loss: 0.3627 - val_accuracy: 0.8500\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3605 - accuracy: 0.8500 - val_loss: 0.3612 - val_accuracy: 0.8500\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8500 - val_loss: 0.3589 - val_accuracy: 0.8500\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8525 - val_loss: 0.3564 - val_accuracy: 0.8500\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8500 - val_loss: 0.3548 - val_accuracy: 0.8500\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8525 - val_loss: 0.3528 - val_accuracy: 0.8500\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8550 - val_loss: 0.3515 - val_accuracy: 0.8500\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8550 - val_loss: 0.3500 - val_accuracy: 0.8500\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8550 - val_loss: 0.3475 - val_accuracy: 0.8500\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8550 - val_loss: 0.3454 - val_accuracy: 0.8500\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8550 - val_loss: 0.3441 - val_accuracy: 0.8500\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.8575 - val_loss: 0.3428 - val_accuracy: 0.8500\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8575 - val_loss: 0.3406 - val_accuracy: 0.8500\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8575 - val_loss: 0.3401 - val_accuracy: 0.8500\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8600 - val_loss: 0.3379 - val_accuracy: 0.8500\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8600 - val_loss: 0.3355 - val_accuracy: 0.8500\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8600 - val_loss: 0.3341 - val_accuracy: 0.8500\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8600 - val_loss: 0.3338 - val_accuracy: 0.8500\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8625 - val_loss: 0.3328 - val_accuracy: 0.8500\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3251 - accuracy: 0.8650 - val_loss: 0.3316 - val_accuracy: 0.8500\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8650 - val_loss: 0.3288 - val_accuracy: 0.8500\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3220 - accuracy: 0.8650 - val_loss: 0.3278 - val_accuracy: 0.8500\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3207 - accuracy: 0.8675 - val_loss: 0.3272 - val_accuracy: 0.8500\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8675 - val_loss: 0.3257 - val_accuracy: 0.8500\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8700 - val_loss: 0.3237 - val_accuracy: 0.8500\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.8700 - val_loss: 0.3238 - val_accuracy: 0.8500\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8700 - val_loss: 0.3232 - val_accuracy: 0.8500\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8675 - val_loss: 0.3218 - val_accuracy: 0.8400\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8675 - val_loss: 0.3196 - val_accuracy: 0.8400\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8725 - val_loss: 0.3185 - val_accuracy: 0.8400\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3090 - accuracy: 0.8725 - val_loss: 0.3176 - val_accuracy: 0.8400\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8700 - val_loss: 0.3163 - val_accuracy: 0.8500\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3066 - accuracy: 0.8750 - val_loss: 0.3143 - val_accuracy: 0.8600\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8725 - val_loss: 0.3139 - val_accuracy: 0.8600\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8775 - val_loss: 0.3128 - val_accuracy: 0.8600\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8800 - val_loss: 0.3120 - val_accuracy: 0.8600\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.8800 - val_loss: 0.3118 - val_accuracy: 0.8600\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8825 - val_loss: 0.3111 - val_accuracy: 0.8600\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8825 - val_loss: 0.3094 - val_accuracy: 0.8600\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8825 - val_loss: 0.3098 - val_accuracy: 0.8600\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8800 - val_loss: 0.3088 - val_accuracy: 0.8600\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8800 - val_loss: 0.3082 - val_accuracy: 0.8700\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8800 - val_loss: 0.3078 - val_accuracy: 0.8600\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2928 - accuracy: 0.8825 - val_loss: 0.3067 - val_accuracy: 0.8600\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8825 - val_loss: 0.3048 - val_accuracy: 0.8600\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8850 - val_loss: 0.3033 - val_accuracy: 0.8600\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2895 - accuracy: 0.8850 - val_loss: 0.3036 - val_accuracy: 0.8600\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.8875 - val_loss: 0.3026 - val_accuracy: 0.8600\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.8875 - val_loss: 0.3018 - val_accuracy: 0.8600\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2860 - accuracy: 0.8875 - val_loss: 0.3011 - val_accuracy: 0.8600\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.8875 - val_loss: 0.2997 - val_accuracy: 0.8600\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8875 - val_loss: 0.3002 - val_accuracy: 0.8600\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.8900 - val_loss: 0.2980 - val_accuracy: 0.8600\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8900 - val_loss: 0.2980 - val_accuracy: 0.8500\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2803 - accuracy: 0.8875 - val_loss: 0.2968 - val_accuracy: 0.8500\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2790 - accuracy: 0.8900 - val_loss: 0.2958 - val_accuracy: 0.8500\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.8900 - val_loss: 0.2968 - val_accuracy: 0.8600\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8950 - val_loss: 0.2957 - val_accuracy: 0.8600\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2763 - accuracy: 0.8925 - val_loss: 0.2932 - val_accuracy: 0.8600\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.8950 - val_loss: 0.2916 - val_accuracy: 0.8500\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.8900 - val_loss: 0.2912 - val_accuracy: 0.8600\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8950 - val_loss: 0.2906 - val_accuracy: 0.8600\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8950 - val_loss: 0.2892 - val_accuracy: 0.8700\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8950 - val_loss: 0.2883 - val_accuracy: 0.8600\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8925 - val_loss: 0.2870 - val_accuracy: 0.8600\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.8925 - val_loss: 0.2874 - val_accuracy: 0.8700\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8950 - val_loss: 0.2862 - val_accuracy: 0.8700\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2668 - accuracy: 0.8975 - val_loss: 0.2860 - val_accuracy: 0.8700\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2658 - accuracy: 0.8975 - val_loss: 0.2852 - val_accuracy: 0.8800\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8925 - val_loss: 0.2844 - val_accuracy: 0.8800\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8975 - val_loss: 0.2836 - val_accuracy: 0.8800\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8950 - val_loss: 0.2828 - val_accuracy: 0.8800\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.9000 - val_loss: 0.2801 - val_accuracy: 0.8700\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2602 - accuracy: 0.8925 - val_loss: 0.2787 - val_accuracy: 0.8700\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.8975 - val_loss: 0.2755 - val_accuracy: 0.8700\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.8950 - val_loss: 0.2783 - val_accuracy: 0.8800\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.9000 - val_loss: 0.2764 - val_accuracy: 0.8700\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2561 - accuracy: 0.8975 - val_loss: 0.2766 - val_accuracy: 0.8800\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.9000 - val_loss: 0.2771 - val_accuracy: 0.8700\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9000 - val_loss: 0.2749 - val_accuracy: 0.8800\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.8975 - val_loss: 0.2743 - val_accuracy: 0.8800\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8960\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9040\n",
            "Training set accuracy: 0.8960000276565552\n",
            "Test set accuracy: 0.9039999842643738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nq6RMLzciwN"
      },
      "source": [
        "Let's next look at some training plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_BySHr13P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcfd538-93a0-4bdb-ed01-6ca8d5389862"
      },
      "source": [
        "history"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbb6fb5d7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpoIfuW8ciwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "36f8448a-18e9-4d23-bfca-e754f0ac244c"
      },
      "source": [
        "# The history of our accuracy during training.\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkivLoq-ciwU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "05d8c9a0-2244-4a62-fa23-7ebb3cc09576"
      },
      "source": [
        "# The history of our cross-entropy loss during training.\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZdrH8e89k16BJJSQQACRKoJE1oYFGwKCFQEV0VXEtay6uqvv7tq2qLviYsEuKjZUFEVFQRBkVRQCAoK0AAFCDYE0CKn3+8cc3BhDSCCTk2Tuz3XNlZlT5tyHCfPL85xzniOqijHGmMDlcbsAY4wx7rIgMMaYAGdBYIwxAc6CwBhjApwFgTHGBDgLAmOMCXAWBMZUQ0RSRERFJKgGy44Rka/roy5j6pIFgWkyRCRDRIpFJL7S9B+cL/MUdyqrXaAYU98sCExTsxEYefCFiBwHRLhXjjENnwWBaWpeB0ZXeH0NMLniAiISKyKTRSRLRDaJyF9ExOPM84rIYyKyW0Q2AIOrWPdlEdkuIltF5O8i4j2agkUkUUSmi8geEUkXkRsqzOsnImkikiciO0XkcWd6mIi8ISLZIpIjIotEpNXR1GEClwWBaWq+A2JEpJvzBT0CeKPSMk8BsUBH4Ax8wXGtM+8GYAjQB0gFLqu07qtAKXCMs8x5wPVHWfMUIBNIdLb3TxEZ4Mx7AnhCVWOATsC7zvRrnH1IBuKAcUDhUdZhApQFgWmKDrYKzgVWAVsPzqgQDveqar6qZgDjgaudRYYDE1R1i6ruAR6usG4rYBBwu6ruU9VdwH+c9zsiIpIMnAr8SVUPqOpS4CX+16opAY4RkXhVLVDV7ypMjwOOUdUyVV2sqnlHWocJbBYEpil6HRgFjKFStxAQDwQDmypM2wS0dZ4nAlsqzTuovbPudqc7Jgd4Hmh5FLUmAntUNf8Q9fwWOBZY7XT/DHGmvw7MBKaIyDYR+ZeIBB9FHSaAWRCYJkdVN+E7aDwI+KDS7N34/ppuX2FaO/7XatiOr7ul4ryDtgBFQLyqNnMeMara4yjK3Qa0EJHoqupR1XWqOhJf2DwKTBWRSFUtUdUHVbU7cAq+7qzRGHMELAhMU/VbYICq7qs4UVXL8PWz/0NEokWkPXAn/zuO8C5wm4gkiUhz4J4K624HZgHjRSRGRDwi0klEzqhFXaHOgd4wEQnD94X/LfCwM62XU/sbACJylYgkqGo5kOO8R7mInCUixzldXXn4wq28FnUY8zMLAtMkqep6VU07xOxbgX3ABuBr4C1gkjPvRXxdLsuAJfy6RTEaCAF+AvYCU4E2tSitAN9B3YOPAfhOd03B1zqYBtyvqrOd5QcCK0WkAN+B4xGqWgi0dradh+84yFf4uouMqTWxG9MYY0xgsxaBMcYEOAsCY4wJcBYExhgT4CwIjDEmwDW6kRDj4+M1JSXF7TKMMaZRWbx48W5VTahqXqMLgpSUFNLSDnVWoDHGmKqIyKZDzbOuIWOMCXAWBMYYE+AsCIwxJsA1umMExhhzJEpKSsjMzOTAgQNul+JXYWFhJCUlERxc88FoLQiMMQEhMzOT6OhoUlJSEBG3y/ELVSU7O5vMzEw6dOhQ4/Wsa8gYExAOHDhAXFxckw0BABEhLi6u1q0eCwJjTMBoyiFw0JHsY8AEwYqtuTz6+WpstFVjjPmlgAmCJZv38uy89Xy3YY/bpRhjAlBOTg7PPPNMrdcbNGgQOTk5h1/wKARMEAxPTSY+KpSJc9OtVWCMqXeHCoLS0tJq15sxYwbNmjXzV1lAAAVBWLCXcWd05Ov03Tzy2WrKyi0MjDH155577mH9+vX07t2bE088kf79+zN06FC6d+8OwEUXXUTfvn3p0aMHL7zwws/rpaSksHv3bjIyMujWrRs33HADPXr04LzzzqOwsLBOaguo00evO7UDGdn7eH7+BhZm7OG2AZ0549gEPJ6mfwDJGPM/D368kp+25dXpe3ZPjOH+C3sccv4jjzzCihUrWLp0KfPmzWPw4MGsWLHi59M8J02aRIsWLSgsLOTEE0/k0ksvJS4u7hfvsW7dOt5++21efPFFhg8fzvvvv89VV1111LX7tUUgIgNFZI2IpIvIPVXM/4+ILHUea0XErx1hHoG/DevJf644nm05hVz76iLOefwrnpi9jvRdBf7ctDHG/EK/fv1+ca7/k08+yfHHH89JJ53Eli1bWLdu3a/W6dChA7179wagb9++ZGRk1EktfmsRiIgXmAicC2QCi0Rkuqr+dHAZVb2jwvK3An38VQ/ps+HrCcjg8VzcpwuDj0vksxXbefP7zUyYs5b/zF5L19bRDD6uDYN7taFjQpTfSjHGuKu6v9zrS2Rk5M/P582bx+zZs1mwYAERERGceeaZVV4LEBoa+vNzr9fbKLqG+gHpqroBQESmAMOAnw6x/Ejgfr9VcyAPdiyHif2gWXtC2vZlWHxnhp3Uiewzk5i5PZJpq/cz/ou1jP9iLd3axHBut5ac1bUlxyc1s+4jY8xRiY6OJj8/v8p5ubm5NG/enIiICFavXs13331Xr7X5MwjaAlsqvM4EflPVgiLSHugAfHmI+WOBsQDt2rU7smp6XgIpp8Hyd2DLQtiaBiunAUocMAoYFd6c4pQObKYNafnNWfBVM+6b25q88GT6dk1hQNeW9O+cQGx4zcfwMMYYgLi4OE499VR69uxJeHg4rVq1+nnewIEDee655+jWrRtdunThpJNOqtfaxF+nUorIZcBAVb3eeX018BtVvaWKZf8EJKnqrYd739TUVK2zG9OUFsHeDMheD3vWV/i5AfIyf7HoHmLYUN6abRqPxrQlKqE9cW07EpfYgfiE1oRHN4fQGPB466Y2Y0ydWrVqFd26dXO7jHpR1b6KyGJVTa1qeX+2CLYCyRVeJznTqjICuNmPtVQtKBQSuvgelZUUwp6NPwdEs+x0umxbyzE5GUTuW0jwvlLI+PVqpQRRLl7KxYtKEOoJAk8QeLyoJ/jn5+IJAm8w4g3yPQ8KRYJDkeBwPMHhSEg4nqAwJDgcgsMhKMz5GQpB4RAc5vsZFOqbHhwBYTG+MAqNAU/AnBlsjDlK/gyCRUBnEemALwBG4OuB+QUR6Qo0Bxb4sZbaCw6HVt19D3ynV0UfnFdeTmHODjI2rCV/1yYKcndzIH8vJftyKCkporSkhLLSYspKSvBoGV7KCZYyvJQR9POj3HldQhAHCJEcwigmlBLCKCZMigmlmDCKCZGyWpWuCKVBkZSHRFMeGouGxiDhsXgPPiKa+cIiLNYXHmGxEBrr+xkZD2HNLEiMCSB+CwJVLRWRW4CZgBeYpKorReQhIE1VpzuLjgCmaGO63NfjIbxFIt1aJFa7mKqyr7iM3MISCovLKC4tp6j04M9yikvLyS8tp6TM97zY+fmL12XlFBUVU1xUSGlRISUH9lFaXEhZUSFaUkh5cSGUFuIpLSRKColhHzFSSEzpPqKLConO308MBUTLLmLYR7QUEs1+gqT8kHWXiZcDwc0pCYunLCIBiUogKKYVYS2SCG6ehMQmQ0wiRLWywDCmCfDrBWWqOgOYUWnafZVeP+DPGtwkIkSFBhEV6v/r9srLlcKSMvYVlbKv2Pdzv/Mzu7iULUVl7Csu9c0vKqW0MJ+yA3nogVykKA9vUR7e4lxCivYQXryHFiW5xBfmEp+zlThZRQK5hEjJL7ZZipe8oHgKQltRGJlEcUx7aNaO4BbJhMe3I6Zle2JjYu2MK2MauIC6srgp83iEyNAgIusgdFSV/KJS9u4rJntfMasLivm2oIj9ubsoy8mEvG0E79tGeOFOYop30rwgi8SChXTe+Rke+WXDLltj2C4tyQpqw97QtuRHtaeoeRci2vYgqWUL2sdFktQ8nGCvtSyMcYsFgfkVESEmLJiYsGDax0VWmNMOqPKkAw6UlLEzL5/8XZso3L2Z0r2ZaG4mwfmZRO7fQs8D6bTY9w3efeWwE8pWCZu0Fas1mY9JZk/kMQS17kGrlG70SI6jR2KsnaZrTD2xIDB1IizYS5u4ZrSJawYcX/VCZaWwdyO6cyUHMn+k2bYVnLZ7NefvW4znQDlkQNHGYNI1kc/KO7Am8kS8x5xFny4dOaljC+KiQqt+X2MagZycHN566y1+97vf1XrdCRMmMHbsWCIiIvxQmR+vI/CXOr2OwDQMJYWQtQZ2raIwczmFW1cQkfUDYaX5lKmwTDvxVdnxZDQ/mVZdT2JgryT6JDcLiLtNmbrj9nUEGRkZDBkyhBUrVtR63ZSUFNLS0oiPj6/R8g3pOgJjaiY4HBJ7Q2JvwnuPJBx8rYdtS2DdbLqsmkmfrA+QgvfZsyiaT7/7DS9GnEVKnwFcfXIHEpuFu70HxhxWxWGozz33XFq2bMm7775LUVERF198MQ8++CD79u1j+PDhZGZmUlZWxl//+ld27tzJtm3bOOuss4iPj2fu3Ll1XpsFgWmYvEGQ3A9vcj8iB/wf7N8D678kauXHjFz7OVcXz2bLdwm8/s055HYbyagze9OzbazbVZvG4rN7YMePdfuerY+DCx455OyKw1DPmjWLqVOnsnDhQlSVoUOHMn/+fLKyskhMTOTTTz8FfGMQxcbG8vjjjzN37twatwhqy4LANA4RLeC4ywg57jIoKoA1M2i58FX+lPk2hWvfZ9qq03i97QiuHjrQAsE0eLNmzWLWrFn06eMbcLmgoIB169bRv39//vCHP/CnP/2JIUOG0L9//3qpx4LAND6hUdBrOKG9hsOOFXi/fZbhK95j1M4v+ey5fnx+7M2MHjaQljFhbldqGqpq/nKvD6rKvffey4033vireUuWLGHGjBn85S9/4eyzz+a+++6r4h3qlp28bRq31j0JuWQiQX9YRdGpdzEgeAV3po/hy/FXMfW/P9r9qU2DUXEY6vPPP59JkyZRUOC7IdbWrVvZtWsX27ZtIyIigquuuoq7776bJUuW/Gpdf7AWgWkaIuMIPfevcOrN5M38B5cvm0Tu7AW8+sMNDLrmj7SK9c9pd8bUVMVhqC+44AJGjRrFySefDEBUVBRvvPEG6enp3H333Xg8HoKDg3n22WcBGDt2LAMHDiQxMdEvB4vt9FHTJJVvX8Gud2+j9d7FLKAXOuwZTulznNtlGRe5ffpofart6aPWNWSaJE+bnrS+bQ5ZZz5KH9bQ9cOBzJj+rnUVGVMFCwLTdImQcOY4ysfO40BIHOcsHscHr02gvNzCwJiKLAhMkxeR2J3Wt3/F9uheXJrxAJ8+ezclpbW7x4NpGgKhRXgk+2hBYAKCJ7I57X7/OWtbns+FWS8y68mbKCwqdbssU4/CwsLIzs5u0mGgqmRnZxMWVrtTp+2sIRMwJDiMY8dNYd2rNzJ48ztMmxjMoNueJDTI7jMdCJKSksjMzCQrK8vtUvwqLCyMpKSkWq1jQWACi8dD5zHPs2FSCRdnvsFHz4Qw+ObxBNn9EJq84OBgOnTo4HYZDZL99pvA4/HQ8bqXWdd6CMP2TOLTV/7RpLsLjDkcCwITmDxeOo+dzPrYk7lgy3+YMWP64dcxpomyIDCBy+MlZexb5Aa35ISFt/Pd8lVuV2SMKywITEDzRrYgavTbtJACZNpYsvIK3S7JmHpnQWACXni7PuSc8Td+o8uZ9/I9dsGZCTgWBMYArc68kYw2F3BJzmt88slUt8sxpl5ZEBgDIEL7a55nT3Brei/+P1Zs3Op2RcbUGwsCYxwSFkv45S+QJFlseOsuDpTYMBQmMFgQGFNBVJfT2dplDENLZvDhB2+5XY4x9cKCwJhKki97mN0hbem38h8sz9jpdjnG+J0FgTGVBYcTPuxxOnq2s2TK3ykpK3e7ImP8yoLAmCpE9hjIzrbncUXhFN6Z/Y3b5RjjVxYExhxCq8sfx+PxEP/NQ2zK3ud2Ocb4jQWBMYfSLJnik3/PQM9C3pryug1MZ5osCwJjqhF91h3khyVy8c6n+XTpFrfLMcYvLAiMqU5wOBEXPkJXzxZWfTyBvAMlbldkTJ3zaxCIyEARWSMi6SJyzyGWGS4iP4nIShGxE7dNg+PtPpT8NqdwQ9kUnp2xyO1yjKlzfgsCEfECE4ELgO7ASBHpXmmZzsC9wKmq2gO43V/1GHPERIi+aDzRcoC2P4xneWaO2xUZU6f82SLoB6Sr6gZVLQamAMMqLXMDMFFV9wKo6i4/1mPMkWvVndK+1zHS+yUvvjedMhuh1DQh/gyCtkDFo2uZzrSKjgWOFZFvROQ7ERnox3qMOSqh5/yZ0pAYrto7kTe/y3C7HGPqjNsHi4OAzsCZwEjgRRFpVnkhERkrImkikpaVlVXPJRrjCG9OyLn38RvPapbPfJVdeQfcrsiYOuHPINgKJFd4neRMqygTmK6qJaq6EViLLxh+QVVfUNVUVU1NSEjwW8HGHI70HUNRfHfu5HUe+fgHt8sxpk74MwgWAZ1FpIOIhAAjgMp3CP8QX2sAEYnH11W0wY81GXN0PF5CLxxPomTTbtULzF9rLVTT+PktCFS1FLgFmAmsAt5V1ZUi8pCIDHUWmwlki8hPwFzgblXN9ldNxtSJ9qdQ1v1ibgr6hInTvrT7FphGTxrbZfOpqamalpbmdhkm0OVmUvZkXz4v7sXa0ydyx7nHul2RMdUSkcWqmlrVPLcPFhvTOMUm4e1/J4O9C1ny1XQ2ZBW4XZExR8yCwJgjdeptlMUk89eg17j/w2U2KJ1ptCwIjDlSweF4B/6DY9lM+4z3mL5sm9sVGXNELAiMORrdhqIp/flTyHs8+fH35BbaoHSm8bEgMOZoiCAXPEoU+xlT/BaPzVzjdkXG1JoFgTFHq1UPJPW3XOmdQ9rC/7J0iw1KZxoXCwJj6sJZ/4eExfLP0Nf48wfLKbUb3ptGxILAmLoQ0QI59wH66Cq67/qYyQs2uV2RMTVmQWBMXekzGk0+iftCpzDpizR25NqgdKZxsCAwpq54PMiFE4hiP3fqZP72yU9uV2RMjVgQGFOXWnZDTrmNSzzzyV45h7lr7F5LpuGzIDCmrp1+N9qsPf8OncTfPvzBBqUzDZ4FgTF1LSQCGfw4ybqNIXnv8vSX6W5XZEy1LAiM8YfO50CPS7g1ZDoz539N+i4blM40XBYExvjLwIfxhoTx9+BJ/GXachuUzjRYFgTG+Et0azzn3M9vWEHrTR8z7YfKd2o1pmGwIDDGn/peh7ZN5cHQN3nqk4Xk7C92uyJjfsWCwBh/8niQC58ghgLGlUzm0c9tUDrT8FgQGONvrXsiJ9/MFd65rFs0i8Wb9rpdkTG/YEFgTH048x7KY5P5V9gr3P/BEkpsUDrTgFgQGFMfQiLxDHqMjrqF03e/w3Pz1rtdkTE/syAwpr50GQjdhnJ7yDQ+/PJr1u3Md7siYwALAmPq1wWPEhQcwkPBr3D3e8soK7drC4z7LAiMqU8xiXjOvo9TWUbyts945ZuNbldkjAWBMfXuxOvRxD78PexNXpqVxqbsfW5XZAKcBYEx9c3jRYY+RQz5/NkzmXve/9GGnzCusiAwxg2tj0P638WF8l8iM2YxZdEWtysyAcyCwBi39P8D2qoH/w57hac/XcT23EK3KzIByoLAGLcEhSDDnqGZ5nKXvspfpq2wLiLjCgsCY9yU2Bs57Q4u9synbO0spi/b5nZFJgBZEBjjtjP+iCZ05bGwSTz20UJ25R9wuyITYCwIjHFbUCgy7BnidA+3lE3mj1PtJjamflkQGNMQJPVFTr6FKzxfwroveOP7zW5XZAKIBYExDcVZf0YTujEh7CUmfvo967PsPsemfvg1CERkoIisEZF0EbmnivljRCRLRJY6j+v9WY8xDVpwGHLJC8SSz9+8L3HHlB9suGpTL/wWBCLiBSYCFwDdgZEi0r2KRd9R1d7O4yV/1WNMo9CmFzLgz5zL93Ta/ilPzlnndkUmANQoCEQkUkQ8zvNjRWSoiAQfZrV+QLqqblDVYmAKMOzoyjUmAJxyG7Q7mX+GTebDuQtYvGmP2xWZJq6mLYL5QJiItAVmAVcDrx5mnbZAxevmM51plV0qIstFZKqIJFf1RiIyVkTSRCQtKyurhiUb00h5vHDxc4QFe5gY/ix3TVlCQVGp21WZJqymQSCquh+4BHhGVS8HetTB9j8GUlS1F/AF8FpVC6nqC6qaqqqpCQkJdbBZYxq45inIkAn0Kl/NRflv8tDHK92uyDRhNQ4CETkZuBL41JnmPcw6W4GKf+EnOdN+pqrZqlrkvHwJ6FvDeoxp+o67DI4fya1BH7JjyafMXLnD7YpME1XTILgduBeYpqorRaQjMPcw6ywCOotIBxEJAUYA0ysuICJtKrwcCqyqYT3GBIZBj0HLbjwT+jTPTv2MXXl21bGpezUKAlX9SlWHquqjzkHj3ap622HWKQVuAWbi+4J/1wmRh0RkqLPYbSKyUkSWAbcBY454T4xpikKj8IyaQlhYGP8pf4T73ltgVx2bOic1+aUSkbeAcUAZvr/0Y4AnVPXf/i3v11JTUzUtLa2+N2uMuzZ9S/krg5la2p+iwU9y9ckpbldkGhkRWayqqVXNq2nXUHdVzQMuAj4DOuA7c8gYUx/an4KcdgfDg75iwYzXSd9lVx2bulPTIAh2rhu4CJiuqiWAtU+NqUdy5j2UtDyOv3tf4MG3v6S41K46NnWjpkHwPJABRALzRaQ9kOevoowxVQgKIfiyF4n1FjNu9yM8NXu12xWZJqKmB4ufVNW2qjpIfTYBZ/m5NmNMZS274R0ynlO9Kwn6+t921bGpEzUdYiJWRB4/eHWviIzH1zowxtS3PldR0nMEtwZN4/W3XiP/QInbFZlGrqZdQ5OAfGC488gDXvFXUcaY6gUPfZyiZsfwlwOP8693Ztsppeao1DQIOqnq/c4AchtU9UGgoz8LM8ZUIySS8FFvEB1UzrXrb+e9+T+4XZFpxGoaBIUictrBFyJyKlDon5KMMTXSsivBo98n2ZNN6zm3s3yLHS8wR6amQTAOmCgiGSKSATwN3Oi3qowxNeJpfxLF5z7M6Z5lLJj8V3IL7XiBqb2anjW0TFWPB3oBvVS1DzDAr5UZY2ok8pTr2dPhQq4vfpPnJ79uxwtMrdXqDmWqmudcYQxwpx/qMcbUlggtrniGgohkRm97iDe/XOx2RaaROZpbVUqdVWGMOTphMcSMfoM4TwHtvrqDtI273a7INCJHEwTW/jSmAZE2x1N63sOc7lnOd6/fx45cG7La1Ey1QSAi+SKSV8UjH0ispxqNMTUUftL15B0zjJvK3uLpl1/mQEmZ2yWZRqDaIFDVaFWNqeIRrapB9VWkMaaGRIi57GkKYzpwZ+4/Gf/OLDt4bA7raLqGjDENUVgMUWOmEhEkXLr2bt6Yb/c7NtWzIDCmKYrrRMiIyRzr2UqrOb/n23W73K7INGAWBMY0UZ7OAyg++2+c50ljxZv3sGXPfrdLMg2UBYExTVjYaTeT320EY3mf11+ewP7iUrdLMg2QBYExTZkI0Zc+SW78CdxR8B+efON9O3hsfsWCwJimLiiU2DHvUBbWnKs33ctrXyxyuyLTwFgQGBMIoloSec07JHgK6PH1zcz7aYvbFZkGxILAmAAhiX1g2ERO9Kwl+93b2JhV4HZJpoGwIDAmgIT0vpzcE3/PpXzJpy8/aLe5NIAFgTEBJ/aCB8hOOodxhS/x8qsvUl5uB48DnQWBMYHG4yHu6lfJjT6GG7ffz9QP3nW7IuMyCwJjAlFoNC3GzSAvtDXn/ngn8xcscLsi4yILAmMClEQl0Oz6D/F6PCR/fi0r0je5XZJxiQWBMQEstGUnyq94g7aSxf43ryRzd67bJRkXWBAYE+CadT2DvQMeo5/+yLIXbiCvsNjtkkw9syAwxtDq9GvJ7HkTg4tn8vHzf6akrNztkkw9siAwxgCQdMk/2dLmPEbufZG3Jz9rYxIFEAsCY4yPx0Pyta+xM7o7V2Tcz/QP33G7IlNPLAiMMf8TEkGrcR+THdqWc5bexjdzZ7hdkakHfg0CERkoImtEJF1E7qlmuUtFREUk1Z/1GGMOzxMV57vGICiOPvPGsO7r990uyfiZ34JARLzAROACoDswUkS6V7FcNPB74Ht/1WKMqZ2wFm0Ju/ELNnuTaDf7RnYu+8Ltkowf+bNF0A9IV9UNqloMTAGGVbHc34BHgQN+rMUYU0vNWyYRdu2HZNKKZtNGse/HT90uyfiJP4OgLVBx0PNMZ9rPROQEIFlVq/0NE5GxIpImImlZWVl1X6kxpkopye3IGT6NteVtCX7/GorW/9ftkowfuHawWEQ8wOPAHw63rKq+oKqpqpqakJDg/+KMMT/r2/1YMoe8yebyBMreuIKSbcvdLsnUMX8GwVYgucLrJGfaQdFAT2CeiGQAJwHT7YCxMQ3PBf168OOAV8gpD2X/y8Moy97odkmmDvkzCBYBnUWkg4iEACOA6QdnqmquqsaraoqqpgDfAUNVNc2PNRljjtDFZ57EV/2eR0uL2Pv8ELRgl9slmTrityBQ1VLgFmAmsAp4V1VXishDIjLUX9s1xvjPyMHnMb3HBCKLdrF74vmQs9ntkkwdkMZ2GXlqaqqmpVmjwRi3qCovvf4aV6y/F09YFFE3zYFm7dwuyxyGiCxW1Sq73u3KYmNMrYgI1111DRNTnqD8QAE5LwyBAjubrzGzIDDG1JrXI9w1+jKeT3qE0H3b2f38hXAgz+2yzBGyIDDGHJFgr4fbr7uaF9s8QGzeWrKeHWTHDBopCwJjzBEL9noYd/1NvNDqPsJy0il85kzYm+F2WaaWLAiMMUclJMjD9WNv5dG2T1NUdIDcF4bAXrv/cWNiQWCMOWqhQV7uu+4SXmz3L9ifTd6z56K5Ww+/omkQLAiMMXUiJMjDnddeyWvHPo2nKJedz15I+f4ct8syNWBBYIypM16PcOuoS/i426PEFWaw/ulhlBbmu12WOQwLAmNMnRIRRo4Yw7xuD9Bx3zIynryAEmsZNGgWBMYYvzh3xG18ddzDtN//E9snnE3h1hVul2QOwYLAGOM3Ay67ifl9nyCqaAfy4gD2rpztdkmmChYExhi/Onvo1ay6+Au2aAJh741i14o5bpdkKrEgMMb43ahnyqcAABHCSURBVKm9u7N/5DS2E0/s1BFkzXwMGtmAl02ZBYExpl4c3/VYSq76mO/keBIW/I3syVfD/j1ul2WwIDDG1KMux3Si4y0f8WLI1TTb8AnFE3pD2iRrHbjMgsAYU6+S4yK57PePc3fcRNIK28Ind6Az/8/CwEUWBMaYetc8MoR/3jSCN7s8zSul5yPfPUP5J3dCaZHbpQUkCwJjjCvCgr08NeoEdpz8AM+VDsGzeBLlT6XC8vesdVDPLAiMMa7xeIR7B3cncsg/GV18LxsKguGD6+GT22F3utvlBQwLAmOM664+qT1jRl/LxaX/4BWGweJX4em+sGCi26UFBAsCY0yDMKBrKz68pT9vx/6Ws4rHkx4/AGb+H3z9H7dLa/IsCIwxDUanhCg+vPlUevXqy/mZ17IgcgDMfgAmD4P/Pg45W9wusUmyIDDGNCgRIUFMuKI39w/rxZic3/JU8LWU7FwDcx6EJ3vDtJvsQrQ6FuR2AcYYU5mIMPrkFHq2jeXmN8N5Kvd8xp/Xggv3TYO0l333RR71DoTFuF1qk2AtAmNMg3VCu+Z8cutpnJjSnFtn7Oam7MvJG/gUbP4WHu8GU66ELQvdLrPRsyAwxjRocVGhTL7uN9x9fhfmrNrFGZ+14Kszp6I9L/WFwMvnwpf/gF2roeSA2+U2SqKN7MKN1NRUTUtLc7sMY4wL1u3M566py1m2JYfzurfiH4NTSJj/V1j2lm8Bbyj0vQYG/NW6jSoRkcWqmlrlPAsCY0xjUlpWzstfb2T8F2sJD/by4IXdGRa7Dtm3GzZ+BUvfhFY94Io3oXl7t8ttMKoLAusaMsY0KkFeDzee0YkZt/WnU0Ikt7+7jBu+jmJbuyEw7GkY9R5kr4cn+8D718P25W6X3OBZi8AY02iVlSuvfLORf89cgwjceHonxp3RifDCHfDdM74rlIsLIPU6GPgoBIW4XbJrrGvIGNOkZe7dz8OfrebT5dtpExvGnwZ2ZVjvRORALsz/Nyx4GjzB0PEMOGE0pPSH8OYg4nbp9caCwBgTEBZu3MNDn6xkxdY8+neO558XH0dyiwhInw3r58LKaZC31bdwTBL0ux66XwQRcU3+4LIFgTEmYJSXK28u3Mw/P11FaXk5o/q14+YBx9AyOgzKy2DDPNi1CtZ/Cevn+FYKjoCug6HzedDpbIiMc3Uf/MGCwBgTcHbkHuDJL9fx7qItBHmFa0/twLjTOxEbEexbQBXWzoT8bbDtB1g9A/bvBgS6D4OhTzWpVoJrQSAiA4EnAC/wkqo+Umn+OOBmoAwoAMaq6k/VvacFgTGmNjJ272PC7LV8tGwbUaFBjDujE2NOSSEytNIIO+XlsP0H+Gk6fPsUNGsHx13u6zY67jKIjHdnB+qIK0EgIl5gLXAukAksAkZW/KIXkRhVzXOeDwV+p6oDq3tfCwJjzJFYvSOP8bPW8sVPO4mPCuHms45h1G/aERrk/fXCGd/A9Ftgzwbfa08wHHMO9LwEelwM4gVP4zr73q0gOBl4QFXPd17fC6CqDx9i+ZHAaFW9oLr3tSAwxhyNJZv38tjMNXy7PpvE2DBuP+dYLjmhLUHeSl/s5eVQVuwLgx9eh1WfQO5mXyhEt4FLnoeErhDRwp0dqSW3guAyYKCqXu+8vhr4jareUmm5m4E7gRBggKquq+K9xgJjAdq1a9d306ZNfqnZGBM4vknfzb9mrmHZlhxS4iK4+axjuKhPW4IrB8JB5eXw47uwfRms+AAKdvhCoddwSOwD+duhz1XQomP97kgNNeggqLD8KOB8Vb2muve1FoExpq6oKl/8tJMn5qxj5bY82rWI4OazOnFxnyRCgqrp+snfARvnQ2aar7VQsh8QCAqFK6dCh/71tg811Vi6hjzAXlWNre59LQiMMXVNVfly9S6emLOO5Zm5tG0Wzu/O6sTlfZOrDwTw3SQnfweEN4PXL/bdK+H0u3wXrbXtC97getmHw3ErCILwHSw+G9iK72DxKFVdWWGZzge7gkTkQuD+QxV6kAWBMcZfVJV5a7N4YvY6lm7JITE2jJvO7MTwE5OrPqhcWUEWfHQzrJvpex3eAs74I/QdA8Hhfq39cNw8fXQQMAHf6aOTVPUfIvIQkKaq00XkCeAcoATYC9xSMSiqYkFgjPE3VeW/63bzxJx1LN60l9YxYYw7oyMj+rUjLPgwgaAKuVtg21JY9JJvRNSIeOdsIw+ccDXEH+vrRqpHdkGZMcYcAVXl2/XZPDF7HQsz9pAQHcq4Mzoxql87wkNq0EJQhU3fwjdP+K5iFi+UFfl+djzDFw5dh9TLmUcWBMYYc5QWrM/miTlr+W7DHuIiQ7jutA5cfXJ7YsJqeAxA1Xc8YdV02LMeVn3sO57gCYJOA+DCJyAm0W/1WxAYY0wdWbhxD0/PTWf+2iyiQ4MYfUp7xvavMHRFTanC9qWw8kNfF1KLjnDlexDd2i91WxAYY0wdW7E1l2fnrWfGiu2EB3sZdFwbLu+bRL8OLZDaDm+97guYMsrXOrjoGd9oqX2vhbhOULAL4jof9ZXMFgTGGOMnq7bn8eo3GXyyfBv7isvolBDJX4Z058xjE2oXCHs2wBuX+bqNKus2FAY/DlEJR1ynBYExxvjZ/uJSPvtxB0/PTWfj7n10SohkZL92jOjXjqjKA9wdyvZlMG0cnHaH73abIZFQlOe7uQ7AoMeg3w1HVJ8FgTHG1JMDJWV8vGwbby/czJLNOcSEBXHlSe0Z1juRrq2PcFjrHT/6hsw+diC07nlEb2FBYIwxLli6JYfn5q1n5k87UIV+HVrwx/O7kJpS/wPVWRAYY4yLsvKL+GjpVl787wZ25hXRvU0Mw1OTuCw1uebdRkfJgsAYYxqA/cWlvJeWydTFmfy4NZeYsCCuOSWFMaekEBfl3yuNLQiMMaaBqdhtFBrk4YrUZK7v35HkFhF+2Z4FgTHGNFDpuwp4Yf56pv2wlbJy5cSUFlx7agrndW+Nx1PL6xGqYUFgjDEN3PbcQt7+fjMfLdvGpuz9dGkVzS0DjmHQcW3w1kEgWBAYY0wjUVaufLJ8G099mU76rgI6JURy64DODO7V5tB3T6sBCwJjjGlkysqVz1Zs56k56azZmU/ziGAeGNqDYb3bHtH7VRcE9XPekjHGmFrxeoQhvRIZ1LMN89bu4oMlW2nbzD83t7EgMMaYBszjEQZ0bcWArq38tw2/vbMxxphGwYLAGGMCnAWBMcYEOAsCY4wJcBYExhgT4CwIjDEmwFkQGGNMgLMgMMaYANfohpgQkSxg0xGuHg/srsNy3GT70jDZvjRMti/QXlUTqprR6ILgaIhI2qHG2mhsbF8aJtuXhsn2pXrWNWSMMQHOgsAYYwJcoAXBC24XUIdsXxom25eGyfalGgF1jMAYY8yvBVqLwBhjTCUWBMYYE+ACJghEZKCIrBGRdBG5x+16aktEMkTkRxFZKiJpzrQWIvKFiKxzfjZ3u86qiMgkEdklIisqTKuydvF50vmclovICe5V/muH2JcHRGSr89ksFZFBFebd6+zLGhE5352qf01EkkVkroj8JCIrReT3zvRG97lUsy+N8XMJE5GFIrLM2ZcHnekdROR7p+Z3RCTEmR7qvE535qcc0YZVtck/AC+wHugIhADLgO5u11XLfcgA4itN+xdwj/P8HuBRt+s8RO2nAycAKw5XOzAI+AwQ4CTge7frr8G+PADcVcWy3Z3ftVCgg/M76HV7H5za2gAnOM+jgbVOvY3uc6lmXxrj5yJAlPM8GPje+fd+FxjhTH8OuMl5/jvgOef5COCdI9luoLQI+gHpqrpBVYuBKcAwl2uqC8OA15znrwEXuVjLIanqfGBPpcmHqn0YMFl9vgOaiUib+qn08A6xL4cyDJiiqkWquhFIx/e76DpV3a6qS5zn+cAqoC2N8HOpZl8OpSF/LqqqBc7LYOehwABgqjO98udy8POaCpwtIlLb7QZKELQFtlR4nUn1vygNkQKzRGSxiIx1prVS1e3O8x2A/25qWvcOVXtj/axucbpMJlXoomsU++J0J/TB99dno/5cKu0LNMLPRUS8IrIU2AV8ga/FkqOqpc4iFev9eV+c+blAXG23GShB0BScpqonABcAN4vI6RVnqq9t2CjPBW7MtTueBToBvYHtwHh3y6k5EYkC3gduV9W8ivMa2+dSxb40ys9FVctUtTeQhK+l0tXf2wyUINgKJFd4neRMazRUdavzcxcwDd8vyM6DzXPn5y73Kqy1Q9Xe6D4rVd3p/OctB17kf90MDXpfRCQY3xfnm6r6gTO5UX4uVe1LY/1cDlLVHGAucDK+rrggZ1bFen/eF2d+LJBd220FShAsAjo7R95D8B1Ume5yTTUmIpEiEn3wOXAesALfPlzjLHYN8JE7FR6RQ9U+HRjtnKVyEpBboauiQarUV34xvs8GfPsywjmzowPQGVhY3/VVxelHfhlYpaqPV5jV6D6XQ+1LI/1cEkSkmfM8HDgX3zGPucBlzmKVP5eDn9dlwJdOS6523D5KXl8PfGc9rMXX3/Znt+upZe0d8Z3lsAxYebB+fH2Bc4B1wGyghdu1HqL+t/E1zUvw9W/+9lC14ztrYqLzOf0IpLpdfw325XWn1uXOf8w2FZb/s7Mva4AL3K6/Ql2n4ev2WQ4sdR6DGuPnUs2+NMbPpRfwg1PzCuA+Z3pHfGGVDrwHhDrTw5zX6c78jkeyXRtiwhhjAlygdA0ZY4w5BAsCY4wJcBYExhgT4CwIjDEmwFkQGGNMgLMgMA2WiKiIjK/w+i4ReaCO3vtVEbns8Ese9XYuF5FVIjLX39uqtN0xIvJ0fW7TNF4WBKYhKwIuEZF4twupqMIVnjXxW+AGVT3LX/UYc7QsCExDVorv/qx3VJ5R+S96ESlwfp4pIl+JyEciskFEHhGRK50x3n8UkU4V3uYcEUkTkbUiMsRZ3ysi/xaRRc5gZTdWeN//ish04Kcq6hnpvP8KEXnUmXYfvoudXhaRf1exzt0VtnNw3PkUEVktIm86LYmpIhLhzDtbRH5wtjNJREKd6SeKyLfiG8N+4cGr0IFEEflcfPcW+FeF/XvVqfNHEfnVv60JPLX5y8YYN0wElh/8Iquh44Fu+IaL3gC8pKr9xHfDkluB253lUvCNP9MJmCsixwCj8Q2fcKLzRfuNiMxylj8B6Km+oYt/JiKJwKNAX2AvvlFiL1LVh0RkAL4x8dMqrXMevqEN+uG7ane6M5DgZqAL8FtV/UZEJgG/c7p5XgXOVtW1IjIZuElEngHeAa5Q1UUiEgMUOpvpjW8kziJgjYg8BbQE2qpqT6eOZrX4dzVNlLUITIOmvlEkJwO31WK1Reobo74I3zACB7/If8T35X/Qu6parqrr8AVGV3zjOI0W3zDA3+MbcqGzs/zCyiHgOBGYp6pZ6hsK+E18N7CpznnO4wdgibPtg9vZoqrfOM/fwNeq6AJsVNW1zvTXnG10Abar6iLw/Xvp/4YrnqOquap6AF8rpr2znx1F5CkRGQj8YsRRE5isRWAagwn4vixfqTCtFOcPGRHx4Lvz3EFFFZ6XV3hdzi9/5yuPr6L4/jq/VVVnVpwhImcC+46s/CoJ8LCqPl9pOymHqOtIVPx3KAOCVHWviBwPnA+MA4YD1x3h+5smwloEpsFT1T34btX32wqTM/B1xQAMxXcnp9q6XEQ8znGDjvgGIJuJr8slGEBEjnVGfK3OQuAMEYkXES8wEvjqMOvMBK4T3xj6iEhbEWnpzGsnIic7z0cBXzu1pTjdVwBXO9tYA7QRkROd94mu7mC2c+Ddo6rvA3/B191lApy1CExjMR64pcLrF4GPRGQZ8DlH9tf6Znxf4jHAOFU9ICIv4es+WuIMb5zFYW4BqqrbReQefEMFC/CpqlY7JLiqzhKRbsAC32YoAK7C95f7Gnw3H5qEr0vnWae2a4H3nC/6RfjuVVssIlcATznDFhcC51Sz6bbAK04rCuDe6uo0gcFGHzWmAXG6hj45eDDXmPpgXUPGGBPgrEVgjDEBzloExhgT4CwIjDEmwFkQGGNMgLMgMMaYAGdBYIwxAe7/AafBJYWthBZZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXPkBbXs7Uqa"
      },
      "source": [
        "### b) Analyzing model performance (5 points)\n",
        "What was your model's final prediction accuracy on the test set? Explain the pattern/trend you have observed in the previous two plots in your own words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW4NHPHi78Fu"
      },
      "source": [
        "The final prediction accuracy is 0.9040.\\\n",
        "As the number of epochs increases, the training and test accuracy gradually increases and the loss decrease.\\\n",
        "The most significant change happens between epoch 100 - 200."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-UNwaIt_HgR"
      },
      "source": [
        "### c) Decision Boundary (5 points)\n",
        "Plot the decisin boundary of the network you built (using the code below) and explain what you observe and why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYDz8YyPciwW"
      },
      "source": [
        "The following code will allow us to visualize our deep neural network's decision boundary. Let's observe.\n",
        "\n",
        "This will take a moment to construct the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs6FGaHKciwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "7845d29a-7267-4d16-e560-3324d7262a90"
      },
      "source": [
        "#\n",
        "# This code is substantively from https://rohitmidha23.github.io/Neural-Network-Decision-Boundary/\n",
        "#\n",
        "def plot_decision_boundary(X, y, model, steps=1000, cmap='bwr'):\n",
        "    # The following allows you to adjust the plot size\n",
        "    rcParams['figure.figsize'] = 8, 6  # 8 inches by 6 inches\n",
        "    cmap = plt.get_cmap(cmap)\n",
        "\n",
        "    # Define region of interest by data limits\n",
        "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "    x_span = np.linspace(xmin, xmax, steps)\n",
        "    y_span = np.linspace(ymin, ymax, steps)\n",
        "    xx, yy = np.meshgrid(x_span, y_span)\n",
        "\n",
        "    # Make predictions across region of interest\n",
        "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Plot decision boundary in region of interest\n",
        "    z = labels.reshape(xx.shape)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
        "\n",
        "    # Get predicted labels on training data and plot\n",
        "    train_labels = model.predict(X)\n",
        "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "plot_decision_boundary(test_data, test_labels, model) \n",
        "# Reset figure size back to default.\n",
        "rcParams['figure.figsize'] = 6, 4"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLtd20xC2Mj3"
      },
      "source": [
        "The decision boundary is not perfect, but mostly accuracy. There are some part of blue and red crosing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak3Y2clPLZpv"
      },
      "source": [
        "## Problem 4 - Fish Data revisited "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wiXAk_ILy2N"
      },
      "source": [
        "We will revist the \"Fish\" dataset and train a regression neural network on the features \"Length1\", \"Length2\", \"Length3\",\t\"Height\", and \"Width\" to predict Weight. Run or fill in the following cells and answer written response questions for each section. Begin by downloading \"Fish.csv\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMy-21iKABVc"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTvM0_JzABVc"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLDSqS7_JD0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "93f3085c-ae84-49db-a718-cb756bc1738c"
      },
      "source": [
        "# Download the Fish data\n",
        "downloaded = drive.CreateFile({'id':\"1AtMi-xCejVlhYS5qjgjjW4gH-TLuWJjC\"})\n",
        "downloaded.GetContentFile('Fish.csv')  \n",
        "\n",
        "# Create pandas dataframe\n",
        "fish_data = pd.read_csv('Fish.csv')\n",
        "\n",
        "# Delete any rows for which there is a measurement of 0.0.\n",
        "fish_data = fish_data.drop( np.where(fish_data==0)[0] )\n",
        "fish_data.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>242.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>25.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.5200</td>\n",
              "      <td>4.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>290.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>31.2</td>\n",
              "      <td>12.4800</td>\n",
              "      <td>4.3056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>340.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>26.5</td>\n",
              "      <td>31.1</td>\n",
              "      <td>12.3778</td>\n",
              "      <td>4.6961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>363.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.5</td>\n",
              "      <td>12.7300</td>\n",
              "      <td>4.4555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>430.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>12.4440</td>\n",
              "      <td>5.1340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
              "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
              "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
              "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
              "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
              "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IZwN2j4yIaX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "52079b35-e359-4021-e12b-d441865c445e"
      },
      "source": [
        "fish_data.describe()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>400.847468</td>\n",
              "      <td>26.293038</td>\n",
              "      <td>28.465823</td>\n",
              "      <td>31.280380</td>\n",
              "      <td>8.986790</td>\n",
              "      <td>4.424232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>357.697796</td>\n",
              "      <td>10.011427</td>\n",
              "      <td>10.731707</td>\n",
              "      <td>11.627605</td>\n",
              "      <td>4.295191</td>\n",
              "      <td>1.689010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.900000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>1.728400</td>\n",
              "      <td>1.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>121.250000</td>\n",
              "      <td>19.150000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.200000</td>\n",
              "      <td>5.940600</td>\n",
              "      <td>3.398650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>281.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>29.700000</td>\n",
              "      <td>7.789000</td>\n",
              "      <td>4.277050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>650.000000</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>35.750000</td>\n",
              "      <td>39.675000</td>\n",
              "      <td>12.371850</td>\n",
              "      <td>5.586750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1650.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>63.400000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>18.957000</td>\n",
              "      <td>8.142000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Weight     Length1     Length2     Length3      Height       Width\n",
              "count   158.000000  158.000000  158.000000  158.000000  158.000000  158.000000\n",
              "mean    400.847468   26.293038   28.465823   31.280380    8.986790    4.424232\n",
              "std     357.697796   10.011427   10.731707   11.627605    4.295191    1.689010\n",
              "min       5.900000    7.500000    8.400000    8.800000    1.728400    1.047600\n",
              "25%     121.250000   19.150000   21.000000   23.200000    5.940600    3.398650\n",
              "50%     281.500000   25.300000   27.400000   29.700000    7.789000    4.277050\n",
              "75%     650.000000   32.700000   35.750000   39.675000   12.371850    5.586750\n",
              "max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH5esQZKdLNX"
      },
      "source": [
        "### a) Data Preprocessing (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yGF14XXidKS"
      },
      "source": [
        "Recall from the previous lectures and class excercises that it is especially important to normalize data for neural networks.\n",
        "\n",
        "In order to normalize our data to $[0,1]$ we use the equation:\n",
        "\n",
        "$$x_{norm}=\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
        "\n",
        "Normalize the \"Length1\", \"Length2\", \"Length3\",\t\"Height\", and \"Width\", and \"Weight\" columns. We often need to normalize the target variables in a neural network regression task to limit exploding gradients (why might exploding gradients be more prevalent in a regression task?).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA98AUX0kukU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "424d9326-045d-4e89-bfea-3c2fb766e943"
      },
      "source": [
        "# Get fish max and min weight, we'll need these later.\n",
        "fish_max = fish_data[\"Weight\"].max()\n",
        "fish_min = fish_data[\"Weight\"].min()\n",
        "\n",
        "# Normalize the \"Length1\", \"Length2\", \"Length3\", \"Height\", \"Width\", \"Weight\" columns of fish_data.\n",
        "### YOUR CODE HERE ###\n",
        "for col in fish_data:\n",
        "    if fish_data[col].dtype != object:\n",
        "        fish_data[col] = (fish_data[col] - fish_data[col].min()) / (fish_data[col].max() - fish_data[col].min())\n",
        "\n",
        "# Take a look at the new age column.\n",
        "fish_data.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.143604</td>\n",
              "      <td>0.304854</td>\n",
              "      <td>0.309091</td>\n",
              "      <td>0.358108</td>\n",
              "      <td>0.568334</td>\n",
              "      <td>0.418978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.320388</td>\n",
              "      <td>0.325455</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.624055</td>\n",
              "      <td>0.459235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.203211</td>\n",
              "      <td>0.318447</td>\n",
              "      <td>0.329091</td>\n",
              "      <td>0.376689</td>\n",
              "      <td>0.618123</td>\n",
              "      <td>0.514279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.217201</td>\n",
              "      <td>0.365049</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.417230</td>\n",
              "      <td>0.638566</td>\n",
              "      <td>0.480365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.368932</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.621966</td>\n",
              "      <td>0.576004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species    Weight   Length1   Length2   Length3    Height     Width\n",
              "0   Bream  0.143604  0.304854  0.309091  0.358108  0.568334  0.418978\n",
              "1   Bream  0.172800  0.320388  0.325455  0.378378  0.624055  0.459235\n",
              "2   Bream  0.203211  0.318447  0.329091  0.376689  0.618123  0.514279\n",
              "3   Bream  0.217201  0.365049  0.374545  0.417230  0.638566  0.480365\n",
              "4   Bream  0.257953  0.368932  0.374545  0.425676  0.621966  0.576004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCtWDzuDoI2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ee0556-6eaa-460f-f2df-973d4b3e8eac"
      },
      "source": [
        "# split the data into features X_fish and target variable y_fish.\n",
        "y_fish = fish_data.iloc[:, 1] # Get Fish Weights\n",
        "X_fish = fish_data.drop(columns=['Weight']) # Get Fish measurements plus species\n",
        "X_fish = X_fish.drop(columns=['Species']) # Drop the Fish Species for now\n",
        "\n",
        "# print X.head(), you should have 5 features for each sample\n",
        "print(\"X_fish.head():\")\n",
        "print(X_fish.head())\n",
        "\n",
        "# print y.head(), you should have one label for each sample\n",
        "print(\"\\ny_fish.head()\")\n",
        "print(y_fish.head())"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_fish.head():\n",
            "    Length1   Length2   Length3    Height     Width\n",
            "0  0.304854  0.309091  0.358108  0.568334  0.418978\n",
            "1  0.320388  0.325455  0.378378  0.624055  0.459235\n",
            "2  0.318447  0.329091  0.376689  0.618123  0.514279\n",
            "3  0.365049  0.374545  0.417230  0.638566  0.480365\n",
            "4  0.368932  0.374545  0.425676  0.621966  0.576004\n",
            "\n",
            "y_fish.head()\n",
            "0    0.143604\n",
            "1    0.172800\n",
            "2    0.203211\n",
            "3    0.217201\n",
            "4    0.257953\n",
            "Name: Weight, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr_6JsI5oyRl"
      },
      "source": [
        "# Split the X_fish and y_fish into 60/20 training/test split using train_test_split()\n",
        "### YOUR CODE HERE ###\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fish, y_fish, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSCV-qq2oUyk"
      },
      "source": [
        "### b) Neural Network Training (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpeCVuNvK4I"
      },
      "source": [
        "In the cell below, build a neural network 4 layers as follows:\n",
        "* **input layer** of shape 5\n",
        "* **dense layer** with 10 neurons, and sigmoid activation\n",
        "* **dense layer** with 10 neurons, and sigmoid activation\n",
        "* **dense layer** with 5 neurons, and sigmoid activation\n",
        "* **dense layer** with 1 neuron, and linear activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pno8UsUpSmR"
      },
      "source": [
        "def build_model1():\n",
        "### YOUR CODE HERE ###\n",
        "    input_layer = Input(shape=(5))\n",
        "    x = Dense(10, activation='sigmoid')(input_layer)\n",
        "    x = Dense(10, activation='sigmoid')(x)\n",
        "    x = Dense(5, activation='sigmoid')(x)\n",
        "    x = Dense(1, activation='linear')(x) \n",
        "    return Model(input_layer, x)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUJtdeuqkxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd15764-5fc7-4ae6-a606-cdbe53d4479b"
      },
      "source": [
        "# Get model summary\n",
        "model = build_model1()\n",
        "model.summary()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 5)]               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 231\n",
            "Trainable params: 231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtfFKunWp0jI"
      },
      "source": [
        "Declare an SGD optimizer with learning rate of 0.05, weight decay of 1e-6 and momentum of 0.9. Compile your model Use mean_squared_error as the loss and metrics with the sgd optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok2LdYJfpr05"
      },
      "source": [
        "# Declare the optimizer\n",
        "### YOUR CODE HERE ###\n",
        "sgd = SGD(learning_rate=0.05, decay=1e-6, momentum=0.9)\n",
        "\n",
        "# Compile model\n",
        "### YOUR CODE HERE ###\n",
        "model.compile(optimizer=sgd ,loss='mean_squared_error',metrics=['mean_squared_error'])"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVlE8NkXOAv"
      },
      "source": [
        "Perform model fitting using the training set. Train for 2500 epochs with a batch size of 128 and a validation split of 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6j3uRfqN-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3b696f-67a6-4b1f-b00c-9ae48a2387a7"
      },
      "source": [
        "# Fit model\n",
        "history = model.fit(X_train,\n",
        "                    y_train, \n",
        "                    epochs=2500, \n",
        "                    batch_size=128, \n",
        "                    validation_split=0.25)### YOUR CODE HERE ###\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/2500\n",
            "1/1 [==============================] - 1s 583ms/step - loss: 0.0627 - mean_squared_error: 0.0627 - val_loss: 0.0631 - val_mean_squared_error: 0.0631\n",
            "Epoch 2/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0552 - mean_squared_error: 0.0552 - val_loss: 0.0561 - val_mean_squared_error: 0.0561\n",
            "Epoch 3/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
            "Epoch 4/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0415 - mean_squared_error: 0.0415 - val_loss: 0.0577 - val_mean_squared_error: 0.0577\n",
            "Epoch 5/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0430 - mean_squared_error: 0.0430 - val_loss: 0.0643 - val_mean_squared_error: 0.0643\n",
            "Epoch 6/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0689 - val_mean_squared_error: 0.0689\n",
            "Epoch 7/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0517 - mean_squared_error: 0.0517 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
            "Epoch 8/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0514 - mean_squared_error: 0.0514 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
            "Epoch 9/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
            "Epoch 10/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0434 - mean_squared_error: 0.0434 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
            "Epoch 11/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0413 - mean_squared_error: 0.0413 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
            "Epoch 12/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
            "Epoch 13/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0444 - mean_squared_error: 0.0444 - val_loss: 0.0560 - val_mean_squared_error: 0.0560\n",
            "Epoch 14/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0559 - val_mean_squared_error: 0.0559\n",
            "Epoch 15/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0459 - mean_squared_error: 0.0459 - val_loss: 0.0547 - val_mean_squared_error: 0.0547\n",
            "Epoch 16/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0441 - mean_squared_error: 0.0441 - val_loss: 0.0536 - val_mean_squared_error: 0.0536\n",
            "Epoch 17/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0537 - val_mean_squared_error: 0.0537\n",
            "Epoch 18/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.0552 - val_mean_squared_error: 0.0552\n",
            "Epoch 19/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0415 - mean_squared_error: 0.0415 - val_loss: 0.0571 - val_mean_squared_error: 0.0571\n",
            "Epoch 20/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
            "Epoch 21/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0434 - mean_squared_error: 0.0434 - val_loss: 0.0581 - val_mean_squared_error: 0.0581\n",
            "Epoch 22/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0432 - mean_squared_error: 0.0432 - val_loss: 0.0568 - val_mean_squared_error: 0.0568\n",
            "Epoch 23/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0551 - val_mean_squared_error: 0.0551\n",
            "Epoch 24/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
            "Epoch 25/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
            "Epoch 26/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
            "Epoch 27/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
            "Epoch 28/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
            "Epoch 29/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0419 - mean_squared_error: 0.0419 - val_loss: 0.0531 - val_mean_squared_error: 0.0531\n",
            "Epoch 30/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0531 - val_mean_squared_error: 0.0531\n",
            "Epoch 31/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
            "Epoch 32/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
            "Epoch 33/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0408 - mean_squared_error: 0.0408 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
            "Epoch 34/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0410 - mean_squared_error: 0.0410 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
            "Epoch 35/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0412 - mean_squared_error: 0.0412 - val_loss: 0.0548 - val_mean_squared_error: 0.0548\n",
            "Epoch 36/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0411 - mean_squared_error: 0.0411 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
            "Epoch 37/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
            "Epoch 38/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
            "Epoch 39/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
            "Epoch 40/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
            "Epoch 41/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 42/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 43/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 44/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
            "Epoch 45/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0529 - val_mean_squared_error: 0.0529\n",
            "Epoch 46/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
            "Epoch 47/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
            "Epoch 48/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
            "Epoch 49/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
            "Epoch 50/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
            "Epoch 51/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0531 - val_mean_squared_error: 0.0531\n",
            "Epoch 52/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
            "Epoch 53/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0526 - val_mean_squared_error: 0.0526\n",
            "Epoch 54/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
            "Epoch 55/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0524 - val_mean_squared_error: 0.0524\n",
            "Epoch 56/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0524 - val_mean_squared_error: 0.0524\n",
            "Epoch 57/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0524 - val_mean_squared_error: 0.0524\n",
            "Epoch 58/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
            "Epoch 59/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
            "Epoch 60/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0526 - val_mean_squared_error: 0.0526\n",
            "Epoch 61/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 62/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 63/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 64/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0526 - val_mean_squared_error: 0.0526\n",
            "Epoch 65/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0525 - val_mean_squared_error: 0.0525\n",
            "Epoch 66/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0524 - val_mean_squared_error: 0.0524\n",
            "Epoch 67/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
            "Epoch 68/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 69/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 70/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
            "Epoch 71/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
            "Epoch 72/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
            "Epoch 73/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 74/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 75/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 76/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 77/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0522 - val_mean_squared_error: 0.0522\n",
            "Epoch 78/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
            "Epoch 79/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0521 - val_mean_squared_error: 0.0521\n",
            "Epoch 80/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
            "Epoch 81/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0519 - val_mean_squared_error: 0.0519\n",
            "Epoch 82/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0519 - val_mean_squared_error: 0.0519\n",
            "Epoch 83/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 84/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0395 - mean_squared_error: 0.0395 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 85/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 86/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 87/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 88/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 89/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 90/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0518 - val_mean_squared_error: 0.0518\n",
            "Epoch 91/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
            "Epoch 92/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
            "Epoch 93/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0517 - val_mean_squared_error: 0.0517\n",
            "Epoch 94/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
            "Epoch 95/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0516 - val_mean_squared_error: 0.0516\n",
            "Epoch 96/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 97/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 98/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0392 - mean_squared_error: 0.0392 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 99/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 100/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
            "Epoch 101/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
            "Epoch 102/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
            "Epoch 103/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
            "Epoch 104/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
            "Epoch 105/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
            "Epoch 106/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
            "Epoch 107/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
            "Epoch 108/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
            "Epoch 109/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
            "Epoch 110/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
            "Epoch 111/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0512 - val_mean_squared_error: 0.0512\n",
            "Epoch 112/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
            "Epoch 113/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
            "Epoch 114/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
            "Epoch 115/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
            "Epoch 116/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
            "Epoch 117/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
            "Epoch 118/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
            "Epoch 119/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0510 - val_mean_squared_error: 0.0510\n",
            "Epoch 120/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
            "Epoch 121/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
            "Epoch 122/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
            "Epoch 123/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0509 - val_mean_squared_error: 0.0509\n",
            "Epoch 124/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0508 - val_mean_squared_error: 0.0508\n",
            "Epoch 125/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0508 - val_mean_squared_error: 0.0508\n",
            "Epoch 126/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0508 - val_mean_squared_error: 0.0508\n",
            "Epoch 127/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 128/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 129/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 130/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 131/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 132/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
            "Epoch 133/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
            "Epoch 134/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
            "Epoch 135/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0506 - val_mean_squared_error: 0.0506\n",
            "Epoch 136/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
            "Epoch 137/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
            "Epoch 138/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0505 - val_mean_squared_error: 0.0505\n",
            "Epoch 139/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
            "Epoch 140/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
            "Epoch 141/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
            "Epoch 142/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
            "Epoch 143/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
            "Epoch 144/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
            "Epoch 145/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
            "Epoch 146/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0503 - val_mean_squared_error: 0.0503\n",
            "Epoch 147/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
            "Epoch 148/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
            "Epoch 149/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
            "Epoch 150/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0502 - val_mean_squared_error: 0.0502\n",
            "Epoch 151/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
            "Epoch 152/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
            "Epoch 153/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
            "Epoch 154/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
            "Epoch 155/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
            "Epoch 156/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
            "Epoch 157/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0500 - val_mean_squared_error: 0.0500\n",
            "Epoch 158/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 159/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 160/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 161/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0499 - val_mean_squared_error: 0.0499\n",
            "Epoch 162/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
            "Epoch 163/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
            "Epoch 164/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0498 - val_mean_squared_error: 0.0498\n",
            "Epoch 165/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 166/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 167/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 168/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 169/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 170/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 171/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 172/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0496 - val_mean_squared_error: 0.0496\n",
            "Epoch 173/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 174/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 175/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
            "Epoch 176/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 177/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 178/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 179/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0494 - val_mean_squared_error: 0.0494\n",
            "Epoch 180/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 181/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 182/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0493 - val_mean_squared_error: 0.0493\n",
            "Epoch 183/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 184/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 185/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 186/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 187/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 188/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 189/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
            "Epoch 190/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 191/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 192/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\n",
            "Epoch 193/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 194/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 195/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0489 - val_mean_squared_error: 0.0489\n",
            "Epoch 196/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 197/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 198/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 199/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 200/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 201/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 202/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 203/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 204/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 205/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 206/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 207/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 208/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 209/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 210/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 211/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n",
            "Epoch 212/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 213/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 214/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
            "Epoch 215/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 216/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 217/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
            "Epoch 218/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 219/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 220/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0481 - val_mean_squared_error: 0.0481\n",
            "Epoch 221/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 222/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 223/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0480 - val_mean_squared_error: 0.0480\n",
            "Epoch 224/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 225/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
            "Epoch 226/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 227/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 228/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
            "Epoch 229/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 230/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 231/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0477 - val_mean_squared_error: 0.0477\n",
            "Epoch 232/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 233/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0476 - val_mean_squared_error: 0.0476\n",
            "Epoch 234/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 235/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 236/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 237/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 238/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 239/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 240/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
            "Epoch 241/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
            "Epoch 242/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 243/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 244/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 245/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 246/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 247/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 248/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 249/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 250/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
            "Epoch 251/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
            "Epoch 252/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
            "Epoch 253/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0468 - val_mean_squared_error: 0.0468\n",
            "Epoch 254/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 255/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 256/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
            "Epoch 257/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
            "Epoch 258/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
            "Epoch 259/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 260/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 261/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 262/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 263/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 264/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 265/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 266/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 267/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 268/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 269/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 270/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
            "Epoch 271/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
            "Epoch 272/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 273/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 274/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 275/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 276/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 277/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 278/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 279/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 280/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 281/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 282/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 283/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 284/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 285/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 286/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 287/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 288/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 289/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 290/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 291/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 292/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 293/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 294/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 295/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 296/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 297/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 298/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 299/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 300/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 301/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 302/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 303/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 304/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 305/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 306/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 307/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 308/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 309/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 310/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 311/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 312/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 313/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 314/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 315/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 316/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 317/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 318/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 319/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 320/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
            "Epoch 321/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
            "Epoch 322/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 323/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 324/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 325/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 326/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
            "Epoch 327/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 328/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 329/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
            "Epoch 330/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
            "Epoch 331/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 332/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 333/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
            "Epoch 334/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
            "Epoch 335/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
            "Epoch 336/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
            "Epoch 337/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
            "Epoch 338/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
            "Epoch 339/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
            "Epoch 340/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0416 - val_mean_squared_error: 0.0416\n",
            "Epoch 341/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
            "Epoch 342/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
            "Epoch 343/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
            "Epoch 344/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
            "Epoch 345/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0412 - val_mean_squared_error: 0.0412\n",
            "Epoch 346/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
            "Epoch 347/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0410 - val_mean_squared_error: 0.0410\n",
            "Epoch 348/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
            "Epoch 349/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
            "Epoch 350/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
            "Epoch 351/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0407 - val_mean_squared_error: 0.0407\n",
            "Epoch 352/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
            "Epoch 353/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
            "Epoch 354/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0404 - val_mean_squared_error: 0.0404\n",
            "Epoch 355/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0303 - mean_squared_error: 0.0303 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
            "Epoch 356/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0402 - val_mean_squared_error: 0.0402\n",
            "Epoch 357/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
            "Epoch 358/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
            "Epoch 359/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 0.0399 - val_mean_squared_error: 0.0399\n",
            "Epoch 360/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
            "Epoch 361/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
            "Epoch 362/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
            "Epoch 363/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0396 - val_mean_squared_error: 0.0396\n",
            "Epoch 364/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
            "Epoch 365/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
            "Epoch 366/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
            "Epoch 367/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
            "Epoch 368/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
            "Epoch 369/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0389 - val_mean_squared_error: 0.0389\n",
            "Epoch 370/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0388 - val_mean_squared_error: 0.0388\n",
            "Epoch 371/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0387 - val_mean_squared_error: 0.0387\n",
            "Epoch 372/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
            "Epoch 373/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
            "Epoch 374/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
            "Epoch 375/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
            "Epoch 376/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
            "Epoch 377/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
            "Epoch 378/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
            "Epoch 379/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
            "Epoch 380/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 381/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
            "Epoch 382/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 383/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
            "Epoch 384/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
            "Epoch 385/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
            "Epoch 386/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
            "Epoch 387/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
            "Epoch 388/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
            "Epoch 389/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0275 - mean_squared_error: 0.0275 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
            "Epoch 390/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
            "Epoch 391/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
            "Epoch 392/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.0363 - val_mean_squared_error: 0.0363\n",
            "Epoch 393/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
            "Epoch 394/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
            "Epoch 395/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
            "Epoch 396/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
            "Epoch 397/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
            "Epoch 398/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
            "Epoch 399/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
            "Epoch 400/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
            "Epoch 401/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
            "Epoch 402/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
            "Epoch 403/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
            "Epoch 404/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
            "Epoch 405/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
            "Epoch 406/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
            "Epoch 407/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
            "Epoch 408/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0342 - val_mean_squared_error: 0.0342\n",
            "Epoch 409/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0341 - val_mean_squared_error: 0.0341\n",
            "Epoch 410/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
            "Epoch 411/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0338 - val_mean_squared_error: 0.0338\n",
            "Epoch 412/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0337 - val_mean_squared_error: 0.0337\n",
            "Epoch 413/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
            "Epoch 414/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
            "Epoch 415/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
            "Epoch 416/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
            "Epoch 417/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0330 - val_mean_squared_error: 0.0330\n",
            "Epoch 418/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0328 - val_mean_squared_error: 0.0328\n",
            "Epoch 419/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
            "Epoch 420/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
            "Epoch 421/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
            "Epoch 422/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
            "Epoch 423/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
            "Epoch 424/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
            "Epoch 425/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0317 - val_mean_squared_error: 0.0317\n",
            "Epoch 426/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
            "Epoch 427/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0314 - val_mean_squared_error: 0.0314\n",
            "Epoch 428/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
            "Epoch 429/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
            "Epoch 430/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0310 - val_mean_squared_error: 0.0310\n",
            "Epoch 431/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0308 - val_mean_squared_error: 0.0308\n",
            "Epoch 432/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
            "Epoch 433/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
            "Epoch 434/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
            "Epoch 435/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0301 - val_mean_squared_error: 0.0301\n",
            "Epoch 436/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
            "Epoch 437/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
            "Epoch 438/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0297 - val_mean_squared_error: 0.0297\n",
            "Epoch 439/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
            "Epoch 440/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0293 - val_mean_squared_error: 0.0293\n",
            "Epoch 441/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0291 - val_mean_squared_error: 0.0291\n",
            "Epoch 442/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
            "Epoch 443/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
            "Epoch 444/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0286 - val_mean_squared_error: 0.0286\n",
            "Epoch 445/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
            "Epoch 446/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0283 - val_mean_squared_error: 0.0283\n",
            "Epoch 447/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0281 - val_mean_squared_error: 0.0281\n",
            "Epoch 448/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
            "Epoch 449/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
            "Epoch 450/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0276 - val_mean_squared_error: 0.0276\n",
            "Epoch 451/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0274 - val_mean_squared_error: 0.0274\n",
            "Epoch 452/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
            "Epoch 453/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0271 - val_mean_squared_error: 0.0271\n",
            "Epoch 454/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0269 - val_mean_squared_error: 0.0269\n",
            "Epoch 455/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
            "Epoch 456/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0265 - val_mean_squared_error: 0.0265\n",
            "Epoch 457/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
            "Epoch 458/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n",
            "Epoch 459/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
            "Epoch 460/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
            "Epoch 461/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
            "Epoch 462/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
            "Epoch 463/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
            "Epoch 464/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0251 - val_mean_squared_error: 0.0251\n",
            "Epoch 465/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
            "Epoch 466/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
            "Epoch 467/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
            "Epoch 468/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
            "Epoch 469/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
            "Epoch 470/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0240 - val_mean_squared_error: 0.0240\n",
            "Epoch 471/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
            "Epoch 472/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
            "Epoch 473/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
            "Epoch 474/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 475/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
            "Epoch 476/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
            "Epoch 477/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
            "Epoch 478/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
            "Epoch 479/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
            "Epoch 480/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
            "Epoch 481/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
            "Epoch 482/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
            "Epoch 483/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
            "Epoch 484/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
            "Epoch 485/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
            "Epoch 486/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
            "Epoch 487/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
            "Epoch 488/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
            "Epoch 489/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
            "Epoch 490/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
            "Epoch 491/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
            "Epoch 492/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
            "Epoch 493/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
            "Epoch 494/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
            "Epoch 495/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
            "Epoch 496/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
            "Epoch 497/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
            "Epoch 498/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
            "Epoch 499/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
            "Epoch 500/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0185 - val_mean_squared_error: 0.0185\n",
            "Epoch 501/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
            "Epoch 502/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
            "Epoch 503/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
            "Epoch 504/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
            "Epoch 505/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
            "Epoch 506/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
            "Epoch 507/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
            "Epoch 508/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
            "Epoch 509/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 510/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 511/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
            "Epoch 512/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 513/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "Epoch 514/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 515/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 516/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 517/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 518/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 519/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 520/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 521/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 522/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 523/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 524/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 525/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 526/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "Epoch 527/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "Epoch 528/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "Epoch 529/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 530/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "Epoch 531/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "Epoch 532/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 533/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "Epoch 534/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 535/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 536/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 537/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 538/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 539/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 540/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 541/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 542/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 543/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 544/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 545/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 546/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 547/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 548/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 549/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 550/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 551/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "Epoch 552/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "Epoch 553/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "Epoch 554/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
            "Epoch 555/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
            "Epoch 556/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
            "Epoch 557/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
            "Epoch 558/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
            "Epoch 559/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
            "Epoch 560/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
            "Epoch 561/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
            "Epoch 562/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
            "Epoch 563/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
            "Epoch 564/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
            "Epoch 565/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
            "Epoch 566/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
            "Epoch 567/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
            "Epoch 568/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
            "Epoch 569/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
            "Epoch 570/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
            "Epoch 571/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
            "Epoch 572/2500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
            "Epoch 573/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
            "Epoch 574/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
            "Epoch 575/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
            "Epoch 576/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
            "Epoch 577/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
            "Epoch 578/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
            "Epoch 579/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 580/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 581/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
            "Epoch 582/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 583/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 584/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 585/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 586/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 587/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 588/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 589/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 590/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 591/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 592/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 593/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 594/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 595/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 596/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 597/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 598/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 599/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 600/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 601/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 602/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 603/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 604/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 605/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 606/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 607/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 608/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 609/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 610/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 611/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 612/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 613/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 614/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 615/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 616/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 617/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 618/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 619/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 620/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 621/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 622/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 623/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 624/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 625/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 626/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 627/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 628/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 629/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 630/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 631/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 632/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 633/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 634/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 635/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 636/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 637/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 638/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 639/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 640/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 641/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 642/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 643/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 644/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 645/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 646/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 647/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 648/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 649/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 650/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 651/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 652/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 653/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 654/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 655/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 656/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 657/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 658/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 659/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 660/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 661/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 662/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 663/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 664/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 665/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 666/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 667/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 668/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 669/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 670/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 671/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 672/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 673/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 674/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 675/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 676/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 677/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 678/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 679/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 680/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 681/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 682/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 683/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 684/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 685/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 686/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 687/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 688/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 689/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 690/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 691/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 692/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 693/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 694/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 695/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 696/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 697/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 698/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 699/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 700/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 701/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 702/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 703/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 704/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 705/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 706/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 707/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 708/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 709/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 710/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 711/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 712/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 713/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 714/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 715/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 716/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 717/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 718/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 719/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 720/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 721/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 722/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 723/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 724/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 725/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 726/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 727/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 728/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 729/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 730/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 731/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 732/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 733/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 734/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 735/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 736/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 737/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 738/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 739/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 740/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 741/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 742/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 743/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 744/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 745/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 746/2500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 747/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 748/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 749/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 750/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 751/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 752/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 753/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 754/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 755/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 756/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 757/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 758/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 759/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 760/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 761/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 762/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 763/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 764/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 765/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 766/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 767/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 768/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 769/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 770/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 771/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 772/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 773/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 774/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 775/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 776/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 777/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 778/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 779/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 780/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 781/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 782/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 783/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 784/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 785/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 786/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 787/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 788/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 789/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 790/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 791/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 792/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 793/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 794/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 795/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 796/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 797/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 798/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 799/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 800/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 801/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 802/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 803/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 804/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 805/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 806/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 807/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 808/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 809/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 810/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 811/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 812/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 813/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 814/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 815/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 816/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 817/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 818/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 819/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 820/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 821/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 822/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 823/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 824/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 825/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 826/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 827/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 828/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 829/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 830/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 831/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 832/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 833/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 834/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 835/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 836/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 837/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 838/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 839/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 840/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 841/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 842/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 843/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 844/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 845/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 846/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 847/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 848/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 849/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 850/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 851/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 852/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 853/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 854/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 855/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 856/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 857/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 858/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 859/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 860/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 861/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 862/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 863/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 864/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 865/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 866/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 867/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 868/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 869/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 870/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 871/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 872/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 873/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 874/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 875/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 876/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 877/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 878/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 879/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 880/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 881/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 882/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 883/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 884/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 885/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 886/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 887/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 888/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 889/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 890/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 891/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 892/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 893/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 894/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 895/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 896/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 897/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 898/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 899/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 900/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 901/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 902/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 903/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 904/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 905/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 906/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 907/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 908/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 909/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 910/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 911/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 912/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 913/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 914/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 915/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 916/2500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 917/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 918/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 919/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 920/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 921/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 922/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 923/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 924/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 925/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 926/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 927/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 928/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 929/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 930/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 931/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 932/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 933/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 934/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 935/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 936/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 937/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 938/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 939/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 940/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 941/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 942/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 943/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 944/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 945/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 946/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 947/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 948/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 949/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 950/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 951/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 952/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 953/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 954/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 955/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 956/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 957/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 958/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 959/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 960/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 961/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 962/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 963/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 964/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 965/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 966/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 967/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 968/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 969/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 970/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 971/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 972/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 973/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 974/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 975/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 976/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 977/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 978/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 979/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 980/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 981/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 982/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 983/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 984/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 985/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 986/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 987/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 988/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 989/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 990/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 991/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 992/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 993/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 994/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 995/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 996/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 997/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 998/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 999/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1000/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1001/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1002/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1003/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1004/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1005/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1006/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1007/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1008/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1009/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1010/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1011/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1012/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1013/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1014/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1015/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1016/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1017/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1018/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1019/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1020/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1021/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1022/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1023/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1024/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1025/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1026/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1027/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1028/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1029/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1030/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1031/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1032/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1033/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1034/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1035/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1036/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1037/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1038/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1039/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1040/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1041/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1042/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1043/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1044/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1045/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1046/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1047/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1048/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1049/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1050/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1051/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1052/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1053/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1054/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1055/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1056/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1057/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1058/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1059/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1060/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1061/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1062/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1063/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1064/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1065/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1066/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1067/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1068/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1069/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1070/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1071/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1072/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1073/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1074/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1075/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1076/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1077/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1078/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1079/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1080/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1081/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1082/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1083/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1084/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1085/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1086/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1087/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1088/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1089/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1090/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1091/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1092/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1093/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1094/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1095/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1096/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1097/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1098/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1099/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1100/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1101/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1102/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1103/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1104/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1105/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1106/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1107/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1108/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1109/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1110/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1111/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1112/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1113/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1114/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1115/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1116/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1117/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1118/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1119/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1120/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1121/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1122/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1123/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1124/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1125/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1126/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1127/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1128/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1129/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1130/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1131/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1132/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1133/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1134/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1135/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1136/2500\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1137/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1138/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1139/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1140/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1141/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1142/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1143/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1144/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1145/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1146/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1147/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1148/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1149/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1150/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1151/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1152/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1153/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1154/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1155/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1156/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1157/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1158/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1159/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1160/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1161/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1162/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1163/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1164/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1165/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1166/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1167/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1168/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1169/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1170/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1171/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1172/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1173/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1174/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1175/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1176/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1177/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1178/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1179/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1180/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1181/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1182/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1183/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1184/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1185/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1186/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1187/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1188/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1189/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1190/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1191/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1192/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1193/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1194/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1195/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1196/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1197/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1198/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1199/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1200/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1201/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1202/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1203/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1204/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1205/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1206/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1207/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1208/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1209/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1210/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1211/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1212/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1213/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1214/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1215/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1216/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1217/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1218/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1219/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1220/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1221/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1222/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1223/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1224/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1225/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1226/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1227/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1228/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1229/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1230/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1231/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1232/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1233/2500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1234/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1235/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1236/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1237/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1238/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1239/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1240/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1241/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1242/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1243/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1244/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1245/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1246/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1247/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1248/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1249/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1250/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1251/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1252/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1253/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1254/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1255/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1256/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1257/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1258/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1259/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1260/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1261/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1262/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1263/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1264/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1265/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1266/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1267/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1268/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1269/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1270/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1271/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1272/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1273/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1274/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1275/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1276/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1277/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1278/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1279/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1280/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1281/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1282/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1283/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1284/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1285/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1286/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1287/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1288/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1289/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1290/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1291/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1292/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1293/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1294/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1295/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1296/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1297/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1298/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1299/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1300/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1301/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1302/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1303/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1304/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1305/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1306/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1307/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1308/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1309/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1310/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1311/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1312/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1313/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1314/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1315/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1316/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1317/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1318/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1319/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1320/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1321/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1322/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1323/2500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1324/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1325/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1326/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1327/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1328/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1329/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1330/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1331/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1332/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1333/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1334/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1335/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1336/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1337/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1338/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1339/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1340/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1341/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1342/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1343/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1344/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1345/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1346/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1347/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1348/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1349/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1350/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1351/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1352/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1353/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1354/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1355/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1356/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1357/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1358/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1359/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1360/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1361/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1362/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1363/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1364/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1365/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1366/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1367/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1368/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1369/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1370/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1371/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1372/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1373/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1374/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1375/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1376/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1377/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1378/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1379/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1380/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1381/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1382/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1383/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1384/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1385/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1386/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1387/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1388/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1389/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1390/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1391/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1392/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1393/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1394/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1395/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1396/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1397/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1398/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1399/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1400/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1401/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1402/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1403/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1404/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1405/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1406/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1407/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1408/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1409/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1410/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1411/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1412/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1413/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1414/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1415/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1416/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1417/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1418/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1419/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1420/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1421/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1422/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1423/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1424/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1425/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1426/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1427/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1428/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1429/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1430/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1431/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1432/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1433/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1434/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1435/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1436/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1437/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1438/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1439/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1440/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1441/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1442/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1443/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1444/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1445/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1446/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1447/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1448/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1449/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1450/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1451/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1452/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1453/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1454/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1455/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1456/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1457/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1458/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1459/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1460/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1461/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1462/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1463/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1464/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1465/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1466/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1467/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1468/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1469/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1470/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1471/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1472/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1473/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1474/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1475/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1476/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1477/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1478/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1479/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1480/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1481/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1482/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1483/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1484/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1485/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1486/2500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1487/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1488/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1489/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1490/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1491/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1492/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1493/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1494/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1495/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1496/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1497/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1498/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1499/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1500/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1501/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1502/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1503/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1504/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1505/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1506/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1507/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1508/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1509/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1510/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1511/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1512/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1513/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1514/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1515/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1516/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1517/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1518/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1519/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1520/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1521/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1522/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 1523/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1524/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1525/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1526/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1527/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1528/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1529/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1530/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1531/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1532/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1533/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1534/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1535/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1536/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1537/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1538/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1539/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1540/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1541/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1542/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1543/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1544/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1545/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1546/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1547/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1548/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1549/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1550/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1551/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1552/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1553/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1554/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1555/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1556/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1557/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1558/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1559/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1560/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1561/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1562/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1563/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1564/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1565/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1566/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1567/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1568/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1569/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1570/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1571/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1572/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 1573/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1574/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1575/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1576/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1577/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1578/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1579/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1580/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1581/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1582/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1583/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1584/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1585/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1586/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1587/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1588/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1589/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1590/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1591/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1592/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1593/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1594/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1595/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1596/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1597/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1598/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1599/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1600/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1601/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1602/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1603/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1604/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1605/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1606/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1607/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1608/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1609/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1610/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1611/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1612/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1613/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1614/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1615/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1616/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1617/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1618/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1619/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1620/2500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1621/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1622/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1623/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1624/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1625/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 1626/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1627/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1628/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1629/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1630/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1631/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1632/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1633/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1634/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1635/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1636/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1637/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1638/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1639/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1640/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1641/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1642/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1643/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1644/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1645/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1646/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1647/2500\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1648/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1649/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1650/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1651/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1652/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1653/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1654/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1655/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1656/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1657/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1658/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1659/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1660/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1661/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1662/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1663/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1664/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1665/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1666/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1667/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1668/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1669/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1670/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1671/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1672/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1673/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1674/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1675/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1676/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1677/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1678/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1679/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 1680/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1681/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1682/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1683/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1684/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1685/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1686/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1687/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1688/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1689/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1690/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1691/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1692/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1693/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1694/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1695/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1696/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1697/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1698/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1699/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1700/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1701/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1702/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1703/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1704/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1705/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1706/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1707/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1708/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1709/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1710/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1711/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1712/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1713/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1714/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1715/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1716/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1717/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1718/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1719/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1720/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1721/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1722/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1723/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1724/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1725/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1726/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1727/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1728/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1729/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1730/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1731/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1732/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1733/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1734/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 1735/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1736/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1737/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1738/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1739/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1740/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1741/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1742/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1743/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1744/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1745/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1746/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1747/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1748/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1749/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1750/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1751/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1752/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1753/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1754/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1755/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1756/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1757/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1758/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1759/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1760/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1761/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1762/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1763/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1764/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1765/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1766/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1767/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1768/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1769/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1770/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1771/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1772/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1773/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1774/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1775/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1776/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1777/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1778/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1779/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1780/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1781/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1782/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1783/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1784/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1785/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1786/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1787/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1788/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1789/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1790/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1791/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1792/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 1793/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1794/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1795/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1796/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1797/2500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1798/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1799/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1800/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1801/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1802/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1803/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1804/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1805/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1806/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1807/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1808/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1809/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1810/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1811/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1812/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1813/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1814/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1815/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1816/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1817/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1818/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1819/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1820/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1821/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1822/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1823/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1824/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1825/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1826/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1827/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1828/2500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1829/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1830/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1831/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1832/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1833/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1834/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1835/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1836/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1837/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1838/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1839/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1840/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1841/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1842/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1843/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1844/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1845/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1846/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1847/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1848/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1849/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1850/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1851/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1852/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
            "Epoch 1853/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1854/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1855/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1856/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1857/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1858/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1859/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1860/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1861/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1862/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1863/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1864/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1865/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1866/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1867/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1868/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1869/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1870/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1871/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1872/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1873/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1874/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1875/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1876/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1877/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1878/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1879/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1880/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1881/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1882/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1883/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1884/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1885/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1886/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1887/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1888/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1889/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1890/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1891/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1892/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1893/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1894/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1895/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1896/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1897/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1898/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1899/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1900/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1901/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1902/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1903/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1904/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1905/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1906/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1907/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1908/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1909/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1910/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1911/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1912/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1913/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
            "Epoch 1914/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1915/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1916/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1917/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1918/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1919/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1920/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1921/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1922/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1923/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1924/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1925/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1926/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1927/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1928/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1929/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1930/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1931/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1932/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1933/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1934/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1935/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1936/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1937/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1938/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1939/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1940/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1941/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1942/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1943/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1944/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1945/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1946/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1947/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1948/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1949/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1950/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1951/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1952/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1953/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1954/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1955/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1956/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1957/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1958/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1959/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1960/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1961/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1962/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1963/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1964/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1965/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1966/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1967/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1968/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1969/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1970/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1971/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1972/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1973/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1974/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1975/2500\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1976/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1977/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
            "Epoch 1978/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1979/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1980/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1981/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1982/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1983/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1984/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1985/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1986/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1987/2500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1988/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1989/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1990/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1991/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1992/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1993/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1994/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1995/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1996/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1997/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1998/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 1999/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2000/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2001/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2002/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2003/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2004/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2005/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2006/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2007/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2008/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2009/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2010/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2011/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2012/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2013/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2014/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2015/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2016/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2017/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2018/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2019/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2020/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2021/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2022/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2023/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2024/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2025/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2026/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2027/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2028/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2029/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2030/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2031/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2032/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2033/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2034/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2035/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2036/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2037/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2038/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2039/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2040/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2041/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2042/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2043/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2044/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
            "Epoch 2045/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2046/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2047/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2048/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2049/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2050/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2051/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2052/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2053/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2054/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2055/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2056/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2057/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2058/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2059/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2060/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2061/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2062/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2063/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2064/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2065/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2066/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2067/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2068/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2069/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2070/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2071/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2072/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2073/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2074/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2075/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2076/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2077/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2078/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2079/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2080/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2081/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2082/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2083/2500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2084/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2085/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2086/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2087/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2088/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2089/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2090/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2091/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2092/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2093/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2094/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2095/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2096/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2097/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2098/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2099/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2100/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2101/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2102/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2103/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2104/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2105/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2106/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2107/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2108/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2109/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2110/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2111/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2112/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2113/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
            "Epoch 2114/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2115/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2116/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2117/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2118/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2119/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2120/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2121/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2122/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2123/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2124/2500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2125/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2126/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2127/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2128/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2129/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2130/2500\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2131/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2132/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2133/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2134/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2135/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2136/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2137/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2138/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2139/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2140/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2141/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2142/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2143/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2144/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2145/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2146/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2147/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2148/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2149/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2150/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2151/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2152/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2153/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2154/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2155/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2156/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2157/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2158/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2159/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2160/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2161/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2162/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2163/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2164/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2165/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2166/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2167/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2168/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2169/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2170/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2171/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2172/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2173/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2174/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2175/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2176/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2177/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2178/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2179/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2180/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2181/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2182/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2183/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2184/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2185/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
            "Epoch 2186/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2187/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2188/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2189/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2190/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2191/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2192/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2193/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2194/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2195/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2196/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2197/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2198/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2199/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2200/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2201/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2202/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2203/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2204/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2205/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2206/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2207/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2208/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2209/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2210/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2211/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2212/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2213/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2214/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2215/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2216/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2217/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2218/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2219/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2220/2500\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2221/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2222/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2223/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2224/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2225/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2226/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2227/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2228/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2229/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2230/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2231/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2232/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2233/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2234/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2235/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2236/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2237/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2238/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2239/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2240/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2241/2500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2242/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2243/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2244/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2245/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2246/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2247/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2248/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2249/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2250/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2251/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2252/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2253/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2254/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2255/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2256/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2257/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2258/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2259/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2260/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
            "Epoch 2261/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2262/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2263/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2264/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2265/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2266/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2267/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2268/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2269/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2270/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2271/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2272/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2273/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2274/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2275/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2276/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2277/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2278/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2279/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2280/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2281/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2282/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2283/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2284/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2285/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2286/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2287/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2288/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2289/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2290/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2291/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2292/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2293/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2294/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2295/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2296/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2297/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2298/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2299/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2300/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2301/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2302/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2303/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2304/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2305/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2306/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2307/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2308/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2309/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2310/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2311/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2312/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2313/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2314/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2315/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2316/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2317/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2318/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2319/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2320/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2321/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2322/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2323/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2324/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2325/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2326/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2327/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2328/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2329/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2330/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2331/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2332/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2333/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2334/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2335/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2336/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2337/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2338/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2339/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
            "Epoch 2340/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2341/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2342/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2343/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2344/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2345/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2346/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2347/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2348/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2349/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2350/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2351/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2352/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2353/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2354/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2355/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2356/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2357/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2358/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2359/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2360/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2361/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2362/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2363/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2364/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2365/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2366/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2367/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2368/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2369/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2370/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2371/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2372/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2373/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2374/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2375/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2376/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2377/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2378/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2379/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2380/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2381/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2382/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2383/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2384/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2385/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2386/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2387/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2388/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2389/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2390/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2391/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2392/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2393/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2394/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2395/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2396/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2397/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2398/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2399/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2400/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2401/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2402/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2403/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2404/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2405/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2406/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2407/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2408/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2409/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2410/2500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2411/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2412/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2413/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2414/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2415/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2416/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2417/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2418/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2419/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2420/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2421/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2422/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
            "Epoch 2423/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2424/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2425/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2426/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2427/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2428/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2429/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2430/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2431/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2432/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2433/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2434/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2435/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2436/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2437/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2438/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2439/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2440/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2441/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2442/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2443/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2444/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2445/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2446/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2447/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2448/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2449/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2450/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2451/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2452/2500\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2453/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2454/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2455/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2456/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2457/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2458/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2459/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2460/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2461/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2462/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2463/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2464/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2465/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2466/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2467/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2468/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2469/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2470/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2471/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2472/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2473/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2474/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2475/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2476/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2477/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2478/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2479/2500\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2480/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2481/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2482/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2483/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2484/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2485/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2486/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2487/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2488/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2489/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2490/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2491/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2492/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2493/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2494/2500\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2495/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2496/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2497/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2498/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2499/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
            "Epoch 2500/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0HqYFKtrVOM"
      },
      "source": [
        "# Get fish weight predictions\n",
        "y_fish_pred = model.predict(X_test)\n",
        "\n",
        "# map normalized fish weights back to grams\n",
        "y_fish_pred = (fish_max-fish_min) * y_fish_pred + fish_min \n",
        "y_test = (fish_max-fish_min) * y_test.values + fish_min "
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0cyLYP-qx36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929ba89d-6586-4f5c-8777-f7d372b34daa"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Compute the mean squared error using y_fish_test and y_fish_pred\n",
        "### YOUR CODE HERE ###\n",
        "print(\"mean squared error:\", mean_squared_error(y_test, y_fish_pred))\n",
        "\n",
        "# Compute the coefficient of determination using y_fish_test and y_fish_pred\n",
        "### YOUR CODE HERE ###\n",
        "print(\"coefficient of determination:\", r2_score(y_test, y_fish_pred))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean squared error: 14946.003630118134\n",
            "coefficient of determination: 0.9041004367347083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXh5nXxgzAsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff98d861-516a-428c-9d73-4c30fd87572c"
      },
      "source": [
        "# Print the predictions along with actual weights\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format},precision=2)\n",
        "print(np.concatenate((y_fish_pred.reshape(len(y_fish_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[446.962341 390.000000]\n",
            " [196.177612 160.000000]\n",
            " [669.945557 700.000000]\n",
            " [859.217957 1015.000000]\n",
            " [111.104973 120.000000]\n",
            " [856.525085 1100.000000]\n",
            " [766.707886 820.000000]\n",
            " [952.274902 950.000000]\n",
            " [618.293518 556.000000]\n",
            " [171.661346 145.000000]\n",
            " [659.982056 700.000000]\n",
            " [1148.448120 1600.000000]\n",
            " [707.152100 720.000000]\n",
            " [17.954830 55.000000]\n",
            " [81.505287 85.000000]\n",
            " [239.275787 188.000000]\n",
            " [426.234375 300.000000]\n",
            " [212.143341 180.000000]\n",
            " [1148.448120 1550.000000]\n",
            " [352.750000 306.000000]\n",
            " [164.819077 140.000000]\n",
            " [918.986511 975.000000]\n",
            " [784.370483 1000.000000]\n",
            " [475.721710 450.000000]\n",
            " [140.109055 110.000000]\n",
            " [86.166931 78.000000]\n",
            " [362.336609 300.000000]\n",
            " [621.307129 650.000000]\n",
            " [-113.161606 6.700000]\n",
            " [547.550293 514.000000]\n",
            " [313.469177 290.000000]\n",
            " [285.722504 270.000000]\n",
            " [579.037842 700.000000]\n",
            " [434.899719 300.000000]\n",
            " [577.746765 510.000000]\n",
            " [612.692017 620.000000]\n",
            " [168.835663 150.000000]\n",
            " [169.567612 170.000000]\n",
            " [691.597229 700.000000]\n",
            " [191.449173 170.000000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FprpdF_YzJf6"
      },
      "source": [
        "What was the R-squared value and mean squared error for this model? Does this model appear to do a better job at predicting weights than linear regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDRR8wzy0SZu"
      },
      "source": [
        "[YOUR ANSWER HERE]"
      ]
    }
  ]
}